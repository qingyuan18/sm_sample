{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579322a2",
   "metadata": {},
   "source": [
    "## Stable Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "526743e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (22.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-23.0.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.3.1\n",
      "    Uninstalling pip-22.3.1:\n",
      "      Successfully uninstalled pip-22.3.1\n",
      "Successfully installed pip-23.0.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.27.71 requires botocore==1.29.71, but you have botocore 1.29.94 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python -m pip install --upgrade pip\n",
    "! pip install botocore --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90adc7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"sagemaker==2.116.0\" \"huggingface_hub==0.13.1\" --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "837b2f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::687912291502:role/service-role/AmazonSageMaker-ExecutionRole-20211013T113123\n",
      "sagemaker bucket: sagemaker-us-west-2-687912291502\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16449ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing code/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/inference.py\n",
    "import base64\n",
    "import torch\n",
    "from io import BytesIO\n",
    "from diffusers import StableDiffusionPipeline,DiffusionPipeline\n",
    "import deepspeed\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "\n",
    "    # Load stable diffusion and move it to the GPU\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_dir, torch_dtype=torch.float16, revision=\"fp16\")\n",
    "    pipe=deepspeed.init_inference(\n",
    "        model=getattr(pipe,\"model\", pipe),      # Transformers models\n",
    "        mp_size=1,        # Number of GPU\n",
    "        dtype=torch.float16, # dtype of the weights (fp16)\n",
    "        replace_method=\"auto\", # Lets DS autmatically identify the layer to replace\n",
    "        replace_with_kernel_inject=False, # replace the model with the kernel injector\n",
    "    )\n",
    "\n",
    "    print(\"!!!!DeepSpeed Inference Engine initialized!!!!!!!!\")\n",
    "    pipe = pipe.to(\"cuda\")\n",
    "    torch.cuda.synchronize(\"cuda\")\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def predict_fn(data, pipe):\n",
    "\n",
    "    # get prompt & parameters\n",
    "    prompt = data.pop(\"inputs\", data)\n",
    "    print(prompt)\n",
    "    # set valid HP for stable diffusion\n",
    "    num_inference_steps = data.pop(\"num_inference_steps\", 50)\n",
    "    guidance_scale = data.pop(\"guidance_scale\", 7.5)\n",
    "    num_images_per_prompt = data.pop(\"num_images_per_prompt\", 4)\n",
    "    width = data.pop(\"width\", 512)\n",
    "    height = data.pop(\"height\", 512)\n",
    "\n",
    "    # run generation with parameters\n",
    "    generated_images = pipe(\n",
    "        prompt,\n",
    "        #num_inference_steps=num_inference_steps,\n",
    "        #guidance_scale=guidance_scale,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        num_images_per_prompt=num_images_per_prompt\n",
    "    )[\"images\"]\n",
    "\n",
    "    # create response\n",
    "    encoded_images = []\n",
    "    for image in generated_images:\n",
    "        buffered = BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        encoded_images.append(base64.b64encode(buffered.getvalue()).decode())\n",
    "\n",
    "    # create response\n",
    "    return {\"generated_images\": encoded_images}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3716b04-a798-435d-b81b-6479382094fb",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com, https://download.pytorch.org/whl/cu113\n",
      "Collecting torch==1.12.1+cu113\n",
      "  Downloading https://download.pytorch.org/whl/cu113/torch-1.12.1%2Bcu113-cp39-cp39-linux_x86_64.whl (1837.7 MB)\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/1.8 GB\u001b[0m \u001b[31m896.3 kB/s\u001b[0m eta \u001b[36m0:18:43\u001b[0m\u001b[31mERROR: Could not install packages due to an OSError: [Errno 28] No space left on device\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/1.8 GB\u001b[0m \u001b[31m892.9 kB/s\u001b[0m eta \u001b[36m0:18:47\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "#!pip install -r ./inference/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "512b56c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list|grep -i  cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0c46a53-061b-4ca1-8a68-a1f752a6e615",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a31227a0564e23ba41c89f59fd3be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded: StableDiffusionPipeline {\n",
      "  \"_class_name\": \"StableDiffusionPipeline\",\n",
      "  \"_diffusers_version\": \"0.13.1\",\n",
      "  \"feature_extractor\": [\n",
      "    \"transformers\",\n",
      "    \"CLIPFeatureExtractor\"\n",
      "  ],\n",
      "  \"requires_safety_checker\": true,\n",
      "  \"safety_checker\": [\n",
      "    \"stable_diffusion\",\n",
      "    \"StableDiffusionSafetyChecker\"\n",
      "  ],\n",
      "  \"scheduler\": [\n",
      "    \"diffusers\",\n",
      "    \"PNDMScheduler\"\n",
      "  ],\n",
      "  \"text_encoder\": [\n",
      "    \"transformers\",\n",
      "    \"CLIPTextModel\"\n",
      "  ],\n",
      "  \"tokenizer\": [\n",
      "    \"transformers\",\n",
      "    \"CLIPTokenizer\"\n",
      "  ],\n",
      "  \"unet\": [\n",
      "    \"diffusers\",\n",
      "    \"UNet2DConditionModel\"\n",
      "  ],\n",
      "  \"vae\": [\n",
      "    \"diffusers\",\n",
      "    \"AutoencoderKL\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "begin load deepspeed....\n",
      "[2023-03-19 01:05:43,108] [INFO] [logging.py:77:log_dist] [Rank -1] DeepSpeed info: version=0.8.2, git-hash=unknown, git-branch=unknown\n",
      "[2023-03-19 01:05:43,109] [WARNING] [config_utils.py:75:_process_deprecated_field] Config parameter replace_method is deprecated. This parameter is no longer needed, please remove from your call to DeepSpeed-inference\n",
      "[2023-03-19 01:05:43,110] [WARNING] [config_utils.py:75:_process_deprecated_field] Config parameter mp_size is deprecated use tensor_parallel.tp_size instead\n",
      "[2023-03-19 01:05:43,110] [INFO] [logging.py:77:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1\n",
      "deepspeed accelarate excpetion!\n",
      "'StableDiffusionPipeline' object has no attribute 'children'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "import boto3\n",
    "import sagemaker\n",
    "import uuid\n",
    "import torch\n",
    "from torch import autocast\n",
    "from PIL import Image\n",
    "import io\n",
    "import requests\n",
    "import traceback\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "import deepspeed\n",
    "\n",
    "\n",
    "\n",
    "#model_dir='/root/dreambooth/models_diffuser/'\n",
    "model_dir='runwayml/stable-diffusion-v1-5'\n",
    "model = StableDiffusionPipeline.from_pretrained(model_dir, torch_dtype=torch.float16, revision=\"fp16\")\n",
    "print(\"model loaded:\",model)\n",
    " \n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "\n",
    "try:\n",
    "    print(\"begin load deepspeed....\")    \n",
    "    model=deepspeed.init_inference(\n",
    "        model=getattr(model,\"model\", model),      # Transformers models\n",
    "        mp_size=1,        # Number of GPU\n",
    "        dtype=torch.float16, # dtype of the weights (fp16)\n",
    "        replace_method=\"auto\", # Lets DS autmatically identify the layer to replace\n",
    "        replace_with_kernel_inject=False, # replace the model with the kernel injector\n",
    "    )\n",
    "    print('model accelarate with deepspeed!')\n",
    "except Exception as e:\n",
    "    print(\"deepspeed accelarate excpetion!\")\n",
    "    print(e)\n",
    "    \n",
    "model = model.to(\"cuda\")\n",
    "model.enable_attention_slicing()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ef7462",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "988518bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import display\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# helper decoder\n",
    "def decode_base64_image(image_string):\n",
    "  base64_image = base64.b64decode(image_string)\n",
    "  buffer = BytesIO(base64_image)\n",
    "  return Image.open(buffer)\n",
    "\n",
    "# display PIL images as grid\n",
    "def display_images(images=None,columns=3, width=100, height=100):\n",
    "    plt.figure(figsize=(width, height))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(int(len(images) / columns + 1), columns, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80cb1171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e78b5331994183b765de377b7391f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_bucket_and_key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_bucket_and_key' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"A dog trying catch a flying pizza art drawn by disney concept artists, golden colour, high quality, highly detailed, elegant, sharp focus\"\n",
    "#prompt = \"portrait photo headshot by mucha, sharp focus, elegant, render, octane, detailed, award winning photography, masterpiece, rim lit\"\n",
    "#prompt = \"priest, blue robes, 68 year old nun, national geographic, portrait, photo, photography\"\n",
    "#prompt = \"hotel room with a swimming pool outside of the window, TV on the table, moon in the sky\"\n",
    "\n",
    "\n",
    "images = model(prompt, num_images_per_prompt=5, num_inference_steps=25, guidance_scale=9).images\n",
    "for image in images:\n",
    "   bucket, key = get_bucket_and_key(output_s3uri)\n",
    "   key = '{0}{1}.jpg'.format(key, uuid.uuid4())\n",
    "   buf = io.BytesIO()\n",
    "   image.save(buf, format='JPEG')\n",
    "   s3_client.put_object(\n",
    "       Body = buf.getvalue(), \n",
    "       Bucket = bucket, \n",
    "       Key = key, \n",
    "       ContentType = 'image/jpeg'\n",
    "   )\n",
    "   print('image: ', 's3://{0}/{1}'.format(bucket, key))\n",
    "\n",
    "# decode images\n",
    "decoded_images = [decode_base64_image(image) for image in response[\"generated_images\"]]\n",
    "\n",
    "# visualize generation\n",
    "display_images(decoded_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b34a868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
