{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7f8b9b-15ab-4384-ba77-8c2a285d259e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/svc-develop-team/so-vits-svc -b 4.1-Stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277d204d-1210-463c-9b88-9f45dd63fc89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd ./so-vits-svc && pip install --upgrade pip setuptools && pip install -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a1d7eb-c64c-4864-8d9c-5a5c912b1a5f",
   "metadata": {},
   "source": [
    "## dataset download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d68018-00de-4a30-8347-5e1dd783f0df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sovits_data_dir=\"/home/ec2-user/SageMaker/tts/so-vits-svc/\"  \n",
    "RAW_DIR=sovits_data_dir + \"raw/\"\n",
    "RESULTS_DIR=sovits_data_dir + \"results/\"\n",
    "FILELISTS_DIR=sovits_data_dir + \"filelists/\"\n",
    "CONFIGS_DIR=sovits_data_dir + \"configs/\"\n",
    "LOGS_DIR=sovits_data_dir + \"logs/44k/\"\n",
    "\n",
    "#!mkdir -p ${RAW_DIR}\"/speaker0\"\n",
    "#!mkdir -p ${RAW_DIR}\"/speaker1\"\n",
    "#\n",
    "#!aws s3 cp \"s3://sagemaker-us-west-2-687912291502/video/raw/.3aece165-a9b8-475e-9ae2-447520f47cf2.mp3\"  {RAW_DIR}\"speaker0/0001.wav\"\n",
    "#!aws s3 cp \"s3://sagemaker-us-west-2-687912291502/video/raw/.4f69647e-23d0-4efe-9dec-dc695224ee56.mp3\"  {RAW_DIR}\"speaker1/0001.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3ba21c-e2fd-4a79-ac36-4db1afc39679",
   "metadata": {},
   "source": [
    "## model download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1a5bad-cb36-4259-b3ae-2104c68e2f68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoder model\n",
    "#!aws s3 cp s3://sagemaker-us-west-2-687912291502/models/checkpoint_best_legacy_500.pt {sovits_data_dir}/pretrain/\n",
    "sovits_data_dir=\"/home/ec2-user/SageMaker/tts/so-vits-svc/\" \n",
    "!wget -P {sovits_data_dir}/pretrain/ https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/hubert_base.pt -O checkpoint_best_legacy_500.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64806a54-1420-4f06-a671-a074e01e3d3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pretrain model\n",
    "download_pretrained_model=True\n",
    "D_0_URL = \"https://huggingface.co/datasets/ms903/sovits4.0-768vec-layer12/resolve/main/sovits_768l12_pre_large_320k/clean_D_320000.pth\" #@param [\"https://huggingface.co/datasets/ms903/sovits4.0-768vec-layer12/resolve/main/sovits_768l12_pre_large_320k/clean_D_320000.pth\", \"https://huggingface.co/1asbgdh/sovits4.0-volemb-vec768/resolve/main/clean_D_320000.pth\", \"https://huggingface.co/datasets/ms903/sovits4.0-768vec-layer12/resolve/main/vol_emb/clean_D_320000.pth\"] {allow-input: true}\n",
    "G_0_URL = \"https://huggingface.co/datasets/ms903/sovits4.0-768vec-layer12/resolve/main/sovits_768l12_pre_large_320k/clean_G_320000.pth\" #@param [\"https://huggingface.co/datasets/ms903/sovits4.0-768vec-layer12/resolve/main/sovits_768l12_pre_large_320k/clean_G_320000.pth\", \"https://huggingface.co/1asbgdh/sovits4.0-volemb-vec768/resolve/main/clean_G_320000.pth\", \"https://huggingface.co/datasets/ms903/sovits4.0-768vec-layer12/resolve/main/vol_emb/clean_G_320000.pth\"] {allow-input: true}\n",
    "\n",
    "#download_pretrained_diffusion_model\n",
    "download_pretrained_diffusion_model=True\n",
    "diff_model_URL = \"https://huggingface.co/datasets/ms903/Diff-SVC-refactor-pre-trained-model/resolve/main/fix_pitch_add_vctk_600k/model_0.pt\" #@param {type:\"string\"}\n",
    "\n",
    "\n",
    "if download_pretrained_model:\n",
    "    !curl -L {D_0_URL} -o {sovits_data_dir}/logs/44k/D_0.pth\n",
    "    !curl -L {G_0_URL} -o {sovits_data_dir}/logs/44k/G_0.pth\n",
    "\n",
    "\n",
    "if download_pretrained_diffusion_model:\n",
    "    !mkdir -p logs/44k/diffusion\n",
    "    !curl -L {diff_model_URL} -o {sovits_data_dir}/logs/44k/diffusion/model_0.pt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a965ce-2e9e-4d5b-8cc8-43d6cce71638",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a76a2a-160a-4f96-97f8-19a00f8905d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ffmpeg -i {sovits_data_dir}/dataset_raw/speaker0/Brigida.wav -f segment -segment_time 60 -c copy out%03d.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bce0b5f0-3982-4cd9-9962-2e5a1d14fa20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU count: 8\n",
      "./dataset_raw/speaker0\n",
      "\u001b[2Kresampling: \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:00\u001b[0mm \u001b[36m0:00:01\u001b[0m\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 7530.17it/s]\n",
      "\u001b[32m2024-03-26 02:35:18.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mWriting ./filelists/train.txt\u001b[0m\n",
      "100%|█████████████████████████████████████████| 3/3 [00:00<00:00, 136770.78it/s]\n",
      "\u001b[32m2024-03-26 02:35:18.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mWriting ./filelists/val.txt\u001b[0m\n",
      "100%|██████████████████████████████████████████| 2/2 [00:00<00:00, 96420.78it/s]\n",
      "\u001b[32m2024-03-26 02:35:18.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m115\u001b[0m - \u001b[1mWriting to configs/config.json\u001b[0m\n",
      "\u001b[32m2024-03-26 02:35:18.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m118\u001b[0m - \u001b[1mWriting to configs/diffusion.yaml\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd ./so-vits-svc/ && rm -rf ./dataset_raw/.ipynb_checkpoints\n",
    "!cd ./so-vits-svc/ && python resample.py\n",
    "#\n",
    "##param [\"vec768l12\", \"vec256l9\", \"hubertsoft\", \"whisper-ppg\", \"whisper-ppg-large\"]\n",
    "speech_encoder=\"vec768l12\" \n",
    "use_vol_aug = False\n",
    "vol_aug = \"--vol_aug\" if use_vol_aug else \"\"\n",
    "#!cd ./so-vits-svc/ && python preprocess_flist_config.py --speech_encoder={speech_encoder} {vol_aug}\n",
    "!cd ./so-vits-svc/ && python preprocess_flist_config.py  --speech_encoder={speech_encoder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c32880-6f21-4847-987e-f263f9843192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tts model train：\n",
    "!cd ./so-vits-svc/ && python preprocess_hubert_f0.py --f0_predictor dio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b6e8b36-e056-41ed-a1ee-155dab60e230",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec768l12\n",
      "\u001b[32m2024-03-26 02:35:32.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mUsing device: cuda:0\u001b[0m\n",
      "\u001b[32m2024-03-26 02:35:32.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mUsing SpeechEncoder: vec768l12\u001b[0m\n",
      "\u001b[32m2024-03-26 02:35:32.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m154\u001b[0m - \u001b[1mUsing extractor: dio\u001b[0m\n",
      "\u001b[32m2024-03-26 02:35:32.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1mUsing diff Mode: True\u001b[0m\n",
      "use_diff\n",
      "Loading Mel Extractor...\n",
      "Loaded Mel Extractor.\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]\u001b[32m2024-03-26 02:35:35.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mprocess_batch\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mLoading speech encoder for content...\u001b[0m\n",
      "\u001b[32m2024-03-26 02:35:35.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mprocess_batch\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mRank 1 uses device cuda:0\u001b[0m\n",
      "2024-03-26 02:35:35.392852: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-26 02:35:35.392909: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-26 02:35:35.392936: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-26 02:35:35.399465: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-26 02:35:36.190344: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "load model(s) from pretrain/checkpoint_best_legacy_500.pt\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "\u001b[32m2024-03-26 02:35:40.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__mp_main__\u001b[0m:\u001b[36mprocess_batch\u001b[0m:\u001b[36m115\u001b[0m - \u001b[1mLoaded speech encoder for rank 1\u001b[0m\n",
      "\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/functional.py:660: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:874.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "\n",
      " 20%|█████████                                    | 1/5 [00:02<00:09,  2.29s/it]\u001b[A\n",
      " 40%|██████████████████                           | 2/5 [00:02<00:03,  1.03s/it]\u001b[A\n",
      " 60%|███████████████████████████                  | 3/5 [00:02<00:01,  1.30it/s]\u001b[A\n",
      " 80%|████████████████████████████████████         | 4/5 [00:03<00:00,  1.57it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:03<00:00,  1.34it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:11<00:00, 11.37s/it]\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "# for diffusion model train only:\n",
    "!cd ./so-vits-svc/ && python preprocess_hubert_f0.py --f0_predictor dio --use_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52714550-881d-4022-9a4e-a00022bec3c9",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c850f32-c632-4b01-abc9-a43fea010681",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_path = sovits_data_dir + \"./configs/config.json\"\n",
    "!cd ./so-vits-svc && python train.py -c {config_path} -m 44k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a97b49a-982f-4f11-8ae8-4ef29b8336f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cd ./so-vits-svc && python cluster/train_cluster.py --gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f767a3f-86df-4dfe-b7d3-ec2a2348f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cd /content/so-vits-svc && python train_index.py -c configs/config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fa3f61-534b-4dab-9b27-c4f08bfc5ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### optinal: train diffusion model\n",
    "%cd ./so-vits-svc\n",
    "\n",
    "import os\n",
    "if not os.path.exists(\"./pretrain/nsf_hifigan/model\"):\n",
    "  !curl -L https://github.com/openvpi/vocoders/releases/download/nsf-hifigan-v1/nsf_hifigan_20221211.zip -o nsf_hifigan_20221211.zip\n",
    "  !unzip nsf_hifigan_20221211.zip\n",
    "  !rm -rf pretrain/nsf_hifigan\n",
    "  !mv -v nsf_hifigan pretrain\n",
    "\n",
    "\n",
    "!python train_diff.py -c configs/diffusion.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7330576c-e8a2-4078-bb68-550b475b7f50",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "emb_g.weight is not in the checkpoint,please check your checkpoint.If you're using pretrain model,just ignore this warning.\n",
      "load \n",
      "2024-03-28 09:33:34.412764: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-28 09:33:34.412808: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-28 09:33:34.417666: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-28 09:33:34.854755: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-28 09:33:36.539098: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "load model(s) from pretrain/checkpoint_best_legacy_500.pt\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "#=====segment start, 8.808s======\n",
      "/home/ec2-user/SageMaker/tts/so-vits-svc/inference/infer_tool.py:270: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "vits use time:0.5179424285888672\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "## prediction\n",
    "!cd ./so-vits-svc && python inference_main.py -m \"logs/44k/G_10000.pth\" -c \"configs/config.json\" -n \"../../validate003.mp3\" -t 0 -s \"speaker0\" --f0_predictor dio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d3e869d-818f-46c4-ab6c-3efe3fe8c9bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Loading] logs/44k/diffusion/model_100000.pt\n",
      "Loaded diffusion model, sampler is dpm-solver++, speedup: 10 \n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "emb_g.weight is not in the checkpoint,please check your checkpoint.If you're using pretrain model,just ignore this warning.\n",
      "load \n",
      "2024-03-28 09:34:53.706036: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-28 09:34:53.706095: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-28 09:34:53.706120: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-28 09:34:53.712157: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-28 09:34:54.490119: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "load model(s) from pretrain/checkpoint_best_legacy_500.pt\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "#=====segment start, 8.808s======\n",
      "/home/ec2-user/SageMaker/tts/so-vits-svc/inference/infer_tool.py:270: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/functional.py:660: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:874.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "sample time step: 100%|█████████████████████████| 10/10 [00:00<00:00, 66.45it/s]\n",
      "| Load HifiGAN:  pretrain/nsf_hifigan/model\n",
      "Removing weight norm...\n",
      "vits use time:1.4355425834655762\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!cd ./so-vits-svc && python inference_main.py --loudness_envelope_adjustment 0.7 --shallow_diffusion --diffusion_model_path \"logs/44k/diffusion/model_100000.pt\" --diffusion_config_path \"logs/44k/diffusion/config.yaml\" -m \"logs/44k/G_10000.pth\" -c \"configs/config.json\" -n \"../../validate003.wav\" -t 0 -s \"speaker0\" --f0_predictor dio\n",
    "                                              #--use_spk_mix \\\n",
    "                                              #--only_diffusion \\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dc7e2b-767a-48a8-8976-99ef19405fbe",
   "metadata": {},
   "source": [
    "## webui startup for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28f3bf3-787e-466a-81ef-9ec74f71f1ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd ./so-vits-svc && python webUI.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06faea9d-9b3d-488b-a563-664808419331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
