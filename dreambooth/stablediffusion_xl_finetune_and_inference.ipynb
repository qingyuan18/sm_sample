{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9eb077",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1. 导入 boto3, sagemaker python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c01e0e-51e7-49c6-bfb7-e4dc3ae4b362",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8314fc9b-c468-497b-abcc-259ec792154c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.pytorch import PyTorch\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region_name = boto3.session.Session().region_name\n",
    "\n",
    "images_s3uri = 's3://{0}/dreambooth-xl/images/'.format(bucket)\n",
    "models_s3uri = 's3://{0}/stable-diffusion/models/'.format(bucket)\n",
    "dreambooth_s3uri = 's3://{0}/stable-diffusion/dreambooth/'.format(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a3178",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 2. 构建 xl fine-tuning 以及webui推理的docker 镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c49cae-3336-4e34-aefd-c53e396f7b04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p sd_xl_finetune_and_inference\n",
    "!cd sd_xl_finetune_and_inference && git clone https://github.com/huggingface/diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7612e5a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile Dockerfile_train_and_inference\n",
    "## You should change below region code to the region you used, here sample is use us-west-2\n",
    "\n",
    "From 763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04\n",
    "\n",
    "################ stable diffusion webui ##########################\n",
    "ENV DEBIAN_FRONTEND noninteractive\n",
    "ENV PATH=\"/opt/ml/code:${PATH}\"\n",
    "ENV PYTHONPATH=\"/opt/ml/code\"\n",
    "ENV COMMANDLINE_ARGS=\"--skip-torch-cuda-test\"\n",
    "\n",
    "# webui dependency packages\n",
    "RUN apt-get update && \\\n",
    "    apt-get install --assume-yes apt-utils vim wget git libgl1-mesa-glx -y && \\\n",
    "    rm -rf /var/lib/apt/lists/* && \\\n",
    "    pip install \\\n",
    "        opencv-python-headless \\\n",
    "        sagemaker-training \\\n",
    "        boto3 \\\n",
    "        uvicorn \\\n",
    "        sagemaker \\\n",
    "        diffusers==0.14.0 \\\n",
    "        accelerate==0.17.0 \\\n",
    "        controlnet_aux \\\n",
    "        wheel bitsandbytes \\\n",
    "        GPUtil \\\n",
    "        nvidia-ml-py \\\n",
    "        pynvml \\\n",
    "        clip-interrogator==0.6.0 \\\n",
    "        spacy \\\n",
    "        retrying \\\n",
    "        piexif \\\n",
    "        supervision==0.6.0 \\\n",
    "        roboflow \\\n",
    "        sagemaker-ssh-helper \\\n",
    "        chardet\n",
    "\n",
    "\n",
    "\n",
    "############ dreambooth fine tune #################################\n",
    "RUN pip install wandb\n",
    "  ##############xforms0.0.21以上，默认开启flash attention v2######\n",
    "RUN pip install xformers==0.0.21 --no-deps\n",
    "#RUN echo \"Y\"|pip uninstall torchvision\n",
    "#RUN pip install -U torchvision\n",
    "RUN pip install bitsandbytes\n",
    "  #############sagemaker 训练镜像torch版本较低（2.0.0），可以考虑升级到最新preview版本\n",
    "#RUN echo \"Y\"|pip uninstall torch\n",
    "#RUN echo \"Y\"|pip uninstall torchvision\n",
    "#RUN pip install --pre torch torchvision --index-url https://download.pytorch.org/whl/nightly/cu118\n",
    "\n",
    "\n",
    "ENV LANG=C.UTF-8\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "ENV PYTHONDONTWRITEBYTECODE=TRUE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d70d510-caf7-4b48-95d4-f9bc2eaa0648",
   "metadata": {},
   "source": [
    "* build & push docker镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f573e3c1-5e49-43cd-b71b-c858547192c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## You should change below region code to the region you used, here sample is use us-west-2\n",
    "!aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-west-2.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69253dd-850f-41b7-b57a-437273648a46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## define repo name, should contain *sagemaker* in the name\n",
    "repo_name = \"sd_xl_finetuning_and_inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a370fa-bdf7-47a6-892d-f05adcf5904c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%script env repo_name=$repo_name bash\n",
    "\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "# This script shows how to build the Docker image and push it to ECR to be ready for use\n",
    "# by SageMaker.\n",
    "\n",
    "# The argument to this script is the image name. This will be used as the image on the local\n",
    "# machine and combined with the account and region to form the repository name for ECR.\n",
    "# The name of our algorithm\n",
    "algorithm_name=${repo_name}\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${algorithm_name} -f ./Dockerfile_train_and_inference ./\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e01e5f-f53f-4443-a149-94d8c7126d8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "* 准备训练图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285d6076-0746-4afa-ba61-0d53f91bd67a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "local_dir = \"./dog\"\n",
    "snapshot_download(\n",
    "    \"diffusers/dog-example\",\n",
    "    local_dir=local_dir, repo_type=\"dataset\",\n",
    "    ignore_patterns=\".gitattributes\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f44953-ee8f-4b7a-bbfe-afad211b3224",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir sd_xl_finetune_and_inference && ./cp s5cmd ./sd_xl_finetune_and_inference/\n",
    "!chmod -R 777 ./sd_xl_finetune_and_inference\n",
    "!./sd_xl_finetune_and_inference/s5cmd sync ./dog/ $images_s3uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d843895",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "#### 3. 模型微调\n",
    "\n",
    "   * image_uri: ecr仓库中的 docker 镜像地址\n",
    "   * instance_type: 用于训练任务的实例大小 , 建议使用 ml.g4dn.xlarge, ml.g5.xlarge\n",
    "   * class_prompt: 提示词类别\n",
    "   * instance_prompt: 用于你的图片的关键词\n",
    "   * model_name: 预训练的模型名称\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720c66e8-8958-47f2-bfa7-c5252fde430e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./sd_xl_finetune_and_inference/train.sh\n",
    "export WANDB_API_KEY=\"298b59ce8a416fd45b5fa9ffc17fe72327854e0c\"\n",
    "export WANDB_WATCH=\"all\"\n",
    "export WANDB_PROJECT=\"sdxl-dreambooth\" \n",
    "\n",
    "mkdir -p /tmp/dog\n",
    "mkdir -p /tmp/output\n",
    "\n",
    "chmod 777 ./s5cmd\n",
    "\n",
    "\n",
    "cd diffusers && pip install -e .\n",
    "cd examples/dreambooth/ && pip install -r requirements_sdxl.txt\n",
    "\n",
    "cp -r /opt/ml/input/data/images/* /tmp/dog/\n",
    "ls -lt /tmp/dog/\n",
    "\n",
    "export MODEL_NAME=\"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "export INSTANCE_DIR=\"/tmp/dog/\"\n",
    "export OUTPUT_DIR=\"/tmp/ouput/\"\n",
    "#export OUTPUT_DIR=\"/opt/ml/model/\"\n",
    "export VAE_PATH=\"madebyollin/sdxl-vae-fp16-fix\"\n",
    "export dreambooth_s3uri=\"s3://sagemaker-us-west-2-687912291502/stable-diffusion/dreambooth/\"\n",
    "\n",
    "accelerate launch /opt/ml/code/diffusers/examples/dreambooth/train_dreambooth_lora_sdxl.py \\\n",
    "  --gradient_checkpointing \\\n",
    "  --use_8bit_adam \\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME  \\\n",
    "  --instance_data_dir=$INSTANCE_DIR \\\n",
    "  --pretrained_vae_model_name_or_path=$VAE_PATH \\\n",
    "  --output_dir=$OUTPUT_DIR \\\n",
    "  --instance_prompt=\"a photo of sks dog\" \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=2 \\\n",
    "  --learning_rate=1e-5 \\\n",
    "  --report_to=\"wandb\" \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --max_train_steps=100 \\\n",
    "  --validation_prompt=\"A photo of sks dog in a bucket\" \\\n",
    "  --validation_epochs=100 \\\n",
    "  --seed=\"0\" \\\n",
    "  #--mixed_precision=\"fp16\" \\\n",
    "  --enable_xformers_memory_efficient_attention\n",
    "\n",
    "echo \"train finished!\"\n",
    "\n",
    "ls -lt /tmp/output/\n",
    "/opt/ml/code/s5cmd sync /tmp/ouput/ $dreambooth_s3uri/output/$(date +%Y-%m-%d-%H-%M-%S)/\n",
    "\n",
    "echo \"upload finished!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da9775b-34e7-4589-87ba-50aa13539db0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./sd_xl_finetune_and_inference/start_sd_webui.py\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import io\n",
    "import base64\n",
    "from PIL import Image, PngImagePlugin\n",
    "from tenacity import retry, wait_exponential\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, filename='./webui.log', filemode='a')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@retry(wait=wait_exponential(multiplier=1, min=10, max=100))\n",
    "def check_server(server_url):\n",
    "    txt2img_url = server_url + \"/sdapi/v1/txt2img\"\n",
    "    data = {\n",
    "        'prompt': 'A photo of sks dog in a bucket',\n",
    "        'sampler_index': 'DPM++ SDE',\n",
    "        'seed': 1234,\n",
    "        'steps': 20,\n",
    "        'width': 512,\n",
    "        'height': 512,\n",
    "        'cfg_scale': 8\n",
    "    }\n",
    "    response = requests.post(txt2img_url, data=json.dumps(data),\n",
    "                             headers={\"Content-Type\": \"application/json\"})\n",
    "    response.raise_for_status()\n",
    "\n",
    "def start_stable_diffusion(server_url=\"http://0.0.0.0:7860\", log_file=\"./webui.log\"):\n",
    "    try:\n",
    "        with open(log_file, \"a\") as f:\n",
    "            process = subprocess.Popen(\n",
    "                [\"python\", \"/tmp/third-package/launch.py\",\"--port\" ,\"7860\", \n",
    "                 \"--xformers\", \"--api\", \"--listen\"],\n",
    "                stdout=f, stderr=subprocess.STDOUT, preexec_fn=os.setpgrp)\n",
    "        if process.returncode is not None:\n",
    "            raise RuntimeError(\"Failed to start stable diffusion process.\")\n",
    "        time.sleep(100)\n",
    "        check_server(server_url)\n",
    "        logger.info(\"stable diffusion server started.\")\n",
    "        return server_url\n",
    "    except Exception as error:\n",
    "        logger.error(f\"stable diffusion server failed, {error}\")\n",
    "        raise RuntimeError(\"Failed to start stable diffusion server or server not responding.\")\n",
    "        \n",
    "def txt2image():\n",
    "    server_url = \"http://0.0.0.0:7860\" \n",
    "    max_retries = 5\n",
    "    retry_count = 0\n",
    "    while retry_count < max_retries:\n",
    "      try:\n",
    "        txt2img_url = server_url + \"/sdapi/v1/txt2img\"\n",
    "        \n",
    "        data = {\n",
    "         'prompt': 'A photo of sks dog in a bucket',\n",
    "         'sampler_index': 'DPM++ SDE',\n",
    "         'seed': 1234,\n",
    "         'steps': 40,\n",
    "         'width': 512,\n",
    "         'height': 512,\n",
    "         'cfg_scale': 8\n",
    "        }\n",
    "  \n",
    "        response = requests.post(txt2img_url, data=json.dumps(data), headers={\"Content-Type\": \"application/json\"})\n",
    "        if response.status_code == 200:\n",
    "          logger.info(\"stable diffusion server inference successed.\")\n",
    "          return response\n",
    "      except Exception as error:\n",
    "        logger.error(f\"stable diffusion server inference failed, {error}\")\n",
    "        return None\n",
    "\n",
    "start_stable_diffusion()\n",
    "r=txt2image().json()\n",
    "for i in r['images']:\n",
    "    image = Image.open(io.BytesIO(base64.b64decode(i.split(\",\",1)[0])))\n",
    "    image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4185ee-d4f2-4db0-ac7c-bc9e11902d86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./sd_xl_finetune_and_inference/train_and_inference.sh\n",
    "\n",
    "chmod -R 777 /opt/ml/code/*\n",
    "##############sdxl dreambooth finetune#################### \n",
    "/opt/ml/code/train.sh\n",
    "\n",
    "\n",
    "##############webui startup & inference##################\n",
    "# clone webui code\n",
    "mkdir -p /tmp/third-package\n",
    "chmod -R 777 /tmp/third-package\n",
    "git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui /tmp/third-package/\n",
    "# copy fine tuned model\n",
    "#aws s3 cp s3://${bucket}/models/sd/sd_xl_base_1.0.safetensors /tmp/third-package/models/Stable-diffusion/\n",
    "#aws s3 cp s3://${bucket}/models/sd/sd_xl_base_1.0_0.9vae.safetensors /tmp/third-package/models/VAE/\n",
    "#cp -r /tmp/ouput/*  /tmp/third-package/models/Stable-diffusion/\n",
    "cp -r /tmp/ouput/ /tmp/third-package/models/Lora/\n",
    "\n",
    "cd /opt/ml/code/  && python start_sd_webui.py "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c569c81",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "   ### 创建训练及推理一体的任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e24897-18f6-4d13-a406-5eea3e2287a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## define repo name, should contain *sagemaker* in the name\n",
    "repo_name = \"sd_xl_finetuning_and_inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6535d22c-ab12-48c4-9989-5fabe4f31f69",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "\n",
    "environment = {\n",
    "    'PYTORCH_CUDA_ALLOC_CONF':'max_split_size_mb:32',\n",
    "    'bucket':bucket\n",
    "}\n",
    "\n",
    "## The image uri which is build and pushed above\n",
    "image_uri = \"{}.dkr.ecr.{}.amazonaws.com/{}:latest\".format(account_id, region_name, repo_name)\n",
    "base_job_name = 'sd-xl-dreambooth-finetuning-inference'\n",
    "instance_type = 'ml.g5.2xlarge'\n",
    "inputs = {\n",
    "    'images': f\"s3://{bucket}/dreambooth-xl/images/\"\n",
    "}\n",
    "\n",
    "estimator = PyTorch(role=role,\n",
    "                      entry_point='train_and_inference.sh',\n",
    "                      source_dir='./sd_xl_finetune_and_inference/',\n",
    "                      base_job_name=base_job_name,\n",
    "                      instance_count=1,\n",
    "                      instance_type=instance_type,\n",
    "                      image_uri=image_uri,\n",
    "                      environment=environment,\n",
    "                      keep_alive_period_in_seconds=3600, #warmpool，为下一次训练保持机器&镜像（滚动续期，最大1hour）；需要开quota。\n",
    "                      disable_profiler=True,\n",
    "                      debugger_hook_config=False,\n",
    "                      max_run=24*60*60*2)\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d8035b-2877-4ddd-89c3-9b4bf52b7ac9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 使用ssh helper 调试 trainning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9cfa20-a85a-49ad-9b3a-1a9387bd9ff9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sagemaker-ssh-helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfd4944-70e7-4b21-a3fb-a09a0831ea74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./sd_xl_finetune_and_inference/setup_ssm.sh\n",
    "SAGEMAKER_ROLE_ARN=arn:aws:iam::687912291502:role/service-role/AmazonSageMaker-ExecutionRole-20211013T113123\n",
    "ACCOUNT_ID=687912291502\n",
    "REGION=us-west-2\n",
    "\n",
    "pip install 'sagemaker-ssh-helper[cdk]'\n",
    "cdk bootstrap aws://\"$ACCOUNT_ID\"/\"$REGION\"\n",
    "APP=\"python -m sagemaker_ssh_helper.cdk.iam_ssm_app\"\n",
    "AWS_REGION=\"$REGION\" cdk -a \"$APP\" deploy SSH-IAM-SSM-Stack \\\n",
    "  -c sagemaker_role=\"$SAGEMAKER_ROLE_ARN\" \\\n",
    "  -c user_role=\"$USER_ROLE_ARN\"\n",
    "APP=\"python -m sagemaker_ssh_helper.cdk.advanced_tier_app\"\n",
    "AWS_REGION=\"$REGION\" cdk -a \"$APP\" deploy SSM-Advanced-Tier-Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4541bf-18f6-4a43-8dd4-8e2a9b42d285",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./sd_xl_finetune_and_inference/train_and_inference.py\n",
    "import sagemaker_ssh_helper\n",
    "sagemaker_ssh_helper.setup_and_start_ssh()\n",
    "\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import socket\n",
    "start_time = time.time()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    hosts = json.loads(os.environ['SM_HOSTS'])\n",
    "    current_host = os.environ['SM_CURRENT_HOST']\n",
    "\n",
    "    while True:\n",
    "       current_time = time.time()\n",
    "       if current_time - start_time >= 1200:\n",
    "           break\n",
    "    os.system(\"chmod +x ./s5cmd\")\n",
    "    os.system(\"/bin/bash train_and_inference.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1718b0f-8067-48ca-9a14-726a39bd88c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## define repo name, should contain *sagemaker* in the name\n",
    "repo_name = \"sd_xl_finetuning_and_inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe448378-7323-4a15-8225-9237cb439ad2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "from sagemaker_ssh_helper.wrapper import SSHEstimatorWrapper\n",
    "\n",
    "environment = {\n",
    "    'PYTORCH_CUDA_ALLOC_CONF':'max_split_size_mb:32'\n",
    "}\n",
    "\n",
    "## The image uri which is build and pushed above\n",
    "image_uri = \"{}.dkr.ecr.{}.amazonaws.com/{}:latest\".format(account_id, region_name, repo_name)\n",
    "base_job_name = 'sd-xl-dreambooth-finetuning-high'\n",
    "instance_type = 'ml.g5.4xlarge'\n",
    "inputs = {\n",
    "    'images': f\"s3://{bucket}/dreambooth-xl/images/\"\n",
    "}\n",
    "\n",
    "estimator = PyTorch(role=role,\n",
    "                      entry_point='train_and_inference.py',\n",
    "                      source_dir='./sd_xl_finetune_and_inference/',\n",
    "                      dependencies=[SSHEstimatorWrapper.dependency_dir()],\n",
    "                      base_job_name=base_job_name,\n",
    "                      instance_count=1,\n",
    "                      instance_type=instance_type,\n",
    "                      image_uri=image_uri,\n",
    "                      environment=environment,\n",
    "                      keep_alive_period_in_seconds=3600, #warmpool，为下一次训练保持机器&镜像（滚动续期，最大1hour）；需要开quota。\n",
    "                      disable_profiler=True,\n",
    "                      debugger_hook_config=False,\n",
    "                      max_run=24*60*60*2)\n",
    "\n",
    "ssh_wrapper = SSHEstimatorWrapper.create(estimator, connection_wait_time_seconds=600)  # <--NEW--\n",
    "estimator.fit(inputs,wait=False)\n",
    "print(f\"To connect over SSH run: sm-local-ssh-training connect {ssh_wrapper.training_job_name()}\")\n",
    "instance_ids = ssh_wrapper.get_instance_ids(timeout_in_sec=900)  # <--NEW-- \n",
    "print(f\"To connect over SSM run: aws ssm start-session --target {instance_ids[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd181b4e-f435-4dca-842a-444d083fdf3c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Model artifact saved at:\\n\", dreambooth_s3uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fd4c76-0748-41b1-ad60-4931e91c59e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
