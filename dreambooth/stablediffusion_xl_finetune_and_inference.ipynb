{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9eb077",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1. 导入 boto3, sagemaker python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8314fc9b-c468-497b-abcc-259ec792154c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.pytorch import PyTorch\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region_name = boto3.session.Session().region_name\n",
    "\n",
    "images_s3uri = 's3://{0}/dreambooth-xl/images/'.format(bucket)\n",
    "models_s3uri = 's3://{0}/stable-diffusion/models/'.format(bucket)\n",
    "dreambooth_s3uri = 's3://{0}/stable-diffusion/dreambooth/'.format(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a3178",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 2. 构建 xl fine-tuning 以及webui推理的docker 镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "15ea934d-0fe0-4d56-94ab-f5858a13385e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./sd_xl_base_1.0_0.9vae.safetensors to s3://sagemaker-us-west-2-687912291502/models/sd/sd_xl_base_1.0_0.9vae.safetensors\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp sd_xl_base_1.0_0.9vae.safetensors s3://$bucket/models/sd/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15c49cae-3336-4e34-aefd-c53e396f7b04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'diffusers'...\n",
      "remote: Enumerating objects: 40712, done.\u001b[K\n",
      "remote: Counting objects: 100% (521/521), done.\u001b[K\n",
      "remote: Compressing objects: 100% (281/281), done.\u001b[K\n",
      "remote: Total 40712 (delta 309), reused 360 (delta 193), pack-reused 40191\u001b[K\n",
      "Receiving objects: 100% (40712/40712), 27.09 MiB | 27.60 MiB/s, done.\n",
      "Resolving deltas: 100% (30104/30104), done.\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p sd_xl_finetune_and_inference\n",
    "!cd sd_xl_finetune_and_inference && git clone https://github.com/huggingface/diffusers\n",
    "#!rm -rf sd_xl_finetune_and_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7612e5a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile_train_and_inference\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile_train_and_inference\n",
    "## You should change below region code to the region you used, here sample is use us-west-2\n",
    "\n",
    "From 763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04\n",
    "\n",
    "################ stable diffusion webui ##########################\n",
    "ENV DEBIAN_FRONTEND noninteractive\n",
    "ENV PATH=\"/opt/ml/code:${PATH}\"\n",
    "ENV PYTHONPATH=\"/opt/ml/code\"\n",
    "ENV COMMANDLINE_ARGS=\"--skip-torch-cuda-test\"\n",
    "\n",
    "# webui dependency packages\n",
    "RUN apt-get update && \\\n",
    "    apt-get install --assume-yes apt-utils vim wget git libgl1-mesa-glx -y && \\\n",
    "    rm -rf /var/lib/apt/lists/* && \\\n",
    "    pip install \\\n",
    "        opencv-python-headless \\\n",
    "        sagemaker-training \\\n",
    "        boto3==1.26.64 \\\n",
    "        uvicorn \\\n",
    "        sagemaker \\\n",
    "        diffusers==0.14.0 \\\n",
    "        accelerate==0.17.0 \\\n",
    "        controlnet_aux \\\n",
    "        wheel bitsandbytes \\\n",
    "        GPUtil \\\n",
    "        nvidia-ml-py \\\n",
    "        pynvml \\\n",
    "        clip-interrogator==0.6.0 \\\n",
    "        spacy \\\n",
    "        retrying \\\n",
    "        piexif \\\n",
    "        supervision==0.6.0 \\\n",
    "        roboflow \\\n",
    "        sagemaker-ssh-helper \\\n",
    "        chardet\n",
    "\n",
    "\n",
    "\n",
    "############ dreambooth fine tune #################################\n",
    "RUN pip install wandb\n",
    "RUN pip install xformers==0.0.18\n",
    "RUN pip install bitsandbytes\n",
    "\n",
    "\n",
    "ENV LANG=C.UTF-8\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "ENV PYTHONDONTWRITEBYTECODE=TRUE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d70d510-caf7-4b48-95d4-f9bc2eaa0648",
   "metadata": {},
   "source": [
    "* build & push docker镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f573e3c1-5e49-43cd-b71b-c858547192c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "## You should change below region code to the region you used, here sample is use us-west-2\n",
    "!aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-west-2.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a69253dd-850f-41b7-b57a-437273648a46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## define repo name, should contain *sagemaker* in the name\n",
    "repo_name = \"sd_xl_finetuning_and_inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20a370fa-bdf7-47a6-892d-f05adcf5904c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  7.139GB\n",
      "Step 1/15 : From 763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04\n",
      " ---> 1f37d018af76\n",
      "Step 2/15 : ENV DEBIAN_FRONTEND noninteractive\n",
      " ---> Using cache\n",
      " ---> 7552e679a5da\n",
      "Step 3/15 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 3cb22f09900e\n",
      "Step 4/15 : ENV PYTHONPATH=\"/opt/ml/code\"\n",
      " ---> Using cache\n",
      " ---> 359dca05dd30\n",
      "Step 5/15 : ENV COMMANDLINE_ARGS=\"--skip-torch-cuda-test\"\n",
      " ---> Using cache\n",
      " ---> 0ce3d0d8d484\n",
      "Step 6/15 : RUN apt-get update &&     apt-get install --assume-yes apt-utils vim wget git libgl1-mesa-glx -y &&     rm -rf /var/lib/apt/lists/* &&     pip install         opencv-python-headless         sagemaker-training         boto3==1.26.64         uvicorn         sagemaker         diffusers==0.14.0         accelerate==0.17.0         controlnet_aux         wheel bitsandbytes         GPUtil         nvidia-ml-py         pynvml         clip-interrogator==0.6.0         spacy         retrying         piexif         supervision==0.6.0         roboflow         sagemaker-ssh-helper         chardet\n",
      " ---> Using cache\n",
      " ---> dc0f1f99d155\n",
      "Step 7/15 : RUN mkdir -p /tmp/third-package\n",
      " ---> Using cache\n",
      " ---> 9281ef651d83\n",
      "Step 8/15 : RUN chmod 755 /tmp/third-package\n",
      " ---> Using cache\n",
      " ---> cdb2486b2280\n",
      "Step 9/15 : RUN git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui /tmp/third-package\n",
      " ---> Using cache\n",
      " ---> 278bfcc5a32e\n",
      "Step 10/15 : RUN pip install wandb\n",
      " ---> Using cache\n",
      " ---> 0981aba563c5\n",
      "Step 11/15 : RUN pip install xformers==0.0.18\n",
      " ---> Using cache\n",
      " ---> ab6561afd0a0\n",
      "Step 12/15 : RUN pip install bitsandbytes\n",
      " ---> Using cache\n",
      " ---> 26b77da42c87\n",
      "Step 13/15 : ENV LANG=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> a5c0c9d63c0b\n",
      "Step 14/15 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 831209f5fc0e\n",
      "Step 15/15 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> d75344398bb8\n",
      "Successfully built d75344398bb8\n",
      "Successfully tagged sd_xl_finetuning_and_inference:latest\n",
      "The push refers to repository [687912291502.dkr.ecr.us-west-2.amazonaws.com/sd_xl_finetuning_and_inference]\n",
      "9a4449db1bfa: Preparing\n",
      "e0ac7498b3a5: Preparing\n",
      "071e679a9674: Preparing\n",
      "c0de9f64116b: Preparing\n",
      "6245fc265db5: Preparing\n",
      "34eddbe3fff6: Preparing\n",
      "d1aaf5ef4fde: Preparing\n",
      "ff37c276152d: Preparing\n",
      "a5ad883d9d7f: Preparing\n",
      "8403b2741d40: Preparing\n",
      "b8b2f58f17fe: Preparing\n",
      "0a86d2f63da9: Preparing\n",
      "e9149126e47f: Preparing\n",
      "81bcaebf20b7: Preparing\n",
      "b89ba47ef264: Preparing\n",
      "5e365e6e2026: Preparing\n",
      "30f10d0e1e2a: Preparing\n",
      "de6ad3f5baf9: Preparing\n",
      "8995be0bc275: Preparing\n",
      "34eddbe3fff6: Waiting\n",
      "7649740a6938: Preparing\n",
      "138718a88769: Preparing\n",
      "d1aaf5ef4fde: Waiting\n",
      "4c8ddbfabe2c: Preparing\n",
      "e11d715889d8: Preparing\n",
      "d2516bd9d454: Preparing\n",
      "ff37c276152d: Waiting\n",
      "ab91cb17a698: Preparing\n",
      "375dafba5be7: Preparing\n",
      "a5ad883d9d7f: Waiting\n",
      "eb2d5581a4b3: Preparing\n",
      "6e5ea4d3b078: Preparing\n",
      "8403b2741d40: Waiting\n",
      "a83e3f8647a8: Preparing\n",
      "629205717bfa: Preparing\n",
      "91962ccfdb56: Preparing\n",
      "e42093c82aca: Preparing\n",
      "88f627f04385: Preparing\n",
      "53d4ef0348b1: Preparing\n",
      "7dec9be1e6de: Preparing\n",
      "1c442bf32dda: Preparing\n",
      "7a4317d0452c: Preparing\n",
      "569b5fc6f9ba: Preparing\n",
      "16acfff66e41: Preparing\n",
      "b8b2f58f17fe: Waiting\n",
      "c2440becfb6e: Preparing\n",
      "93dc2ad27ff8: Preparing\n",
      "30f10d0e1e2a: Waiting\n",
      "3b6112f80af1: Preparing\n",
      "1be54c625d9b: Preparing\n",
      "0a86d2f63da9: Waiting\n",
      "5d4d8e450a3a: Preparing\n",
      "aed2d71a436d: Preparing\n",
      "de6ad3f5baf9: Waiting\n",
      "e9149126e47f: Waiting\n",
      "e11d715889d8: Waiting\n",
      "7af37e3e56a9: Preparing\n",
      "b89ba47ef264: Waiting\n",
      "e5167e76bf1b: Preparing\n",
      "81bcaebf20b7: Waiting\n",
      "d2516bd9d454: Waiting\n",
      "a490a70ab1cd: Preparing\n",
      "8995be0bc275: Waiting\n",
      "b3c248c52364: Preparing\n",
      "5e365e6e2026: Waiting\n",
      "d543b8cad89e: Preparing\n",
      "ab91cb17a698: Waiting\n",
      "6e5ea4d3b078: Waiting\n",
      "629205717bfa: Waiting\n",
      "7649740a6938: Waiting\n",
      "a83e3f8647a8: Waiting\n",
      "375dafba5be7: Waiting\n",
      "4c8ddbfabe2c: Waiting\n",
      "eb2d5581a4b3: Waiting\n",
      "138718a88769: Waiting\n",
      "91962ccfdb56: Waiting\n",
      "93dc2ad27ff8: Waiting\n",
      "7af37e3e56a9: Waiting\n",
      "5d4d8e450a3a: Waiting\n",
      "e42093c82aca: Waiting\n",
      "b3c248c52364: Waiting\n",
      "3b6112f80af1: Waiting\n",
      "16acfff66e41: Waiting\n",
      "e5167e76bf1b: Waiting\n",
      "d543b8cad89e: Waiting\n",
      "88f627f04385: Waiting\n",
      "7a4317d0452c: Waiting\n",
      "1be54c625d9b: Waiting\n",
      "569b5fc6f9ba: Waiting\n",
      "1c442bf32dda: Waiting\n",
      "c2440becfb6e: Waiting\n",
      "c0de9f64116b: Layer already exists\n",
      "9a4449db1bfa: Layer already exists\n",
      "071e679a9674: Layer already exists\n",
      "e0ac7498b3a5: Layer already exists\n",
      "6245fc265db5: Layer already exists\n",
      "34eddbe3fff6: Layer already exists\n",
      "d1aaf5ef4fde: Layer already exists\n",
      "a5ad883d9d7f: Layer already exists\n",
      "ff37c276152d: Layer already exists\n",
      "8403b2741d40: Layer already exists\n",
      "b8b2f58f17fe: Layer already exists\n",
      "e9149126e47f: Layer already exists\n",
      "b89ba47ef264: Layer already exists\n",
      "0a86d2f63da9: Layer already exists\n",
      "81bcaebf20b7: Layer already exists\n",
      "5e365e6e2026: Layer already exists\n",
      "30f10d0e1e2a: Layer already exists\n",
      "de6ad3f5baf9: Layer already exists\n",
      "7649740a6938: Layer already exists\n",
      "8995be0bc275: Layer already exists\n",
      "138718a88769: Layer already exists\n",
      "4c8ddbfabe2c: Layer already exists\n",
      "e11d715889d8: Layer already exists\n",
      "d2516bd9d454: Layer already exists\n",
      "ab91cb17a698: Layer already exists\n",
      "375dafba5be7: Layer already exists\n",
      "eb2d5581a4b3: Layer already exists\n",
      "6e5ea4d3b078: Layer already exists\n",
      "a83e3f8647a8: Layer already exists\n",
      "629205717bfa: Layer already exists\n",
      "91962ccfdb56: Layer already exists\n",
      "88f627f04385: Layer already exists\n",
      "e42093c82aca: Layer already exists\n",
      "7dec9be1e6de: Layer already exists\n",
      "53d4ef0348b1: Layer already exists\n",
      "1c442bf32dda: Layer already exists\n",
      "7a4317d0452c: Layer already exists\n",
      "16acfff66e41: Layer already exists\n",
      "569b5fc6f9ba: Layer already exists\n",
      "93dc2ad27ff8: Layer already exists\n",
      "c2440becfb6e: Layer already exists\n",
      "5d4d8e450a3a: Layer already exists\n",
      "3b6112f80af1: Layer already exists\n",
      "1be54c625d9b: Layer already exists\n",
      "aed2d71a436d: Layer already exists\n",
      "e5167e76bf1b: Layer already exists\n",
      "7af37e3e56a9: Layer already exists\n",
      "a490a70ab1cd: Layer already exists\n",
      "b3c248c52364: Layer already exists\n",
      "d543b8cad89e: Layer already exists\n",
      "latest: digest: sha256:36d775eb022baee1768df36c08ad9257eedfe734a8d7c043ed6ba17de464ded2 size: 10836\n"
     ]
    }
   ],
   "source": [
    "%%script env repo_name=$repo_name bash\n",
    "\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "# This script shows how to build the Docker image and push it to ECR to be ready for use\n",
    "# by SageMaker.\n",
    "\n",
    "# The argument to this script is the image name. This will be used as the image on the local\n",
    "# machine and combined with the account and region to form the repository name for ECR.\n",
    "# The name of our algorithm\n",
    "algorithm_name=${repo_name}\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${algorithm_name} -f ./Dockerfile_train_and_inference ./\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e01e5f-f53f-4443-a149-94d8c7126d8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "* 准备训练图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "285d6076-0746-4afa-ba61-0d53f91bd67a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f39eb239b444c479d53114aa705a461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/sd_xl/dog'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "local_dir = \"./dog\"\n",
    "snapshot_download(\n",
    "    \"diffusers/dog-example\",\n",
    "    local_dir=local_dir, repo_type=\"dataset\",\n",
    "    ignore_patterns=\".gitattributes\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c9f44953-ee8f-4b7a-bbfe-afad211b3224",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘sd_xl_finetune_and_inference’: File exists\n",
      "cp dog/alvan-nee-bQaAJCbNq3g-unsplash.jpeg s3://sagemaker-us-west-2-687912291502/dreambooth-xl/images/alvan-nee-bQaAJCbNq3g-unsplash.jpeg\n",
      "cp dog/alvan-nee-9M0tSjb-cpA-unsplash.jpeg s3://sagemaker-us-west-2-687912291502/dreambooth-xl/images/alvan-nee-9M0tSjb-cpA-unsplash.jpeg\n",
      "cp dog/alvan-nee-eoqnr8ikwFE-unsplash.jpeg s3://sagemaker-us-west-2-687912291502/dreambooth-xl/images/alvan-nee-eoqnr8ikwFE-unsplash.jpeg\n",
      "cp dog/alvan-nee-Id1DBHv4fbg-unsplash.jpeg s3://sagemaker-us-west-2-687912291502/dreambooth-xl/images/alvan-nee-Id1DBHv4fbg-unsplash.jpeg\n",
      "cp dog/alvan-nee-brFsZ7qszSY-unsplash.jpeg s3://sagemaker-us-west-2-687912291502/dreambooth-xl/images/alvan-nee-brFsZ7qszSY-unsplash.jpeg\n"
     ]
    }
   ],
   "source": [
    "!mkdir sd_xl_finetune_and_inference && ./cp s5cmd ./sd_xl_finetune_and_inference/\n",
    "!chmod -R 777 ./sd_xl_finetune_and_inference\n",
    "!./sd_xl_finetune_and_inference/s5cmd sync ./dog/ $images_s3uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d843895",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "#### 3. 模型微调\n",
    "\n",
    "   * image_uri: ecr仓库中的 docker 镜像地址\n",
    "   * instance_type: 用于训练任务的实例大小 , 建议使用 ml.g4dn.xlarge, ml.g5.xlarge\n",
    "   * class_prompt: 提示词类别\n",
    "   * instance_prompt: 用于你的图片的关键词\n",
    "   * model_name: 预训练的模型名称\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db67efa4-9ad4-4735-9d70-818bc807a3c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!./s5cmd sync s3://sagemaker-us-west-2-687912291502/models/sd/* /tmp/third-package/models/Stable-diffusion/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "720c66e8-8958-47f2-bfa7-c5252fde430e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./sd_xl_finetune_and_inference/train.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./sd_xl_finetune_and_inference/train.sh\n",
    "\n",
    "\n",
    "mkdir -p /tmp/dog\n",
    "ls -lt ./\n",
    "chmod 777 ./s5cmd\n",
    "\n",
    "\n",
    "cd diffusers && pip install -e .\n",
    "cd examples/dreambooth/ && pip install -r requirements_sdxl.txt\n",
    "\n",
    "cp -r /opt/ml/input/data/images/* /tmp/dog/\n",
    "\n",
    "export MODEL_NAME=\"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "export INSTANCE_DIR=\"/tmp/dog/\"\n",
    "export OUTPUT_DIR=\"/tmp/ouput\"\n",
    "#export OUTPUT_DIR=\"/opt/ml/model/\"\n",
    "export VAE_PATH=\"madebyollin/sdxl-vae-fp16-fix\"\n",
    "export dreambooth_s3uri=\"s3://sagemaker-us-west-2-687912291502/stable-diffusion/dreambooth/\"\n",
    "\n",
    "accelerate launch /opt/ml/code/diffusers/examples/dreambooth/train_dreambooth_lora_sdxl.py \\\n",
    "  --gradient_checkpointing \\\n",
    "  --use_8bit_adam \\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME  \\\n",
    "  --instance_data_dir=$INSTANCE_DIR \\\n",
    "  --pretrained_vae_model_name_or_path=$VAE_PATH \\\n",
    "  --output_dir=$OUTPUT_DIR \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --instance_prompt=\"a photo of sks dog\" \\\n",
    "  --resolution=1024 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --learning_rate=1e-5 \\\n",
    "  --report_to=\"wandb\" \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --max_train_steps=500 \\\n",
    "  --validation_prompt=\"A photo of sks dog in a bucket\" \\\n",
    "  --validation_epochs=25 \\\n",
    "  --seed=\"0\" \\\n",
    "  --enable_xformers_memory_efficient_attention\n",
    "\n",
    "/opt/ml/code/s5cmd sync /tmp/ouput/ $dreambooth_s3uri/output/$(date +%Y-%m-%d-%H-%M-%S)/\n",
    "\n",
    "####在shell中拷贝webui需要的模型文件############\n",
    "aws s3 cp s3://${bucket}/models/sd/sd_xl_base_1.0.safetensors /tmp/third-package/models/Stable-diffusion/\n",
    "aws s3 cp s3://${bucket}/models/sd/sd_xl_base_1.0_0.9vae.safetensors /tmp/third-package/models/VAE/\n",
    "cp -R /tmp/ouput/*  /tmp/third-package/models/Stable-diffusion/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4da9775b-34e7-4589-87ba-50aa13539db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./sd_xl_finetune_and_inference/start_sd_webui.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./sd_xl_finetune_and_inference/start_sd_webui.py\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "from tenacity import retry, wait_exponential\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, filename='./webui.log', filemode='a')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@retry(wait=wait_exponential(multiplier=1, min=10, max=100), stop=stop_after_attempt(5))\n",
    "def check_server(server_url):\n",
    "    txt2img_url = server_url + \"/sdapi/v1/txt2img\"\n",
    "    data = {\n",
    "        'prompt': 'A photo of sks dog in a bucket',\n",
    "        'sampler_index': 'DPM++ SDE',\n",
    "        'seed': 1234,\n",
    "        'steps': 20,\n",
    "        'width': 512,\n",
    "        'height': 512,\n",
    "        'cfg_scale': 8\n",
    "    }\n",
    "    response = requests.post(txt2img_url, data=json.dumps(data),\n",
    "                             headers={\"Content-Type\": \"application/json\"})\n",
    "    response.raise_for_status()\n",
    "\n",
    "def start_stable_diffusion(server_url=\"http://0.0.0.0:7860\", log_file=\"./webui.log\"):\n",
    "    try:\n",
    "        with open(log_file, \"a\") as f:\n",
    "            process = subprocess.Popen(\n",
    "                [\"python\", \"/tmp/third-package/launch.py\",\"--port\" ,\"8080\", \n",
    "                 \"--xformers\", \"--api\", \"--listen\"],\n",
    "                stdout=f, stderr=subprocess.STDOUT, preexec_fn=os.setpgrp)\n",
    "        if process.returncode is not None:\n",
    "            raise RuntimeError(\"Failed to start stable diffusion process.\")\n",
    "        time.sleep(100)\n",
    "        check_server(server_url)\n",
    "        logger.info(\"stable diffusion server started.\")\n",
    "        return server_url\n",
    "    except Exception as error:\n",
    "        logger.error(f\"stable diffusion server failed, {error}\")\n",
    "        raise RuntimeError(\"Failed to start stable diffusion server or server not responding.\")\n",
    "        \n",
    "def txt2image():\n",
    "    server_url = \"http://0.0.0.0:7860\" \n",
    "    max_retries = 5\n",
    "    retry_count = 0\n",
    "    while retry_count < max_retries:\n",
    "      try:\n",
    "        txt2img_url = server_url + \"/sdapi/v1/txt2img\"\n",
    "        \n",
    "        data = {\n",
    "         'prompt': 'A photo of sks dog in a bucket',\n",
    "         'sampler_index': 'DPM++ SDE',\n",
    "         'seed': 1234,\n",
    "         'steps': 20,\n",
    "         'width': 512,\n",
    "         'height': 512,\n",
    "         'cfg_scale': 8\n",
    "        }\n",
    "  \n",
    "      response = requests.post(txt2img_url, data=json.dumps(data), headers={\"Content-Type\": \"application/json\"})\n",
    "      if response.status_code == 200:\n",
    "        log_and_raise(\"info\", \"stable diffusion server started.\")\n",
    "        return server_url\n",
    "      except Exception as error:\n",
    "        log_and_raise(\"error\", f\"stable diffusion server failed, {error}\")\n",
    "\n",
    "start_stable_diffusion()\n",
    "txt2image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef4185ee-d4f2-4db0-ac7c-bc9e11902d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./sd_xl_finetune_and_inference/train_and_inference.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./sd_xl_finetune_and_inference/train_and_inference.sh\n",
    "\n",
    "sudo chmod -R 777 /opt/ml/code/*\n",
    "##############sdxl dreambooth finetune#################### \n",
    "/opt/ml/code/train.sh \n",
    "/opt/ml/code/s5cmd sync /tmp/ouput/ $dreambooth_s3uri/output/$(date +%Y-%m-%d-%H-%M-%S)/\n",
    "\n",
    "##############webui startup & inference##################\n",
    "# clone webui code并copy到docker内\n",
    "mkdir -p /tmp/third-package\n",
    "chmod 755 /tmp/third-package\n",
    "\n",
    "git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui /tmp/third-package/\n",
    "cd /opt/ml/code/  && python start_sd_webui.py "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c569c81",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "   ### 创建训练及推理一体的任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41e24897-18f6-4d13-a406-5eea3e2287a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## define repo name, should contain *sagemaker* in the name\n",
    "repo_name = \"sd_xl_finetuning_and_inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6535d22c-ab12-48c4-9989-5fabe4f31f69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "\n",
    "environment = {\n",
    "    'PYTORCH_CUDA_ALLOC_CONF':'max_split_size_mb:32',\n",
    "    'bucket':bucket\n",
    "}\n",
    "\n",
    "## The image uri which is build and pushed above\n",
    "image_uri = \"{}.dkr.ecr.{}.amazonaws.com/{}:latest\".format(account_id, region_name, repo_name)\n",
    "base_job_name = 'sd-xl-dreambooth-finetuning-high'\n",
    "instance_type = 'ml.g5.2xlarge'\n",
    "inputs = {\n",
    "    'images': f\"s3://{bucket}/dreambooth-xl/images/\"\n",
    "}\n",
    "\n",
    "estimator = PyTorch(role=role,\n",
    "                      entry_point='train_and_inference.sh',\n",
    "                      source_dir='./sd_xl_finetune_and_inference/',\n",
    "                      base_job_name=base_job_name,\n",
    "                      instance_count=1,\n",
    "                      instance_type=instance_type,\n",
    "                      image_uri=image_uri,\n",
    "                      environment=environment,\n",
    "                      keep_alive_period_in_seconds=3600, #warmpool，为下一次训练保持机器&镜像（滚动续期，最大1hour）；需要开quota。\n",
    "                      disable_profiler=True,\n",
    "                      debugger_hook_config=False,\n",
    "                      max_run=24*60*60*2)\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d8035b-2877-4ddd-89c3-9b4bf52b7ac9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 使用ssh helper 调试 trainning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcfd4944-70e7-4b21-a3fb-a09a0831ea74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./sd_xl_finetune_and_inference/setup_ssm.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./sd_xl_finetune_and_inference/setup_ssm.sh\n",
    "SAGEMAKER_ROLE_ARN=arn:aws:iam::687912291502:role/service-role/AmazonSageMaker-ExecutionRole-20211013T113123\n",
    "ACCOUNT_ID=687912291502\n",
    "REGION=us-west-2\n",
    "\n",
    "pip install 'sagemaker-ssh-helper[cdk]'\n",
    "cdk bootstrap aws://\"$ACCOUNT_ID\"/\"$REGION\"\n",
    "APP=\"python -m sagemaker_ssh_helper.cdk.iam_ssm_app\"\n",
    "AWS_REGION=\"$REGION\" cdk -a \"$APP\" deploy SSH-IAM-SSM-Stack \\\n",
    "  -c sagemaker_role=\"$SAGEMAKER_ROLE_ARN\" \\\n",
    "  -c user_role=\"$USER_ROLE_ARN\"\n",
    "APP=\"python -m sagemaker_ssh_helper.cdk.advanced_tier_app\"\n",
    "AWS_REGION=\"$REGION\" cdk -a \"$APP\" deploy SSM-Advanced-Tier-Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc4541bf-18f6-4a43-8dd4-8e2a9b42d285",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./sd_xl_finetune_and_inference/train_and_inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./sd_xl_finetune_and_inference/train_and_inference.py\n",
    "import sagemaker_ssh_helper\n",
    "sagemaker_ssh_helper.setup_and_start_ssh()\n",
    "\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import socket\n",
    "start_time = time.time()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    hosts = json.loads(os.environ['SM_HOSTS'])\n",
    "    current_host = os.environ['SM_CURRENT_HOST']\n",
    "\n",
    "    while True:\n",
    "       current_time = time.time()\n",
    "       if current_time - start_time >= 1200:\n",
    "           break\n",
    "    os.system(\"chmod +x ./s5cmd\")\n",
    "    os.system(\"/bin/bash train_and_inference.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1718b0f-8067-48ca-9a14-726a39bd88c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## define repo name, should contain *sagemaker* in the name\n",
    "repo_name = \"sd_xl_finetuning_and_inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe448378-7323-4a15-8225-9237cb439ad2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "from sagemaker_ssh_helper.wrapper import SSHEstimatorWrapper\n",
    "\n",
    "environment = {\n",
    "    'PYTORCH_CUDA_ALLOC_CONF':'max_split_size_mb:32'\n",
    "}\n",
    "\n",
    "## The image uri which is build and pushed above\n",
    "image_uri = \"{}.dkr.ecr.{}.amazonaws.com/{}:latest\".format(account_id, region_name, repo_name)\n",
    "base_job_name = 'sd-xl-dreambooth-finetuning-high'\n",
    "instance_type = 'ml.g5.4xlarge'\n",
    "inputs = {\n",
    "    'images': f\"s3://{bucket}/dreambooth-xl/images/\"\n",
    "}\n",
    "\n",
    "estimator = PyTorch(role=role,\n",
    "                      entry_point='train_and_inference.py',\n",
    "                      source_dir='./sd_xl_finetune_and_inference/',\n",
    "                      dependencies=[SSHEstimatorWrapper.dependency_dir()],\n",
    "                      base_job_name=base_job_name,\n",
    "                      instance_count=1,\n",
    "                      instance_type=instance_type,\n",
    "                      image_uri=image_uri,\n",
    "                      environment=environment,\n",
    "                      keep_alive_period_in_seconds=3600, #warmpool，为下一次训练保持机器&镜像（滚动续期，最大1hour）；需要开quota。\n",
    "                      disable_profiler=True,\n",
    "                      debugger_hook_config=False,\n",
    "                      max_run=24*60*60*2)\n",
    "\n",
    "ssh_wrapper = SSHEstimatorWrapper.create(estimator, connection_wait_time_seconds=600)  # <--NEW--\n",
    "estimator.fit(inputs,wait=False)\n",
    "print(f\"To connect over SSH run: sm-local-ssh-training connect {ssh_wrapper.training_job_name()}\")\n",
    "instance_ids = ssh_wrapper.get_instance_ids(timeout_in_sec=900)  # <--NEW-- \n",
    "print(f\"To connect over SSM run: aws ssm start-session --target {instance_ids[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd181b4e-f435-4dca-842a-444d083fdf3c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model artifact saved at:\n",
      " s3://sagemaker-us-west-2-687912291502/stable-diffusion/dreambooth/\n"
     ]
    }
   ],
   "source": [
    "print(\"Model artifact saved at:\\n\", dreambooth_s3uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fd4c76-0748-41b1-ad60-4931e91c59e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
