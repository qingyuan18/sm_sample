{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8314fc9b-c468-497b-abcc-259ec792154c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.pytorch import PyTorch\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region_name = boto3.session.Session().region_name\n",
    "images_s3uri = 's3://{0}/dreambooth/images/'.format(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "516418fb-5755-4e40-b0df-ca80c085067e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-25 09:08:22--  https://d1xkebsgyt7kzd.cloudfront.net/R_1.jpg\n",
      "Resolving d1xkebsgyt7kzd.cloudfront.net (d1xkebsgyt7kzd.cloudfront.net)... 54.230.125.156, 54.230.125.99, 54.230.125.217, ...\n",
      "Connecting to d1xkebsgyt7kzd.cloudfront.net (d1xkebsgyt7kzd.cloudfront.net)|54.230.125.156|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 38281 (37K) [image/jpeg]\n",
      "Saving to: ‘R_1.jpg’\n",
      "\n",
      "100%[======================================>] 38,281      --.-K/s   in 0.002s  \n",
      "\n",
      "2023-04-25 09:08:22 (23.2 MB/s) - ‘R_1.jpg’ saved [38281/38281]\n",
      "\n",
      "--2023-04-25 09:08:22--  https://d1xkebsgyt7kzd.cloudfront.net/R_2.jpg\n",
      "Resolving d1xkebsgyt7kzd.cloudfront.net (d1xkebsgyt7kzd.cloudfront.net)... 54.230.125.73, 54.230.125.217, 54.230.125.99, ...\n",
      "Connecting to d1xkebsgyt7kzd.cloudfront.net (d1xkebsgyt7kzd.cloudfront.net)|54.230.125.73|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 33919 (33K) [image/jpeg]\n",
      "Saving to: ‘R_2.jpg’\n",
      "\n",
      "100%[======================================>] 33,919      --.-K/s   in 0.001s  \n",
      "\n",
      "2023-04-25 09:08:22 (26.9 MB/s) - ‘R_2.jpg’ saved [33919/33919]\n",
      "\n",
      "--2023-04-25 09:08:22--  https://d1xkebsgyt7kzd.cloudfront.net/R_3.jpg\n",
      "Resolving d1xkebsgyt7kzd.cloudfront.net (d1xkebsgyt7kzd.cloudfront.net)... 54.230.125.156, 54.230.125.73, 54.230.125.217, ...\n",
      "Connecting to d1xkebsgyt7kzd.cloudfront.net (d1xkebsgyt7kzd.cloudfront.net)|54.230.125.156|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 118319 (116K) [image/jpeg]\n",
      "Saving to: ‘R_3.jpg’\n",
      "\n",
      "100%[======================================>] 118,319     --.-K/s   in 0.01s   \n",
      "\n",
      "2023-04-25 09:08:22 (10.2 MB/s) - ‘R_3.jpg’ saved [118319/118319]\n",
      "\n",
      "--2023-04-25 09:08:22--  https://d1xkebsgyt7kzd.cloudfront.net/R_4.jpg\n",
      "Resolving d1xkebsgyt7kzd.cloudfront.net (d1xkebsgyt7kzd.cloudfront.net)... 54.230.125.99, 54.230.125.156, 54.230.125.73, ...\n",
      "Connecting to d1xkebsgyt7kzd.cloudfront.net (d1xkebsgyt7kzd.cloudfront.net)|54.230.125.99|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 88012 (86K) [image/jpeg]\n",
      "Saving to: ‘R_4.jpg’\n",
      "\n",
      "100%[======================================>] 88,012      --.-K/s   in 0.007s  \n",
      "\n",
      "2023-04-25 09:08:22 (12.3 MB/s) - ‘R_4.jpg’ saved [88012/88012]\n",
      "\n",
      "--2023-04-25 09:08:23--  https://d1xkebsgyt7kzd.cloudfront.net/R_5.jpg\n",
      "Resolving d1xkebsgyt7kzd.cloudfront.net (d1xkebsgyt7kzd.cloudfront.net)... 54.230.125.217, 54.230.125.99, 54.230.125.156, ...\n",
      "Connecting to d1xkebsgyt7kzd.cloudfront.net (d1xkebsgyt7kzd.cloudfront.net)|54.230.125.217|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 334713 (327K) [image/jpeg]\n",
      "Saving to: ‘R_5.jpg’\n",
      "\n",
      "100%[======================================>] 334,713     --.-K/s   in 0.02s   \n",
      "\n",
      "2023-04-25 09:08:23 (13.3 MB/s) - ‘R_5.jpg’ saved [334713/334713]\n",
      "\n",
      "upload: images/R_4.jpg to s3://sagemaker-us-west-2-687912291502/dreambooth/images/R_4.jpg\n",
      "upload: images/R_3.jpg to s3://sagemaker-us-west-2-687912291502/dreambooth/images/R_3.jpg\n",
      "upload: images/R_2.jpg to s3://sagemaker-us-west-2-687912291502/dreambooth/images/R_2.jpg\n",
      "upload: images/R_1.jpg to s3://sagemaker-us-west-2-687912291502/dreambooth/images/R_1.jpg\n",
      "upload: images/R_5.jpg to s3://sagemaker-us-west-2-687912291502/dreambooth/images/R_5.jpg\n"
     ]
    }
   ],
   "source": [
    "imgs=\"https://d1xkebsgyt7kzd.cloudfront.net/R_1.jpg,https://d1xkebsgyt7kzd.cloudfront.net/R_2.jpg,https://d1xkebsgyt7kzd.cloudfront.net/R_3.jpg,https://d1xkebsgyt7kzd.cloudfront.net/R_4.jpg,https://d1xkebsgyt7kzd.cloudfront.net/R_5.jpg\"\n",
    "for image in imgs.split(\",\"):\n",
    "    !wget $image\n",
    "!mv ./*.jpg ./images/\n",
    "!aws s3 cp images $images_s3uri --recursive    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf52509-8df2-4e35-96ca-0c5738f09887",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 与webui绑定的training BYOC#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09ff0467-9f0a-4c42-8af4-7b3db7f7ccc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1:model_name: str = \"\",\\n2:adam_beta1: float = 0.9,\\n3:adam_beta2: float = 0.999,\\n4:adam_epsilon: float = 1e-8,\\n5:adam_weight_decay: float = 0.01,\\n6:attention: str = \"default\",\\n7:center_crop: bool = True,\\n8:concepts_path: str = \"\",\\n9:custom_model_name: str = \"\",\\n10:epoch_pause_frequency: int = 0,\\n11:epoch_pause_time: int = 0,\\n12:gradient_accumulation_steps: int = 1,\\n13:gradient_checkpointing: bool = True,\\n14:half_model: bool = False,\\n15:has_ema: bool = False,\\n16:hflip: bool = False,\\n17:learning_rate: float = 0.00000172,\\n18:lora_learning_rate: float = 1e-4,\\n19:lora_txt_learning_rate: float = 5e-5,\\n20:lr_scheduler: str = \\'constant\\',\\n21:lr_warmup_steps: int = 0,\\n22:max_token_length: int = 75,\\n23:max_train_steps: int = 1000,\\n24:mixed_precision: str = \"fp16\",\\n25:model_path: str = \"\",\\n26:not_cache_latents=False,\\n27:num_train_epochs: int = 1,\\n28:pad_tokens: bool = True,\\n29:pretrained_vae_name_or_path: str = \"\",\\n30:prior_loss_weight: float = 1.0,\\n31:resolution: int = 512,\\n32:revision: int = 0,\\n33:sample_batch_size: int = 1,\\n34:save_class_txt: bool = False,\\n35:save_embedding_every: int = 500,\\n36:save_preview_every: int = 500,\\n37:save_use_global_counts: bool = False,\\n38:save_use_epochs: bool = False,\\n39:scale_lr: bool = False,\\n40:scheduler: str = \"ddim\",\\n41:src: str = \"\",\\n42:shuffle_tags: bool = False,\\n43:train_batch_size: int = 1,\\n44:train_text_encoder: bool = True,\\n45:use_8bit_adam: bool = True,\\n46:use_concepts: bool = False,\\n47:use_cpu: bool = False,\\n48:use_ema: bool = True,\\n49:use_lora: bool = False,\\n50:v2: bool = False,\\n51:c1_class_data_dir: str = \"\",\\n52:c1_class_guidance_scale: float = 7.5,\\n53:c1_class_infer_steps: int = 60,\\n54:c1_class_negative_prompt: str = \"\",\\n55:c1_class_prompt: str = \"\",\\n56:c1_class_token: str = \"\",\\n57:c1_instance_data_dir: str = \"\",\\n58:c1_instance_prompt: str = \"\",\\n59:c1_instance_token: str = \"\",\\n60:c1_max_steps: int = -1,\\n61:c1_n_save_sample: int = 1,\\n62:c1_num_class_images: int = 0,\\n63:c1_sample_seed: int = -1,\\n64:c1_save_guidance_scale: float = 7.5,\\n65:c1_save_infer_steps: int = 60,\\n66:c1_save_sample_negative_prompt: str = \"\",\\n67:c1_save_sample_prompt: str = \"\",\\n68:c1_save_sample_template: str = \"\",\\n69:c2_class_data_dir: str = \"\",\\n70:c2_class_guidance_scale: float = 7.5,\\n71:c2_class_infer_steps: int = 60,\\n72:c2_class_negative_prompt: str = \"\",\\n73:c2_class_prompt: str = \"\",\\n74:c2_class_token: str = \"\",\\n75:c2_instance_data_dir: str = \"\",\\n76:c2_instance_prompt: str = \"\",\\n77:c2_instance_token: str = \"\",\\n78:c2_max_steps: int = -1,\\n79:c2_n_save_sample: int = 1,\\n80:c2_num_class_images: int = 0,\\n81:c2_sample_seed: int = -1,\\n82:c2_save_guidance_scale: float = 7.5,\\n83:c2_save_infer_steps: int = 60,\\n84:c2_save_sample_negative_prompt: str = \"\",\\n85:c2_save_sample_prompt: str = \"\",\\n86:c2_save_sample_template: str = \"\",\\n87:c3_class_data_dir: str = \"\",\\n88:c3_class_guidance_scale: float = 7.5,\\n89:c3_class_infer_steps: int = 60,\\n90:c3_class_negative_prompt: str = \"\",\\n91:c3_class_prompt: str = \"\",\\n92:c3_class_token: str = \"\",\\n93:c3_instance_data_dir: str = \"\",\\n94:c3_instance_prompt: str = \"\",\\n95:c3_instance_token: str = \"\",\\n96:c3_max_steps: int = -1,\\n97:c3_n_save_sample: int = 1,\\n98:c3_num_class_images: int = 0,\\n99:c3_sample_seed: int = -1,\\n100:c3_save_guidance_scale: float = 7.5,\\n101:c3_save_infer_steps: int = 60,\\n102:c3_save_sample_negative_prompt: str = \"\",\\n103:c3_save_sample_prompt: str = \"\",\\n104:c3_save_sample_template: str = \"\",\\n105:concepts_list=None\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1:model_name: str = \"\",\n",
    "2:adam_beta1: float = 0.9,\n",
    "3:adam_beta2: float = 0.999,\n",
    "4:adam_epsilon: float = 1e-8,\n",
    "5:adam_weight_decay: float = 0.01,\n",
    "6:attention: str = \"default\",\n",
    "7:center_crop: bool = True,\n",
    "8:concepts_path: str = \"\",\n",
    "9:custom_model_name: str = \"\",\n",
    "10:epoch_pause_frequency: int = 0,\n",
    "11:epoch_pause_time: int = 0,\n",
    "12:gradient_accumulation_steps: int = 1,\n",
    "13:gradient_checkpointing: bool = True,\n",
    "14:half_model: bool = False,\n",
    "15:has_ema: bool = False,\n",
    "16:hflip: bool = False,\n",
    "17:learning_rate: float = 0.00000172,\n",
    "18:lora_learning_rate: float = 1e-4,\n",
    "19:lora_txt_learning_rate: float = 5e-5,\n",
    "20:lr_scheduler: str = 'constant',\n",
    "21:lr_warmup_steps: int = 0,\n",
    "22:max_token_length: int = 75,\n",
    "23:max_train_steps: int = 1000,\n",
    "24:mixed_precision: str = \"fp16\",\n",
    "25:model_path: str = \"\",\n",
    "26:not_cache_latents=False,\n",
    "27:num_train_epochs: int = 1,\n",
    "28:pad_tokens: bool = True,\n",
    "29:pretrained_vae_name_or_path: str = \"\",\n",
    "30:prior_loss_weight: float = 1.0,\n",
    "31:resolution: int = 512,\n",
    "32:revision: int = 0,\n",
    "33:sample_batch_size: int = 1,\n",
    "34:save_class_txt: bool = False,\n",
    "35:save_embedding_every: int = 500,\n",
    "36:save_preview_every: int = 500,\n",
    "37:save_use_global_counts: bool = False,\n",
    "38:save_use_epochs: bool = False,\n",
    "39:scale_lr: bool = False,\n",
    "40:scheduler: str = \"ddim\",\n",
    "41:src: str = \"\",\n",
    "42:shuffle_tags: bool = False,\n",
    "43:train_batch_size: int = 1,\n",
    "44:train_text_encoder: bool = True,\n",
    "45:use_8bit_adam: bool = True,\n",
    "46:use_concepts: bool = False,\n",
    "47:use_cpu: bool = False,\n",
    "48:use_ema: bool = True,\n",
    "49:use_lora: bool = False,\n",
    "50:v2: bool = False,\n",
    "51:c1_class_data_dir: str = \"\",\n",
    "52:c1_class_guidance_scale: float = 7.5,\n",
    "53:c1_class_infer_steps: int = 60,\n",
    "54:c1_class_negative_prompt: str = \"\",\n",
    "55:c1_class_prompt: str = \"\",\n",
    "56:c1_class_token: str = \"\",\n",
    "57:c1_instance_data_dir: str = \"\",\n",
    "58:c1_instance_prompt: str = \"\",\n",
    "59:c1_instance_token: str = \"\",\n",
    "60:c1_max_steps: int = -1,\n",
    "61:c1_n_save_sample: int = 1,\n",
    "62:c1_num_class_images: int = 0,\n",
    "63:c1_sample_seed: int = -1,\n",
    "64:c1_save_guidance_scale: float = 7.5,\n",
    "65:c1_save_infer_steps: int = 60,\n",
    "66:c1_save_sample_negative_prompt: str = \"\",\n",
    "67:c1_save_sample_prompt: str = \"\",\n",
    "68:c1_save_sample_template: str = \"\",\n",
    "69:c2_class_data_dir: str = \"\",\n",
    "70:c2_class_guidance_scale: float = 7.5,\n",
    "71:c2_class_infer_steps: int = 60,\n",
    "72:c2_class_negative_prompt: str = \"\",\n",
    "73:c2_class_prompt: str = \"\",\n",
    "74:c2_class_token: str = \"\",\n",
    "75:c2_instance_data_dir: str = \"\",\n",
    "76:c2_instance_prompt: str = \"\",\n",
    "77:c2_instance_token: str = \"\",\n",
    "78:c2_max_steps: int = -1,\n",
    "79:c2_n_save_sample: int = 1,\n",
    "80:c2_num_class_images: int = 0,\n",
    "81:c2_sample_seed: int = -1,\n",
    "82:c2_save_guidance_scale: float = 7.5,\n",
    "83:c2_save_infer_steps: int = 60,\n",
    "84:c2_save_sample_negative_prompt: str = \"\",\n",
    "85:c2_save_sample_prompt: str = \"\",\n",
    "86:c2_save_sample_template: str = \"\",\n",
    "87:c3_class_data_dir: str = \"\",\n",
    "88:c3_class_guidance_scale: float = 7.5,\n",
    "89:c3_class_infer_steps: int = 60,\n",
    "90:c3_class_negative_prompt: str = \"\",\n",
    "91:c3_class_prompt: str = \"\",\n",
    "92:c3_class_token: str = \"\",\n",
    "93:c3_instance_data_dir: str = \"\",\n",
    "94:c3_instance_prompt: str = \"\",\n",
    "95:c3_instance_token: str = \"\",\n",
    "96:c3_max_steps: int = -1,\n",
    "97:c3_n_save_sample: int = 1,\n",
    "98:c3_num_class_images: int = 0,\n",
    "99:c3_sample_seed: int = -1,\n",
    "100:c3_save_guidance_scale: float = 7.5,\n",
    "101:c3_save_infer_steps: int = 60,\n",
    "102:c3_save_sample_negative_prompt: str = \"\",\n",
    "103:c3_save_sample_prompt: str = \"\",\n",
    "104:c3_save_sample_template: str = \"\",\n",
    "105:concepts_list=None\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be957491-0b71-4351-9a3c-35eda7ec9c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dreambooth_params = [\n",
    "  \"\",\n",
    "  0.9,\n",
    "  0.999,\n",
    "  1e-08,\n",
    "  0.01,\n",
    "  \"default\",\n",
    "  False,\n",
    "  \"\",\n",
    "  \"\",\n",
    "  0.0,\n",
    "  60.0,\n",
    "  1,\n",
    "  True,\n",
    "  False,\n",
    "  \"\",\n",
    "  True,\n",
    "  2e-06,\n",
    "  0.0002,\n",
    "  0.0002,\n",
    "  \"constant\",\n",
    "  500,\n",
    "  75,\n",
    "  0,\n",
    "  \"no\",\n",
    "  \"\",\n",
    "  True,\n",
    "  100,\n",
    "  True,\n",
    "  \"\",\n",
    "  1,\n",
    "  512,\n",
    "  \"\",\n",
    "  1,\n",
    "  True,\n",
    "  500,\n",
    "  500,\n",
    "  True,\n",
    "  False,\n",
    "  False,\n",
    "  \"\",\n",
    "  \"\",\n",
    "  False,\n",
    "  1,\n",
    "  True,\n",
    "  False,\n",
    "  False,\n",
    "  False,\n",
    "  False,\n",
    "  False,\n",
    "  \"\",\n",
    "  \"/opt/ml/input/data/images/\",\n",
    "  7.5,\n",
    "  40,\n",
    "  \"\",\n",
    "  \"a photo of Erwin Rommel\",\n",
    "  \"\",\n",
    "  \"/opt/ml/input/data/images/\",\n",
    "  \"Erwin Rommel\",\n",
    "  \"\",\n",
    "  -1,\n",
    "  1,\n",
    "  0,\n",
    "  -1,\n",
    "  7.5,\n",
    "  40,\n",
    "  \"\",\n",
    "  \"\",\n",
    "  \"\",\n",
    "  \"\",\n",
    "  7.5,\n",
    "  40,\n",
    "  \"\",\n",
    "  \"\",\n",
    "  \"\",\n",
    "  \"\",\n",
    "  \"\",\n",
    "  \"\",\n",
    "  -1,\n",
    "  1,\n",
    "  0,\n",
    "  -1,\n",
    "  7.5,\n",
    "  40,\n",
    "  \"\",\n",
    "  \"\",\n",
    "  \"\",\n",
    "  \"\",\n",
    "  7.5,\n",
    "  40,\n",
    "  \"\",\n",
    "  \"\",\n",
    "  \"\",\n",
    "  \"\",\n",
    "  \"\",\n",
    "  \"\",\n",
    "  -1,\n",
    "  1,\n",
    "  0,\n",
    "  -1,\n",
    "  7.5,\n",
    "  40,\n",
    "  \"\",\n",
    "  \"\",\n",
    "  \"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46f3044-4e3d-4e25-a1e5-aaca22926b49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uuid, json\n",
    "dreambooth_config_id = \"dreambooth_train_config\"\n",
    "dreambooth_config_file =f'{dreambooth_config_id}.json'\n",
    "json.dump(dreambooth_params, open(dreambooth_config_file,'w'), indent=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f09633bd-bdd6-44df-9a0d-7fc1619696d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"\", 0.9, 0.999, 1e-08, 0.01, \"default\", false, \"\", \"\", 0.0, 60.0, 1, true, false, \"\", true, 2e-06, 0.0002, 0.0002, \"constant\", 500, 75, 0, \"no\", \"\", true, 100, true, \"\", 1, 512, \"\", 1, true, 500, 500, true, false, false, \"\", \"\", false, 1, true, false, false, false, false, false, \"\", \"/opt/ml/input/data/images/\", 7.5, 40, \"\", \"a photo of Erwin Rommel\", \"\", \"/opt/ml/input/data/images/\", \"Erwin Rommel\", \"\", -1, 1, 0, -1, 7.5, 40, \"\", \"\", \"\", \"\", 7.5, 40, \"\", \"\", \"\", \"\", \"\", \"\", -1, 1, 0, -1, 7.5, 40, \"\", \"\", \"\", \"\", 7.5, 40, \"\", \"\", \"\", \"\", \"\", \"\", -1, 1, 0, -1, 7.5, 40, \"\", \"\", \"\"]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(dreambooth_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3656f142-057c-4bc9-bd38-ea318b8c4865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/all-in-one-ai-stable-diffusion-webui-training'.format(account_id, region_name)\n",
    "image_uri = '687912291502.dkr.ecr.ap-southeast-1.amazonaws.com/dreambooth-finetuning-v3:latest'\n",
    "models_s3uri = 's3://{0}/stable-diffusion/models/'.format(bucket)\n",
    "dreambooth_s3uri = 's3://{0}/stable-diffusion/dreambooth/'.format(bucket)\n",
    "dreambooth_config_s3uri = 's3://{0}/stable-diffusioni/dreambooth-config/'.format(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37afa1cf-56ce-4299-affb-500ae7b17319",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dreambooth_config_file)\n",
    "print(dreambooth_config_s3uri)\n",
    "!aws s3 cp $dreambooth_config_file $dreambooth_config_s3uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38dda204-a307-4776-b907-e8e3548df905",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-args {\"train_dreambooth_settings\": {\"db_create_new_db_model\": true, \"db_new_model_name\": \"aws-db-new-model\", \"db_new_model_src\": \"768-v-ema.ckpt\", \"db_new_model_scheduler\": \"ddim\", \"db_create_from_hub\": false, \"db_new_model_url\": \"\", \"db_new_model_token\": \"\", \"db_new_model_extract_ema\": false, \"db_model_name\": \"\", \"db_lora_model_name\": \"\", \"db_lora_weight\": 1, \"db_lora_txt_weight\": 1, \"db_train_imagic_only\": false, \"db_use_subdir\": false, \"db_custom_model_name\": \"\", \"db_train_wizard_person\": false, \"db_train_wizard_object\": true, \"db_performance_wizard\": true}}\n",
      "train-task dreambooth\n",
      "sd-models-s3uri s3://sagemaker-ap-southeast-1-687912291502/stable-diffusion/models/\n",
      "db-models-s3uri s3://sagemaker-ap-southeast-1-687912291502/stable-diffusion/dreambooth/\n",
      "ckpt /opt/ml/input/data/models/768-v-ema.ckpt\n",
      "dreambooth-config-id dreambooth_train_config\n",
      "api-endpoint noapi\n"
     ]
    }
   ],
   "source": [
    "def json_encode_hyperparameters(hyperparameters):\n",
    "    for (k, v) in hyperparameters.items():\n",
    "        print(k, v)\n",
    "    \n",
    "    return {k: json.dumps(v) for (k, v) in hyperparameters.items()}\n",
    "\n",
    "train_args = {\n",
    "    'train_dreambooth_settings': {\n",
    "        'db_create_new_db_model': True, \n",
    "        'db_new_model_name': 'aws-db-new-model', \n",
    "        'db_new_model_src': '768-v-ema.ckpt', \n",
    "        'db_new_model_scheduler': 'ddim', \n",
    "        'db_create_from_hub': False, \n",
    "        'db_new_model_url': '', \n",
    "        'db_new_model_token': '', \n",
    "        'db_new_model_extract_ema': False, \n",
    "        'db_model_name': '', \n",
    "        'db_lora_model_name': '', \n",
    "        'db_lora_weight': 1, \n",
    "        'db_lora_txt_weight': 1, \n",
    "        'db_train_imagic_only': False, \n",
    "        'db_use_subdir': False, \n",
    "        'db_custom_model_name': '', \n",
    "        'db_train_wizard_person': False, \n",
    "        'db_train_wizard_object': True, \n",
    "        'db_performance_wizard': True\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "hyperparameters = {\n",
    "    'train-args': json.dumps(train_args),\n",
    "    'train-task': 'dreambooth',\n",
    "    'sd-models-s3uri': models_s3uri,\n",
    "    'db-models-s3uri': dreambooth_s3uri,\n",
    "    'ckpt': '/opt/ml/input/data/models/768-v-ema.ckpt',\n",
    "    'dreambooth-config-id': dreambooth_config_id,\n",
    "    'api-endpoint': 'noapi'\n",
    "}\n",
    "\n",
    "hyperparameters = json_encode_hyperparameters(hyperparameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fb547e0-c9fa-40ec-8acb-68736292803a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-southeast-1-687912291502/stable-diffusion/models/\n"
     ]
    }
   ],
   "source": [
    "print(models_s3uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccaf4b6-b813-40fa-96d9-10320e37b110",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-27 13:04:29 Starting - Starting the training job...\n",
      "2023-01-27 13:04:47 Starting - Preparing the instances for trainingProfilerReport-1674824668: InProgress\n",
      "......\n",
      "2023-01-27 13:05:46 Downloading - Downloading input data...............\n",
      "2023-01-27 13:08:27 Training - Downloading the training image...............\n",
      "2023-01-27 13:10:48 Training - Training image download completed. Training in progress.....\u001b[34m2023-01-27 13:11:26,448 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-01-27 13:11:26,481 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-01-27 13:11:26,511 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-01-27 13:11:26,521 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"config\": \"/opt/ml/input/data/config\",\n",
      "        \"images\": \"/opt/ml/input/data/images\",\n",
      "        \"models\": \"/opt/ml/input/data/models\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"api-endpoint\": \"noapi\",\n",
      "        \"ckpt\": \"/opt/ml/input/data/models/768-v-ema.ckpt\",\n",
      "        \"db-models-s3uri\": \"s3://sagemaker-ap-southeast-1-687912291502/stable-diffusion/dreambooth/\",\n",
      "        \"dreambooth-config-id\": \"dreambooth_train_config\",\n",
      "        \"sd-models-s3uri\": \"s3://sagemaker-ap-southeast-1-687912291502/stable-diffusion/models/\",\n",
      "        \"train-args\": \"{\\\"train_dreambooth_settings\\\": {\\\"db_create_new_db_model\\\": true, \\\"db_new_model_name\\\": \\\"aws-db-new-model\\\", \\\"db_new_model_src\\\": \\\"768-v-ema.ckpt\\\", \\\"db_new_model_scheduler\\\": \\\"ddim\\\", \\\"db_create_from_hub\\\": false, \\\"db_new_model_url\\\": \\\"\\\", \\\"db_new_model_token\\\": \\\"\\\", \\\"db_new_model_extract_ema\\\": false, \\\"db_model_name\\\": \\\"\\\", \\\"db_lora_model_name\\\": \\\"\\\", \\\"db_lora_weight\\\": 1, \\\"db_lora_txt_weight\\\": 1, \\\"db_train_imagic_only\\\": false, \\\"db_use_subdir\\\": false, \\\"db_custom_model_name\\\": \\\"\\\", \\\"db_train_wizard_person\\\": false, \\\"db_train_wizard_object\\\": true, \\\"db_performance_wizard\\\": true}}\",\n",
      "        \"train-task\": \"dreambooth\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"config\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"images\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"models\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"job_name\": \"dreambooth-finetuning-v3-with-webui-2023-01-27-13-04-28-401\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"api-endpoint\":\"noapi\",\"ckpt\":\"/opt/ml/input/data/models/768-v-ema.ckpt\",\"db-models-s3uri\":\"s3://sagemaker-ap-southeast-1-687912291502/stable-diffusion/dreambooth/\",\"dreambooth-config-id\":\"dreambooth_train_config\",\"sd-models-s3uri\":\"s3://sagemaker-ap-southeast-1-687912291502/stable-diffusion/models/\",\"train-args\":\"{\\\"train_dreambooth_settings\\\": {\\\"db_create_new_db_model\\\": true, \\\"db_new_model_name\\\": \\\"aws-db-new-model\\\", \\\"db_new_model_src\\\": \\\"768-v-ema.ckpt\\\", \\\"db_new_model_scheduler\\\": \\\"ddim\\\", \\\"db_create_from_hub\\\": false, \\\"db_new_model_url\\\": \\\"\\\", \\\"db_new_model_token\\\": \\\"\\\", \\\"db_new_model_extract_ema\\\": false, \\\"db_model_name\\\": \\\"\\\", \\\"db_lora_model_name\\\": \\\"\\\", \\\"db_lora_weight\\\": 1, \\\"db_lora_txt_weight\\\": 1, \\\"db_train_imagic_only\\\": false, \\\"db_use_subdir\\\": false, \\\"db_custom_model_name\\\": \\\"\\\", \\\"db_train_wizard_person\\\": false, \\\"db_train_wizard_object\\\": true, \\\"db_performance_wizard\\\": true}}\",\"train-task\":\"dreambooth\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"images\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"models\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"config\",\"images\",\"models\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g4dn.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"config\":\"/opt/ml/input/data/config\",\"images\":\"/opt/ml/input/data/images\",\"models\":\"/opt/ml/input/data/models\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g4dn.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"api-endpoint\":\"noapi\",\"ckpt\":\"/opt/ml/input/data/models/768-v-ema.ckpt\",\"db-models-s3uri\":\"s3://sagemaker-ap-southeast-1-687912291502/stable-diffusion/dreambooth/\",\"dreambooth-config-id\":\"dreambooth_train_config\",\"sd-models-s3uri\":\"s3://sagemaker-ap-southeast-1-687912291502/stable-diffusion/models/\",\"train-args\":\"{\\\"train_dreambooth_settings\\\": {\\\"db_create_new_db_model\\\": true, \\\"db_new_model_name\\\": \\\"aws-db-new-model\\\", \\\"db_new_model_src\\\": \\\"768-v-ema.ckpt\\\", \\\"db_new_model_scheduler\\\": \\\"ddim\\\", \\\"db_create_from_hub\\\": false, \\\"db_new_model_url\\\": \\\"\\\", \\\"db_new_model_token\\\": \\\"\\\", \\\"db_new_model_extract_ema\\\": false, \\\"db_model_name\\\": \\\"\\\", \\\"db_lora_model_name\\\": \\\"\\\", \\\"db_lora_weight\\\": 1, \\\"db_lora_txt_weight\\\": 1, \\\"db_train_imagic_only\\\": false, \\\"db_use_subdir\\\": false, \\\"db_custom_model_name\\\": \\\"\\\", \\\"db_train_wizard_person\\\": false, \\\"db_train_wizard_object\\\": true, \\\"db_performance_wizard\\\": true}}\",\"train-task\":\"dreambooth\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"images\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"models\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"dreambooth-finetuning-v3-with-webui-2023-01-27-13-04-28-401\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--api-endpoint\",\"noapi\",\"--ckpt\",\"/opt/ml/input/data/models/768-v-ema.ckpt\",\"--db-models-s3uri\",\"s3://sagemaker-ap-southeast-1-687912291502/stable-diffusion/dreambooth/\",\"--dreambooth-config-id\",\"dreambooth_train_config\",\"--sd-models-s3uri\",\"s3://sagemaker-ap-southeast-1-687912291502/stable-diffusion/models/\",\"--train-args\",\"{\\\"train_dreambooth_settings\\\": {\\\"db_create_new_db_model\\\": true, \\\"db_new_model_name\\\": \\\"aws-db-new-model\\\", \\\"db_new_model_src\\\": \\\"768-v-ema.ckpt\\\", \\\"db_new_model_scheduler\\\": \\\"ddim\\\", \\\"db_create_from_hub\\\": false, \\\"db_new_model_url\\\": \\\"\\\", \\\"db_new_model_token\\\": \\\"\\\", \\\"db_new_model_extract_ema\\\": false, \\\"db_model_name\\\": \\\"\\\", \\\"db_lora_model_name\\\": \\\"\\\", \\\"db_lora_weight\\\": 1, \\\"db_lora_txt_weight\\\": 1, \\\"db_train_imagic_only\\\": false, \\\"db_use_subdir\\\": false, \\\"db_custom_model_name\\\": \\\"\\\", \\\"db_train_wizard_person\\\": false, \\\"db_train_wizard_object\\\": true, \\\"db_performance_wizard\\\": true}}\",\"--train-task\",\"dreambooth\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_CONFIG=/opt/ml/input/data/config\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_IMAGES=/opt/ml/input/data/images\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_MODELS=/opt/ml/input/data/models\u001b[0m\n",
      "\u001b[34mSM_HP_API-ENDPOINT=noapi\u001b[0m\n",
      "\u001b[34mSM_HP_CKPT=/opt/ml/input/data/models/768-v-ema.ckpt\u001b[0m\n",
      "\u001b[34mSM_HP_DB-MODELS-S3URI=s3://sagemaker-ap-southeast-1-687912291502/stable-diffusion/dreambooth/\u001b[0m\n",
      "\u001b[34mSM_HP_DREAMBOOTH-CONFIG-ID=dreambooth_train_config\u001b[0m\n",
      "\u001b[34mSM_HP_SD-MODELS-S3URI=s3://sagemaker-ap-southeast-1-687912291502/stable-diffusion/models/\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN-ARGS={\"train_dreambooth_settings\": {\"db_create_new_db_model\": true, \"db_new_model_name\": \"aws-db-new-model\", \"db_new_model_src\": \"768-v-ema.ckpt\", \"db_new_model_scheduler\": \"ddim\", \"db_create_from_hub\": false, \"db_new_model_url\": \"\", \"db_new_model_token\": \"\", \"db_new_model_extract_ema\": false, \"db_model_name\": \"\", \"db_lora_model_name\": \"\", \"db_lora_weight\": 1, \"db_lora_txt_weight\": 1, \"db_train_imagic_only\": false, \"db_use_subdir\": false, \"db_custom_model_name\": \"\", \"db_train_wizard_person\": false, \"db_train_wizard_object\": true, \"db_performance_wizard\": true}}\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN-TASK=dreambooth\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --api-endpoint noapi --ckpt /opt/ml/input/data/models/768-v-ema.ckpt --db-models-s3uri s3://sagemaker-ap-southeast-1-687912291502/stable-diffusion/dreambooth/ --dreambooth-config-id dreambooth_train_config --sd-models-s3uri s3://sagemaker-ap-southeast-1-687912291502/stable-diffusion/models/ --train-args {\"train_dreambooth_settings\": {\"db_create_new_db_model\": true, \"db_new_model_name\": \"aws-db-new-model\", \"db_new_model_src\": \"768-v-ema.ckpt\", \"db_new_model_scheduler\": \"ddim\", \"db_create_from_hub\": false, \"db_new_model_url\": \"\", \"db_new_model_token\": \"\", \"db_new_model_extract_ema\": false, \"db_model_name\": \"\", \"db_lora_model_name\": \"\", \"db_lora_weight\": 1, \"db_lora_txt_weight\": 1, \"db_train_imagic_only\": false, \"db_use_subdir\": false, \"db_custom_model_name\": \"\", \"db_train_wizard_person\": false, \"db_train_wizard_object\": true, \"db_performance_wizard\": true}} --train-task dreambooth\u001b[0m\n",
      "\u001b[34m2023-01-27 13:11:26,522 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2023-01-27 13:11:26,522 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m################################################################\u001b[0m\n",
      "\u001b[34m#033[1m#033[32mInstall script for stable-diffusion + Web UI\u001b[0m\n",
      "\u001b[34m#033[1m#033[34mTested on Debian 11 (Bullseye)#033[0m\u001b[0m\n",
      "\u001b[34m################################################################\u001b[0m\n",
      "\u001b[34m################################################################\u001b[0m\n",
      "\u001b[34mRepo already cloned, using it as install directory\u001b[0m\n",
      "\u001b[34m################################################################\u001b[0m\n",
      "\u001b[34m################################################################\u001b[0m\n",
      "\u001b[34mCreate and activate python venv\u001b[0m\n",
      "\u001b[34m################################################################\u001b[0m\n",
      "\u001b[34m################################################################\u001b[0m\n",
      "\u001b[34mLaunching launch.py...\u001b[0m\n",
      "\u001b[34m################################################################\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/_distutils_hack/__init__.py:17: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\u001b[0m\n",
      "\u001b[34mPython 3.9.12 (main, Apr  5 2022, 06:56:58) \u001b[0m\n",
      "\u001b[34m[GCC 7.5.0]\u001b[0m\n",
      "\u001b[34mCommit hash: 2fdec7820a3a85748bd55624a635ed75754ae073\u001b[0m\n",
      "\u001b[34mInstalling gfpgan\u001b[0m\n",
      "\u001b[34mInstalling clip\u001b[0m\n",
      "\u001b[34mInstalling open_clip\u001b[0m\n",
      "\u001b[34mCloning Stable Diffusion into repositories/stable-diffusion-stability-ai...\u001b[0m\n",
      "\u001b[34mCloning Taming Transformers into repositories/taming-transformers...\u001b[0m\n",
      "\u001b[34mCloning K-diffusion into repositories/k-diffusion...\u001b[0m\n",
      "\u001b[34mCloning CodeFormer into repositories/CodeFormer...\u001b[0m\n",
      "\u001b[34mCloning BLIP into repositories/BLIP...\u001b[0m\n",
      "\u001b[34mInstalling requirements for CodeFormer\u001b[0m\n",
      "\u001b[34mInstalling requirements for Web UI\u001b[0m\n",
      "\u001b[34m#######################################################################################################\u001b[0m\n",
      "\u001b[34mInitializing Dreambooth\u001b[0m\n",
      "\u001b[34mIf submitting an issue on github, please provide the below text for debugging purposes:\u001b[0m\n",
      "\u001b[34mPython revision: 3.9.12 (main, Apr  5 2022, 06:56:58) \u001b[0m\n",
      "\u001b[34m[GCC 7.5.0]\u001b[0m\n",
      "\u001b[34mDreambooth revision: aea91495c8b34e42a5f6bd7bdd7a35b211fe66ab\u001b[0m\n",
      "\u001b[34mSD-WebUI revision: 2fdec7820a3a85748bd55624a635ed75754ae073\u001b[0m\n",
      "\u001b[34mChecking Dreambooth requirements...\u001b[0m\n",
      "\u001b[34m[+] bitsandbytes version 0.35.0 installed.\u001b[0m\n",
      "\u001b[34m[+] diffusers version 0.10.2 installed.\u001b[0m\n",
      "\u001b[34m[+] transformers version 4.25.1 installed.\u001b[0m\n",
      "\u001b[34m[+] xformers version 0.0.15+4cc967a.d20230126 installed.\u001b[0m\n",
      "\u001b[34m[+] torch version 1.12.1+cu113 installed.\u001b[0m\n",
      "\u001b[34m[+] torchvision version 0.13.1+cu113 installed.\u001b[0m\n",
      "\u001b[34m#######################################################################################################\u001b[0m\n",
      "\u001b[34mLaunching Web UI with arguments: --port 8080 --listen --xformers --train --train-task dreambooth --train-args {\"train_dreambooth_settings\": {\"db_create_new_db_model\": true, \"db_new_model_name\": \"aws-db-new-model\", \"db_new_model_src\": \"768-v-ema.ckpt\", \"db_new_model_scheduler\": \"ddim\", \"db_create_from_hub\": false, \"db_new_model_url\": \"\", \"db_new_model_token\": \"\", \"db_new_model_extract_ema\": false, \"db_model_name\": \"\", \"db_lora_model_name\": \"\", \"db_lora_weight\": 1, \"db_lora_txt_weight\": 1, \"db_train_imagic_only\": false, \"db_use_subdir\": false, \"db_custom_model_name\": \"\", \"db_train_wizard_person\": false, \"db_train_wizard_object\": true, \"db_performance_wizard\": true}} --embeddings-dir /opt/ml/input/data/embeddings --hypernetwork-dir /opt/ml/input/data/hypernetwork --lora-models-path /opt/ml/input/data/lora --dreambooth-models-path /opt/ml/input/data/dreambooth --ckpt /opt/ml/input/data/models/768-v-ema.ckpt --ckpt-dir /opt/ml/input/data/models --region-name None --api-endpoint noapi --sd-models-s3uri s3://sagemaker-ap-southeast-1-687912291502/stable-diffusion/models/ --db-models-s3uri s3://sagemaker-ap-southeast-1-687912291502/stable-diffusion/dreambooth/ --dreambooth-config-id dreambooth_train_config\u001b[0m\n",
      "\u001b[34mDreambooth API layer loaded\u001b[0m\n",
      "\u001b[34mLoading config from: /opt/ml/input/data/models/768-v-ema.yaml\u001b[0m\n",
      "\u001b[34mLatentDiffusion: Running in v-prediction mode\u001b[0m\n",
      "\u001b[34mDiffusionWrapper has 865.91 M params.\u001b[0m\n",
      "\u001b[34m#015Downloading (…)_pytorch_model.bin\";:   0%|          | 0.00/3.94G [00:00<?, ?B/s]#015Downloading (…)_pytorch_model.bin\";:   1%|          | 21.0M/3.94G [00:00<00:19, 200MB/s]#015Downloading (…)_pytorch_model.bin\";:   2%|▏         | 62.9M/3.94G [00:00<00:13, 278MB/s]#015Downloading (…)_pytorch_model.bin\";:   3%|▎         | 105M/3.94G [00:00<00:11, 334MB/s] #015Downloading (…)_pytorch_model.bin\";:   4%|▍         | 157M/3.94G [00:00<00:10, 360MB/s]#015Downloading (…)_pytorch_model.bin\";:   5%|▌         | 199M/3.94G [00:00<00:10, 373MB/s]#015Downloading (…)_pytorch_model.bin\";:   6%|▋         | 252M/3.94G [00:00<00:09, 395MB/s]#015Downloading (…)_pytorch_model.bin\";:   8%|▊         | 304M/3.94G [00:00<00:08, 412MB/s]#015Downloading (…)_pytorch_model.bin\";:   9%|▉         | 357M/3.94G [00:00<00:08, 427MB/s]#015Downloading (…)_pytorch_model.bin\";:  10%|█         | 409M/3.94G [00:01<00:07, 442MB/s]#015Downloading (…)_pytorch_model.bin\";:  12%|█▏        | 461M/3.94G [00:01<00:09, 382MB/s]#015Downloading (…)_pytorch_model.bin\";:  13%|█▎        | 503M/3.94G [00:01<00:08, 388MB/s]#015Downloading (…)_pytorch_model.bin\";:  14%|█▍        | 556M/3.94G [00:01<00:08, 413MB/s]#015Downloading (…)_pytorch_model.bin\";:  15%|█▌        | 608M/3.94G [00:01<00:08, 414MB/s]#015Downloading (…)_pytorch_model.bin\";:  17%|█▋        | 661M/3.94G [00:01<00:07, 431MB/s]#015Downloading (…)_pytorch_model.bin\";:  18%|█▊        | 713M/3.94G [00:01<00:07, 434MB/s]#015Downloading (…)_pytorch_model.bin\";:  19%|█▉        | 765M/3.94G [00:01<00:07, 417MB/s]#015Downloading (…)_pytorch_model.bin\";:  21%|██        | 818M/3.94G [00:02<00:07, 408MB/s]#015Downloading (…)_pytorch_model.bin\";:  22%|██▏       | 860M/3.94G [00:02<00:07, 406MB/s]#015Downloading (…)_pytorch_model.bin\";:  23%|██▎       | 912M/3.94G [00:02<00:07, 417MB/s]#015Downloading (…)_pytorch_model.bin\";:  24%|██▍       | 965M/3.94G [00:02<00:07, 423MB/s]#015Downloading (…)_pytorch_model.bin\";:  26%|██▌       | 1.02G/3.94G [00:02<00:06, 435MB/s]#015Downloading (…)_pytorch_model.bin\";:  27%|██▋       | 1.07G/3.94G [00:02<00:06, 433MB/s]#015Downloading (…)_pytorch_model.bin\";:  28%|██▊       | 1.12G/3.94G [00:02<00:06, 439MB/s]#015Downloading (…)_pytorch_model.bin\";:  30%|██▉       | 1.17G/3.94G [00:02<00:06, 434MB/s]#015Downloading (…)_pytorch_model.bin\";:  31%|███       | 1.23G/3.94G [00:02<00:06, 442MB/s]#015Downloading (…)_pytorch_model.bin\";:  32%|███▏      | 1.28G/3.94G [00:03<00:06, 408MB/s]#015Downloading (…)_pytorch_model.bin\";:  33%|███▎      | 1.32G/3.94G [00:03<00:06, 404MB/s]#015Downloading (…)_pytorch_model.bin\";:  35%|███▍      | 1.36G/3.94G [00:03<00:06, 397MB/s]#015Downloading (…)_pytorch_model.bin\";:  36%|███▌      | 1.42G/3.94G [00:03<00:06, 403MB/s]#015Downloading (…)_pytorch_model.bin\";:  37%|███▋      | 1.46G/3.94G [00:03<00:06, 402MB/s]#015Downloading (…)_pytorch_model.bin\";:  38%|███▊      | 1.50G/3.94G [00:03<00:06, 382MB/s]#015Downloading (…)_pytorch_model.bin\";:  39%|███▉      | 1.54G/3.94G [00:03<00:06, 356MB/s]#015Downloading (…)_pytorch_model.bin\";:  40%|████      | 1.58G/3.94G [00:03<00:06, 360MB/s]#015Downloading (…)_pytorch_model.bin\";:  41%|████▏     | 1.64G/3.94G [00:04<00:05, 385MB/s]#015Downloading (…)_pytorch_model.bin\";:  43%|████▎     | 1.69G/3.94G [00:04<00:05, 397MB/s]#015Downloading (…)_pytorch_model.bin\";:  44%|████▍     | 1.73G/3.94G [00:04<00:05, 400MB/s]#015Downloading (…)_pytorch_model.bin\";:  45%|████▌     | 1.78G/3.94G [00:04<00:05, 407MB/s]#015Downloading (…)_pytorch_model.bin\";:  47%|████▋     | 1.84G/3.94G [00:04<00:05, 412MB/s]#015Downloading (…)_pytorch_model.bin\";:  48%|████▊     | 1.88G/3.94G [00:04<00:05, 375MB/s]#015Downloading (…)_pytorch_model.bin\";:  49%|████▊     | 1.92G/3.94G [00:04<00:05, 363MB/s]#015Downloading (…)_pytorch_model.bin\";:  50%|████▉     | 1.96G/3.94G [00:04<00:05, 356MB/s]#015Downloading (…)_pytorch_model.bin\";:  51%|█████     | 2.00G/3.94G [00:05<00:05, 338MB/s]#015Downloading (…)_pytorch_model.bin\";:  52%|█████▏    | 2.04G/3.94G [00:05<00:05, 347MB/s]#015Downloading (…)_pytorch_model.bin\";:  53%|█████▎    | 2.09G/3.94G [00:05<00:05, 334MB/s]#015Downloading (…)_pytorch_model.bin\";:  54%|█████▍    | 2.13G/3.94G [00:05<00:05, 343MB/s]#015Downloading (…)_pytorch_model.bin\";:  55%|█████▌    | 2.17G/3.94G [00:05<00:05, 351MB/s]#015Downloading (…)_pytorch_model.bin\";:  56%|█████▋    | 2.22G/3.94G [00:05<00:04, 376MB/s]#015Downloading (…)_pytorch_model.bin\";:  57%|█████▋    | 2.26G/3.94G [00:05<00:04, 371MB/s]#015Downloading (…)_pytorch_model.bin\";:  58%|█████▊    | 2.31G/3.94G [00:05<00:04, 375MB/s]#015Downloading (…)_pytorch_model.bin\";:  60%|█████▉    | 2.35G/3.94G [00:06<00:04, 361MB/s]#015Downloading (…)_pytorch_model.bin\";:  61%|██████    | 2.39G/3.94G [00:06<00:04, 345MB/s]#015Downloading (…)_pytorch_model.bin\";:  62%|██████▏   | 2.43G/3.94G [00:06<00:04, 356MB/s]#015Downloading (…)_pytorch_model.bin\";:  63%|██████▎   | 2.47G/3.94G [00:06<00:04, 364MB/s]#015Downloading (…)_pytorch_model.bin\";:  64%|██████▍   | 2.52G/3.94G [00:06<00:04, 349MB/s]#015Downloading (…)_pytorch_model.bin\";:  65%|██████▍   | 2.56G/3.94G [00:06<00:03, 353MB/s]#015Downloading (…)_pytorch_model.bin\";:  66%|██████▌   | 2.60G/3.94G [00:06<00:03, 344MB/s]#015Downloading (…)_pytorch_model.bin\";:  67%|██████▋   | 2.64G/3.94G [00:06<00:03, 359MB/s]#015Downloading (…)_pytorch_model.bin\";:  68%|██████▊   | 2.68G/3.94G [00:06<00:03, 372MB/s]#015Downloading (…)_pytorch_model.bin\";:  69%|██████▉   | 2.73G/3.94G [00:07<00:03, 332MB/s]#015Downloading (…)_pytorch_model.bin\";:  70%|███████   | 2.77G/3.94G [00:07<00:03, 344MB/s]#015Downloading (…)_pytorch_model.bin\";:  72%|███████▏  | 2.82G/3.94G [00:07<00:03, 368MB/s]#015Downloading (…)_pytorch_model.bin\";:  73%|███████▎  | 2.86G/3.94G [00:07<00:02, 374MB/s]#015Downloading (…)_pytorch_model.bin\";:  74%|███████▎  | 2.90G/3.94G [00:07<00:02, 381MB/s]#015Downloading (…)_pytorch_model.bin\";:  75%|███████▍  | 2.95G/3.94G [00:07<00:02, 387MB/s]#015Downloading (…)_pytorch_model.bin\";:  76%|███████▌  | 2.99G/3.94G [00:07<00:02, 337MB/s]#015Downloading (…)_pytorch_model.bin\";:  77%|███████▋  | 3.03G/3.94G [00:07<00:02, 331MB/s]#015Downloading (…)_pytorch_model.bin\";:  78%|███████▊  | 3.07G/3.94G [00:08<00:02, 344MB/s]#015Downloading (…)_pytorch_model.bin\";:  79%|███████▉  | 3.12G/3.94G [00:08<00:02, 368MB/s]#015Downloading (…)_pytorch_model.bin\";:  81%|████████  | 3.18G/3.94G [00:08<00:01, 389MB/s]#015Downloading (…)_pytorch_model.bin\";:  82%|████████▏ | 3.23G/3.94G [00:08<00:01, 398MB/s]#015Downloading (…)_pytorch_model.bin\";:  83%|████████▎ | 3.27G/3.94G [00:08<00:01, 375MB/s]#015Downloading (…)_pytorch_model.bin\";:  84%|████████▍ | 3.31G/3.94G [00:08<00:01, 333MB/s]#015Downloading (…)_pytorch_model.bin\";:  85%|████████▌ | 3.37G/3.94G [00:08<00:01, 355MB/s]#015Downloading (…)_pytorch_model.bin\";:  87%|████████▋ | 3.42G/3.94G [00:08<00:01, 373MB/s]#015Downloading (…)_pytorch_model.bin\";:  88%|████████▊ | 3.46G/3.94G [00:09<00:01, 381MB/s]#015Downloading (…)_pytorch_model.bin\";:  89%|████████▉ | 3.50G/3.94G [00:09<00:01, 387MB/s]#015Downloading (…)_pytorch_model.bin\";:  90%|████████▉ | 3.54G/3.94G [00:09<00:01, 391MB/s]#015Downloading (…)_pytorch_model.bin\";:  91%|█████████ | 3.59G/3.94G [00:09<00:00, 394MB/s]#015Downloading (…)_pytorch_model.bin\";:  92%|█████████▏| 3.63G/3.94G [00:09<00:00, 397MB/s]#015Downloading (…)_pytorch_model.bin\";:  93%|█████████▎| 3.67G/3.94G [00:09<00:00, 401MB/s]#015Downloading (…)_pytorch_model.bin\";:  94%|█████████▍| 3.72G/3.94G [00:09<00:00, 407MB/s]#015Downloading (…)_pytorch_model.bin\";:  95%|█████████▌| 3.76G/3.94G [00:09<00:00, 389MB/s]#015Downloading (…)_pytorch_model.bin\";:  96%|█████████▋| 3.81G/3.94G [00:09<00:00, 371MB/s]#015Downloading (…)_pytorch_model.bin\";:  98%|█████████▊| 3.86G/3.94G [00:10<00:00, 390MB/s]#015Downloading (…)_pytorch_model.bin\";:  99%|█████████▉| 3.91G/3.94G [00:10<00:00, 266MB/s]#015Downloading (…)_pytorch_model.bin\";: 100%|██████████| 3.94G/3.94G [00:10<00:00, 375MB/s]\u001b[0m\n",
      "\u001b[34mLoading weights [2c02b20a] from /opt/ml/input/data/models/768-v-ema.ckpt\u001b[0m\n",
      "\u001b[34mApplying xformers cross attention optimization.\u001b[0m\n",
      "\u001b[34mModel loaded.\u001b[0m\n",
      "\u001b[34mLoading model from checkpoint.\u001b[0m\n",
      "\u001b[34m768-v-ema.ckpt\u001b[0m\n",
      "\u001b[34mLoading checkpoint...\u001b[0m\n",
      "\u001b[34mCheckpointInfo(filename='/opt/ml/input/data/models/768-v-ema.ckpt', title='768-v-ema.ckpt [2c02b20a]', hash='2c02b20a', model_name='768-v-ema', config='/opt/ml/input/data/models/768-v-ema.yaml')\u001b[0m\n",
      "\u001b[34mv2 model loaded.\u001b[0m\n",
      "\u001b[34mCreating scheduler...\u001b[0m\n",
      "\u001b[34mConverting unet...\u001b[0m\n",
      "\u001b[34mConverting vae...\u001b[0m\n",
      "\u001b[34mConverting text encoder...\u001b[0m\n",
      "\u001b[34m#015Downloading (…)_encoder/config.json:   0%|          | 0.00/633 [00:00<?, ?B/s]#015Downloading (…)_encoder/config.json: 100%|██████████| 633/633 [00:00<00:00, 90.6kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)\"model.safetensors\";:   0%|          | 0.00/1.36G [00:00<?, ?B/s]#015Downloading (…)\"model.safetensors\";:   2%|▏         | 31.5M/1.36G [00:00<00:04, 275MB/s]#015Downloading (…)\"model.safetensors\";:   5%|▌         | 73.4M/1.36G [00:00<00:04, 313MB/s]#015Downloading (…)\"model.safetensors\";:   8%|▊         | 115M/1.36G [00:00<00:03, 337MB/s] #015Downloading (…)\"model.safetensors\";:  12%|█▏        | 157M/1.36G [00:00<00:03, 349MB/s]#015Downloading (…)\"model.safetensors\";:  15%|█▍        | 199M/1.36G [00:00<00:03, 351MB/s]#015Downloading (…)\"model.safetensors\";:  18%|█▊        | 241M/1.36G [00:00<00:03, 352MB/s]#015Downloading (…)\"model.safetensors\";:  21%|██        | 283M/1.36G [00:00<00:03, 335MB/s]#015Downloading (…)\"model.safetensors\";:  24%|██▍       | 325M/1.36G [00:00<00:03, 327MB/s]#015Downloading (…)\"model.safetensors\";:  27%|██▋       | 367M/1.36G [00:01<00:02, 337MB/s]#015Downloading (…)\"model.safetensors\";:  30%|███       | 409M/1.36G [00:01<00:02, 333MB/s]#015Downloading (…)\"model.safetensors\";:  33%|███▎      | 451M/1.36G [00:01<00:03, 299MB/s]#015Downloading (…)\"model.safetensors\";:  35%|███▌      | 482M/1.36G [00:01<00:02, 300MB/s]#015Downloading (…)\"model.safetensors\";:  39%|███▊      | 524M/1.36G [00:01<00:02, 319MB/s]#015Downloading (…)\"model.safetensors\";:  42%|████▏     | 566M/1.36G [00:01<00:02, 338MB/s]#015Downloading (…)\"model.safetensors\";:  45%|████▍     | 608M/1.36G [00:01<00:02, 349MB/s]#015Downloading (…)\"model.safetensors\";:  48%|████▊     | 650M/1.36G [00:01<00:01, 361MB/s]#015Downloading (…)\"model.safetensors\";:  51%|█████     | 692M/1.36G [00:02<00:01, 370MB/s]#015Downloading (…)\"model.safetensors\";:  54%|█████▍    | 734M/1.36G [00:02<00:01, 372MB/s]#015Downloading (…)\"model.safetensors\";:  57%|█████▋    | 776M/1.36G [00:02<00:01, 379MB/s]#015Downloading (…)\"model.safetensors\";:  60%|██████    | 818M/1.36G [00:02<00:01, 332MB/s]#015Downloading (…)\"model.safetensors\";:  63%|██████▎   | 860M/1.36G [00:02<00:01, 333MB/s]#015Downloading (…)\"model.safetensors\";:  66%|██████▌   | 902M/1.36G [00:02<00:01, 349MB/s]#015Downloading (…)\"model.safetensors\";:  69%|██████▉   | 944M/1.36G [00:02<00:01, 337MB/s]#015Downloading (…)\"model.safetensors\";:  72%|███████▏  | 986M/1.36G [00:02<00:01, 348MB/s]#015Downloading (…)\"model.safetensors\";:  75%|███████▌  | 1.03G/1.36G [00:03<00:00, 354MB/s]#015Downloading (…)\"model.safetensors\";:  79%|███████▊  | 1.07G/1.36G [00:03<00:00, 362MB/s]#015Downloading (…)\"model.safetensors\";:  82%|████████▏ | 1.11G/1.36G [00:03<00:00, 360MB/s]#015Downloading (…)\"model.safetensors\";:  85%|████████▍ | 1.15G/1.36G [00:03<00:00, 356MB/s]#015Downloading (…)\"model.safetensors\";:  88%|████████▊ | 1.20G/1.36G [00:03<00:00, 351MB/s]#015Downloading (…)\"model.safetensors\";:  91%|█████████ | 1.24G/1.36G [00:03<00:00, 358MB/s]#015Downloading (…)\"model.safetensors\";:  94%|█████████▍| 1.28G/1.36G [00:03<00:00, 362MB/s]#015Downloading (…)\"model.safetensors\";:  97%|█████████▋| 1.32G/1.36G [00:03<00:00, 362MB/s]#015Downloading (…)\"model.safetensors\";: 100%|██████████| 1.36G/1.36G [00:03<00:00, 362MB/s]#015Downloading (…)\"model.safetensors\";: 100%|██████████| 1.36G/1.36G [00:03<00:00, 345MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]#015Downloading (…)tokenizer/vocab.json: 100%|██████████| 1.06M/1.06M [00:01<00:00, 779kB/s]#015Downloading (…)tokenizer/vocab.json: 100%|██████████| 1.06M/1.06M [00:01<00:00, 778kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]#015Downloading (…)tokenizer/merges.txt: 100%|██████████| 525k/525k [00:01<00:00, 484kB/s]#015Downloading (…)tokenizer/merges.txt: 100%|██████████| 525k/525k [00:01<00:00, 484kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)cial_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]#015Downloading (…)cial_tokens_map.json: 100%|██████████| 460/460 [00:00<00:00, 172kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)okenizer_config.json:   0%|          | 0.00/824 [00:00<?, ?B/s]#015Downloading (…)okenizer_config.json: 100%|██████████| 824/824 [00:00<00:00, 309kB/s]\u001b[0m\n",
      "\u001b[34m/opt/ml/code/venv/lib/python3.9/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mSaving diffusers model...\n",
      " Restored system models. \n",
      " Allocated: 2.4GB \n",
      " Reserved: 2.5GB \n",
      " Allocated 2.4/2.4GB \n",
      " Reserved: 2.5/2.5GB \u001b[0m\n",
      "\u001b[34mCheckpoint successfully extracted to /opt/ml/input/data/dreambooth/aws-db-new-model/working\u001b[0m\n",
      "\u001b[34maws-db-new-model 0 ddim /opt/ml/input/data/models/768-v-ema.ckpt False True 768\u001b[0m\n",
      "\u001b[34mConcept 0 class dir is /opt/ml/input/data/images/\u001b[0m\n",
      "\u001b[34m{'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'adam_weight_decay': 0.01, 'attention': 'default', 'center_crop': False, 'concepts_path': '', 'custom_model_name': '', 'epoch_pause_frequency': 0.0, 'epoch_pause_time': 60.0, 'gradient_accumulation_steps': 1, 'gradient_checkpointing': True, 'half_model': False, 'hflip': True, 'learning_rate': 2e-06, 'lora_learning_rate': 0.0002, 'lora_txt_learning_rate': 0.0002, 'lr_scheduler': 'constant', 'lr_warmup_steps': 500, 'max_token_length': 75, 'max_train_steps': 0, 'mixed_precision': 'no', 'model_dir': '/opt/ml/input/data/dreambooth/aws-db-new-model', 'model_name': 'aws-db-new-model', 'not_cache_latents': True, 'num_train_epochs': 100, 'pad_tokens': True, 'pretrained_model_name_or_path': '/opt/ml/input/data/dreambooth/aws-db-new-model/working', 'pretrained_vae_name_or_path': '', 'prior_loss_weight': 1, 'resolution': 768, 'revision': 0, 'sample_batch_size': 1, 'save_class_txt': True, 'save_embedding_every': 500, 'save_preview_every': 500, 'save_use_global_counts': True, 'save_use_epochs': False, 'scale_lr': False, 'src': '/opt/ml/input/data/models/768-v-ema.ckpt', 'shuffle_tags': False, 'train_batch_size': 1, 'train_text_encoder': True, 'use_8bit_adam': False, 'use_concepts': False, 'use_cpu': False, 'use_ema': False, 'use_lora': False, 'scheduler': 'ddim', 'v2': True, 'has_ema': 'False', 'concepts_list': [{'max_steps': -1, 'instance_data_dir': '/opt/ml/input/data/images/', 'class_data_dir': '/opt/ml/input/data/images/', 'instance_prompt': 'Erwin Rommel', 'class_prompt': 'a photo of Erwin Rommel', 'save_sample_prompt': '', 'save_sample_template': '', 'instance_token': '', 'class_token': '', 'num_class_images': 0, 'class_negative_prompt': '', 'class_guidance_scale': 7.5, 'class_infer_steps': 40, 'save_sample_negative_prompt': '', 'n_save_sample': 1, 'sample_seed': -1, 'save_guidance_scale': 7.5, 'save_infer_steps': 40}]}\u001b[0m\n",
      "\u001b[34mImage count in /opt/ml/input/data/images/ is 9\u001b[0m\n",
      "\u001b[34mWizard results:<br>Num Epochs: 125.00000000000003<br>Max Steps: 0<br>Concept 0 Class Images: 0\u001b[0m\n",
      "\u001b[34mTotal VRAM: 15\u001b[0m\n",
      "\u001b[34mConcept 0 class dir is /opt/ml/input/data/images/\u001b[0m\n",
      "\u001b[34m{'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'adam_weight_decay': 0.01, 'attention': 'xformers', 'center_crop': False, 'concepts_path': '', 'custom_model_name': '', 'epoch_pause_frequency': 0.0, 'epoch_pause_time': 60.0, 'gradient_accumulation_steps': 1, 'gradient_checkpointing': True, 'half_model': False, 'hflip': True, 'learning_rate': 2e-06, 'lora_learning_rate': 0.0002, 'lora_txt_learning_rate': 0.0002, 'lr_scheduler': 'constant', 'lr_warmup_steps': 500, 'max_token_length': 75, 'max_train_steps': 0, 'mixed_precision': 'fp16', 'model_dir': '/opt/ml/input/data/dreambooth/aws-db-new-model', 'model_name': 'aws-db-new-model', 'not_cache_latents': True, 'num_train_epochs': 125, 'pad_tokens': True, 'pretrained_model_name_or_path': '/opt/ml/input/data/dreambooth/aws-db-new-model/working', 'pretrained_vae_name_or_path': '', 'prior_loss_weight': 1, 'resolution': 768, 'revision': 0, 'sample_batch_size': 1, 'save_class_txt': True, 'save_embedding_every': 500, 'save_preview_every': 500, 'save_use_global_counts': True, 'save_use_epochs': False, 'scale_lr': False, 'src': '/opt/ml/input/data/models/768-v-ema.ckpt', 'shuffle_tags': False, 'train_batch_size': 1, 'train_text_encoder': False, 'use_8bit_adam': True, 'use_concepts': False, 'use_cpu': False, 'use_ema': False, 'use_lora': False, 'scheduler': 'ddim', 'v2': True, 'has_ema': 'False', 'concepts_list': [{'max_steps': -1, 'instance_data_dir': '/opt/ml/input/data/images/', 'class_data_dir': '/opt/ml/input/data/images/', 'instance_prompt': 'Erwin Rommel', 'class_prompt': 'a photo of Erwin Rommel', 'save_sample_prompt': '', 'save_sample_template': '', 'instance_token': '', 'class_token': '', 'num_class_images': 0, 'class_negative_prompt': '', 'class_guidance_scale': 7.5, 'class_infer_steps': 40, 'save_sample_negative_prompt': '', 'n_save_sample': 1, 'sample_seed': -1, 'save_guidance_scale': 7.5, 'save_infer_steps': 40}]}\u001b[0m\n",
      "\u001b[34mCustom model name is \u001b[0m\n",
      "\u001b[34mStarting Dreambooth training...\n",
      " Allocated 0.0/2.4GB \n",
      " Reserved: 0.0/2.5GB \u001b[0m\n",
      "\u001b[34mInitializing dreambooth training...\u001b[0m\n",
      "\u001b[34mPatching transformers to fix kwargs errors.\u001b[0m\n",
      "\u001b[34mReplace CrossAttention.forward to use xformers\u001b[0m\n",
      "\u001b[34mChecking concept: {'max_steps': -1, 'instance_data_dir': '/opt/ml/input/data/images/', 'class_data_dir': '/opt/ml/input/data/images/', 'instance_prompt': 'Erwin Rommel', 'class_prompt': 'a photo of Erwin Rommel', 'save_sample_prompt': '', 'save_sample_template': '', 'instance_token': '', 'class_token': '', 'num_class_images': 0, 'class_negative_prompt': '', 'class_guidance_scale': 7.5, 'class_infer_steps': 40, 'save_sample_negative_prompt': '', 'n_save_sample': 1, 'sample_seed': -1, 'save_guidance_scale': 7.5, 'save_infer_steps': 40}\u001b[0m\n",
      "\u001b[34mConcept requires 0 images.\n",
      " Loaded model. \n",
      " Allocated: 0.0GB \n",
      " Reserved: 0.0GB \u001b[0m\n",
      "\u001b[34m===================================BUG REPORT===================================\u001b[0m\n",
      "\u001b[34mWelcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\u001b[0m\n",
      "\u001b[34mFor effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\u001b[0m\n",
      "\u001b[34m================================================================================\u001b[0m\n",
      "\u001b[34mCUDA SETUP: CUDA runtime path found: /opt/conda/lib/libcudart.so\u001b[0m\n",
      "\u001b[34mCUDA SETUP: Highest compute capability among GPUs detected: 7.5\u001b[0m\n",
      "\u001b[34mCUDA SETUP: Detected CUDA version 113\u001b[0m\n",
      "\u001b[34mCUDA SETUP: Loading binary /opt/ml/code/venv/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...\n",
      " Scheduler, EMA Loaded. \n",
      " Allocated: 4.0GB \n",
      " Reserved: 4.1GB \u001b[0m\n",
      "\u001b[34m***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num batches each epoch = 9\n",
      "  Num Epochs = 125\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1125\n",
      "  Actual steps: 1125\n",
      "   Training settings: CPU: False Adam: True, Prec: fp16, Grad: True, TextTr: False EM: False, LR: 2e-06 LORA:False \n",
      " Allocated: 4.0GB \n",
      " Reserved: 4.1GB \u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1125 [00:00<?, ?it/s]#015Steps:   0%|          | 0/1125 [00:00<?, ?it/s]#015Steps:   0%|          | 0/1125 [00:05<?, ?it/s, loss=0.293, lr=2e-6, vram=5.7/9.0GB]#015Steps:   0%|          | 1/1125 [00:05<1:43:03,  5.50s/it, loss=0.293, lr=2e-6, vram=5.7/9.0GB]#015Steps:   0%|          | 2/1125 [00:06<55:05,  2.94s/it, loss=0.293, lr=2e-6, vram=5.7/9.0GB]  #015Steps:   0%|          | 2/1125 [00:07<55:05,  2.94s/it, loss=0.34, lr=2e-6, vram=5.7/9.7GB] #015Steps:   0%|          | 3/1125 [00:07<39:32,  2.11s/it, loss=0.34, lr=2e-6, vram=5.7/9.7GB]#015Steps:   0%|          | 4/1125 [00:08<32:24,  1.73s/it, loss=0.34, lr=2e-6, vram=5.7/9.7GB]#015Steps:   0%|          | 4/1125 [00:10<32:24,  1.73s/it, loss=0.267, lr=2e-6, vram=5.7/9.7GB]#015Steps:   0%|          | 5/1125 [00:10<28:28,  1.53s/it, loss=0.267, lr=2e-6, vram=5.7/9.7GB]#015Steps:   1%|          | 6/1125 [00:11<26:07,  1.40s/it, loss=0.267, lr=2e-6, vram=5.7/9.7GB]#015Steps:   1%|          | 6/1125 [00:12<26:07,  1.40s/it, loss=0.383, lr=2e-6, vram=5.7/9.7GB]#015Steps:   1%|          | 7/1125 [00:12<24:29,  1.31s/it, loss=0.383, lr=2e-6, vram=5.7/9.7GB]#015Steps:   1%|          | 8/1125 [00:13<23:27,  1.26s/it, loss=0.383, lr=2e-6, vram=5.7/9.7GB]#015Steps:   1%|          | 8/1125 [00:14<23:27,  1.26s/it, loss=0.287, lr=2e-6, vram=5.7/9.7GB]#015Steps:   1%|          | 9/1125 [00:14<22:39,  1.22s/it, loss=0.287, lr=2e-6, vram=5.7/9.7GB]#015Steps:   1%|          | 10/1125 [00:15<22:21,  1.20s/it, loss=0.287, lr=2e-6, vram=5.7/9.7GB]#015Steps:   1%|          | 10/1125 [00:16<22:21,  1.20s/it, loss=0.285, lr=2e-6, vram=5.7/9.7GB]#015Steps:   1%|          | 11/1125 [00:16<22:06,  1.19s/it, loss=0.285, lr=2e-6, vram=5.7/9.7GB]#015Steps:   1%|          | 12/1125 [00:18<21:45,  1.17s/it, loss=0.285, lr=2e-6, vram=5.7/9.7GB]#015Steps:   1%|          | 12/1125 [00:19<21:45,  1.17s/it, loss=0.567, lr=2e-6, vram=5.7/9.7GB]#015Steps:   1%|          | 13/1125 [00:19<21:39,  1.17s/it, loss=0.567, lr=2e-6, vram=5.7/9.7GB]#015Steps:   1%|          | 14/1125 [00:20<21:34,  1.17s/it, loss=0.567, lr=2e-6, vram=5.7/9.7GB]#015Steps:   1%|          | 14/1125 [00:21<21:34,  1.17s/it, loss=0.442, lr=2e-6, vram=5.7/9.7GB]#015Steps:   1%|▏         | 15/1125 [00:21<21:23,  1.16s/it, loss=0.442, lr=2e-6, vram=5.7/9.7GB]#015Steps:   1%|▏         | 16/1125 [00:22<21:16,  1.15s/it, loss=0.442, lr=2e-6, vram=5.7/9.7GB]#015Steps:   1%|▏         | 16/1125 [00:23<21:16,  1.15s/it, loss=0.279, lr=2e-6, vram=5.7/9.7GB]#015Steps:   2%|▏         | 17/1125 [00:23<21:16,  1.15s/it, loss=0.279, lr=2e-6, vram=5.7/9.7GB]#015Steps:   2%|▏         | 18/1125 [00:24<21:06,  1.14s/it, loss=0.279, lr=2e-6, vram=5.7/9.7GB]#015Steps:   2%|▏         | 18/1125 [00:26<21:06,  1.14s/it, loss=0.289, lr=2e-6, vram=5.7/9.7GB]#015Steps:   2%|▏         | 19/1125 [00:26<21:16,  1.15s/it, loss=0.289, lr=2e-6, vram=5.7/9.7GB]#015Steps:   2%|▏         | 20/1125 [00:27<21:16,  1.16s/it, loss=0.289, lr=2e-6, vram=5.7/9.7GB]#015Steps:   2%|▏         | 20/1125 [00:28<21:16,  1.16s/it, loss=0.344, lr=2e-6, vram=5.7/9.7GB]#015Steps:   2%|▏         | 21/1125 [00:28<21:12,  1.15s/it, loss=0.344, lr=2e-6, vram=5.7/9.7GB]#015Steps:   2%|▏         | 22/1125 [00:29<21:09,  1.15s/it, loss=0.344, lr=2e-6, vram=5.7/9.7GB]#015Steps:   2%|▏         | 22/1125 [00:30<21:09,  1.15s/it, loss=0.557, lr=2e-6, vram=5.7/9.7GB]#015Steps:   2%|▏         | 23/1125 [00:30<21:15,  1.16s/it, loss=0.557, lr=2e-6, vram=5.7/9.7GB]#015Steps:   2%|▏         | 24/1125 [00:31<21:16,  1.16s/it, loss=0.557, lr=2e-6, vram=5.7/9.7GB]#015Steps:   2%|▏         | 24/1125 [00:33<21:16,  1.16s/it, loss=0.486, lr=2e-6, vram=5.7/9.7GB]#015Steps:   2%|▏         | 25/1125 [00:33<21:12,  1.16s/it, loss=0.486, lr=2e-6, vram=5.7/9.7GB]#015Steps:   2%|▏         | 26/1125 [00:34<21:15,  1.16s/it, loss=0.486, lr=2e-6, vram=5.7/9.7GB]#015Steps:   2%|▏         | 26/1125 [00:35<21:15,  1.16s/it, loss=0.391, lr=2e-6, vram=5.7/9.7GB]#015Steps:   2%|▏         | 27/1125 [00:35<21:06,  1.15s/it, loss=0.391, lr=2e-6, vram=5.7/9.7GB]#015Steps:   2%|▏         | 28/1125 [00:36<21:14,  1.16s/it, loss=0.391, lr=2e-6, vram=5.7/9.7GB]#015Steps:   2%|▏         | 28/1125 [00:37<21:14,  1.16s/it, loss=0.533, lr=2e-6, vram=5.7/9.7GB]#015Steps:   3%|▎         | 29/1125 [00:37<21:18,  1.17s/it, loss=0.533, lr=2e-6, vram=5.7/9.7GB]#015Steps:   3%|▎         | 30/1125 [00:38<21:18,  1.17s/it, loss=0.533, lr=2e-6, vram=5.7/9.7GB]#015Steps:   3%|▎         | 30/1125 [00:40<21:18,  1.17s/it, loss=0.605, lr=2e-6, vram=5.7/9.7GB]#015Steps:   3%|▎         | 31/1125 [00:40<21:09,  1.16s/it, loss=0.605, lr=2e-6, vram=5.7/9.7GB]#015Steps:   3%|▎         | 32/1125 [00:41<21:09,  1.16s/it, loss=0.605, lr=2e-6, vram=5.7/9.7GB]#015Steps:   3%|▎         | 32/1125 [00:42<21:09,  1.16s/it, loss=0.328, lr=2e-6, vram=5.7/9.7GB]#015Steps:   3%|▎         | 33/1125 [00:42<21:03,  1.16s/it, loss=0.328, lr=2e-6, vram=5.7/9.7GB]#015Steps:   3%|▎         | 34/1125 [00:43<21:06,  1.16s/it, loss=0.328, lr=2e-6, vram=5.7/9.7GB]#015Steps:   3%|▎         | 34/1125 [00:44<21:06,  1.16s/it, loss=0.383, lr=2e-6, vram=5.7/9.7GB]#015Steps:   3%|▎         | 35/1125 [00:44<21:04,  1.16s/it, loss=0.383, lr=2e-6, vram=5.7/9.7GB]#015Steps:   3%|▎         | 36/1125 [00:45<20:57,  1.15s/it, loss=0.383, lr=2e-6, vram=5.7/9.7GB]#015Steps:   3%|▎         | 36/1125 [00:47<20:57,  1.15s/it, loss=0.344, lr=2e-6, vram=5.7/9.7GB]#015Steps:   3%|▎         | 37/1125 [00:47<21:07,  1.17s/it, loss=0.344, lr=2e-6, vram=5.7/9.7GB]#015Steps:   3%|▎         | 38/1125 [00:48<21:12,  1.17s/it, loss=0.344, lr=2e-6, vram=5.7/9.7GB]#015Steps:   3%|▎         | 38/1125 [00:49<21:12,  1.17s/it, loss=0.439, lr=2e-6, vram=5.7/9.7GB]#015Steps:   3%|▎         | 39/1125 [00:49<21:10,  1.17s/it, loss=0.439, lr=2e-6, vram=5.7/9.7GB]#015Steps:   4%|▎         | 40/1125 [00:50<21:04,  1.16s/it, loss=0.439, lr=2e-6, vram=5.7/9.7GB]#015Steps:   4%|▎         | 40/1125 [00:51<21:04,  1.16s/it, loss=0.3, lr=2e-6, vram=5.7/9.7GB]  #015Steps:   4%|▎         | 41/1125 [00:51<21:00,  1.16s/it, loss=0.3, lr=2e-6, vram=5.7/9.7GB]#015Steps:   4%|▎         | 42/1125 [00:52<21:03,  1.17s/it, loss=0.3, lr=2e-6, vram=5.7/9.7GB]#015Steps:   4%|▎         | 42/1125 [00:54<21:03,  1.17s/it, loss=0.391, lr=2e-6, vram=5.7/9.7GB]#015Steps:   4%|▍         | 43/1125 [00:54<21:05,  1.17s/it, loss=0.391, lr=2e-6, vram=5.7/9.7GB]#015Steps:   4%|▍         | 44/1125 [00:55<21:02,  1.17s/it, loss=0.391, lr=2e-6, vram=5.7/9.7GB]#015Steps:   4%|▍         | 44/1125 [00:56<21:02,  1.17s/it, loss=0.332, lr=2e-6, vram=5.7/9.7GB]#015Steps:   4%|▍         | 45/1125 [00:56<20:53,  1.16s/it, loss=0.332, lr=2e-6, vram=5.7/9.7GB]#015Steps:   4%|▍         | 46/1125 [00:57<21:09,  1.18s/it, loss=0.332, lr=2e-6, vram=5.7/9.7GB]#015Steps:   4%|▍         | 46/1125 [00:58<21:09,  1.18s/it, loss=0.433, lr=2e-6, vram=5.7/9.7GB]#015Steps:   4%|▍         | 47/1125 [00:58<21:03,  1.17s/it, loss=0.433, lr=2e-6, vram=5.7/9.7GB]#015Steps:   4%|▍         | 48/1125 [00:59<20:59,  1.17s/it, loss=0.433, lr=2e-6, vram=5.7/9.7GB]#015Steps:   4%|▍         | 48/1125 [01:01<20:59,  1.17s/it, loss=0.423, lr=2e-6, vram=5.7/9.7GB]#015Steps:   4%|▍         | 49/1125 [01:01<21:03,  1.17s/it, loss=0.423, lr=2e-6, vram=5.7/9.7GB]#015Steps:   4%|▍         | 50/1125 [01:02<20:59,  1.17s/it, loss=0.423, lr=2e-6, vram=5.7/9.7GB]#015Steps:   4%|▍         | 50/1125 [01:03<20:59,  1.17s/it, loss=0.298, lr=2e-6, vram=5.7/9.7GB]#015Steps:   5%|▍         | 51/1125 [01:03<20:53,  1.17s/it, loss=0.298, lr=2e-6, vram=5.7/9.7GB]#015Steps:   5%|▍         | 52/1125 [01:04<20:54,  1.17s/it, loss=0.298, lr=2e-6, vram=5.7/9.7GB]#015Steps:   5%|▍         | 52/1125 [01:05<20:54,  1.17s/it, loss=0.386, lr=2e-6, vram=5.7/9.7GB]#015Steps:   5%|▍         | 53/1125 [01:05<20:49,  1.17s/it, loss=0.386, lr=2e-6, vram=5.7/9.7GB]#015Steps:   5%|▍         | 54/1125 [01:06<20:44,  1.16s/it, loss=0.386, lr=2e-6, vram=5.7/9.7GB]#015Steps:   5%|▍         | 54/1125 [01:08<20:44,  1.16s/it, loss=0.25, lr=2e-6, vram=5.7/9.7GB] #015Steps:   5%|▍         | 55/1125 [01:08<20:55,  1.17s/it, loss=0.25, lr=2e-6, vram=5.7/9.7GB]#015Steps:   5%|▍         | 56/1125 [01:09<20:48,  1.17s/it, loss=0.25, lr=2e-6, vram=5.7/9.7GB]#015Steps:   5%|▍         | 56/1125 [01:10<20:48,  1.17s/it, loss=0.452, lr=2e-6, vram=5.7/9.7GB]#015Steps:   5%|▌         | 57/1125 [01:10<20:50,  1.17s/it, loss=0.452, lr=2e-6, vram=5.7/9.7GB]#015Steps:   5%|▌         | 58/1125 [01:11<20:49,  1.17s/it, loss=0.452, lr=2e-6, vram=5.7/9.7GB]#015Steps:   5%|▌         | 58/1125 [01:12<20:49,  1.17s/it, loss=0.4, lr=2e-6, vram=5.7/9.7GB]  #015Steps:   5%|▌         | 59/1125 [01:12<20:56,  1.18s/it, loss=0.4, lr=2e-6, vram=5.7/9.7GB]#015Steps:   5%|▌         | 60/1125 [01:13<20:58,  1.18s/it, loss=0.4, lr=2e-6, vram=5.7/9.7GB]#015Steps:   5%|▌         | 60/1125 [01:15<20:58,  1.18s/it, loss=0.494, lr=2e-6, vram=5.7/9.7GB]#015Steps:   5%|▌         | 61/1125 [01:15<20:51,  1.18s/it, loss=0.494, lr=2e-6, vram=5.7/9.7GB]#015Steps:   6%|▌         | 62/1125 [01:16<20:51,  1.18s/it, loss=0.494, lr=2e-6, vram=5.7/9.7GB]#015Steps:   6%|▌         | 62/1125 [01:17<20:51,  1.18s/it, loss=0.372, lr=2e-6, vram=5.7/9.7GB]#015Steps:   6%|▌         | 63/1125 [01:17<20:42,  1.17s/it, loss=0.372, lr=2e-6, vram=5.7/9.7GB]#015Steps:   6%|▌         | 64/1125 [01:18<20:57,  1.19s/it, loss=0.372, lr=2e-6, vram=5.7/9.7GB]#015Steps:   6%|▌         | 64/1125 [01:19<20:57,  1.19s/it, loss=0.312, lr=2e-6, vram=5.7/9.7GB]#015Steps:   6%|▌         | 65/1125 [01:19<20:55,  1.18s/it, loss=0.312, lr=2e-6, vram=5.7/9.7GB]#015Steps:   6%|▌         | 66/1125 [01:21<20:57,  1.19s/it, loss=0.312, lr=2e-6, vram=5.7/9.7GB]#015Steps:   6%|▌         | 66/1125 [01:22<20:57,  1.19s/it, loss=0.321, lr=2e-6, vram=5.7/9.7GB]#015Steps:   6%|▌         | 67/1125 [01:22<20:50,  1.18s/it, loss=0.321, lr=2e-6, vram=5.7/9.7GB]#015Steps:   6%|▌         | 68/1125 [01:23<20:43,  1.18s/it, loss=0.321, lr=2e-6, vram=5.7/9.7GB]#015Steps:   6%|▌         | 68/1125 [01:24<20:43,  1.18s/it, loss=0.346, lr=2e-6, vram=5.7/9.7GB]#015Steps:   6%|▌         | 69/1125 [01:24<20:40,  1.17s/it, loss=0.346, lr=2e-6, vram=5.7/9.7GB]#015Steps:   6%|▌         | 70/1125 [01:25<20:37,  1.17s/it, loss=0.346, lr=2e-6, vram=5.7/9.7GB]#015Steps:   6%|▌         | 70/1125 [01:26<20:37,  1.17s/it, loss=0.337, lr=2e-6, vram=5.7/9.7GB]#015Steps:   6%|▋         | 71/1125 [01:26<20:41,  1.18s/it, loss=0.337, lr=2e-6, vram=5.7/9.7GB]#015Steps:   6%|▋         | 72/1125 [01:28<20:33,  1.17s/it, loss=0.337, lr=2e-6, vram=5.7/9.7GB]#015Steps:   6%|▋         | 72/1125 [01:29<20:33,  1.17s/it, loss=0.376, lr=2e-6, vram=5.7/9.7GB]#015Steps:   6%|▋         | 73/1125 [01:29<20:52,  1.19s/it, loss=0.376, lr=2e-6, vram=5.7/9.7GB]#015Steps:   7%|▋         | 74/1125 [01:30<20:51,  1.19s/it, loss=0.376, lr=2e-6, vram=5.7/9.7GB]#015Steps:   7%|▋         | 74/1125 [01:31<20:51,  1.19s/it, loss=0.449, lr=2e-6, vram=5.7/9.7GB]#015Steps:   7%|▋         | 75/1125 [01:31<20:46,  1.19s/it, loss=0.449, lr=2e-6, vram=5.7/9.7GB]#015Steps:   7%|▋         | 76/1125 [01:32<20:40,  1.18s/it, loss=0.449, lr=2e-6, vram=5.7/9.7GB]#015Steps:   7%|▋         | 76/1125 [01:34<20:40,  1.18s/it, loss=0.276, lr=2e-6, vram=5.7/9.7GB]#015Steps:   7%|▋         | 77/1125 [01:34<20:36,  1.18s/it, loss=0.276, lr=2e-6, vram=5.7/9.7GB]#015Steps:   7%|▋         | 78/1125 [01:35<20:32,  1.18s/it, loss=0.276, lr=2e-6, vram=5.7/9.7GB]#015Steps:   7%|▋         | 78/1125 [01:36<20:32,  1.18s/it, loss=0.519, lr=2e-6, vram=5.7/9.7GB]#015Steps:   7%|▋         | 79/1125 [01:36<20:34,  1.18s/it, loss=0.519, lr=2e-6, vram=5.7/9.7GB]#015Steps:   7%|▋         | 80/1125 [01:37<20:33,  1.18s/it, loss=0.519, lr=2e-6, vram=5.7/9.7GB]#015Steps:   7%|▋         | 80/1125 [01:38<20:33,  1.18s/it, loss=0.586, lr=2e-6, vram=5.7/9.7GB]#015Steps:   7%|▋         | 81/1125 [01:38<20:26,  1.18s/it, loss=0.586, lr=2e-6, vram=5.7/9.7GB]#015Steps:   7%|▋         | 82/1125 [01:39<20:39,  1.19s/it, loss=0.586, lr=2e-6, vram=5.7/9.7GB]#015Steps:   7%|▋         | 82/1125 [01:41<20:39,  1.19s/it, loss=0.351, lr=2e-6, vram=5.7/9.7GB]#015Steps:   7%|▋         | 83/1125 [01:41<20:33,  1.18s/it, loss=0.351, lr=2e-6, vram=5.7/9.7GB]#015Steps:   7%|▋         | 84/1125 [01:42<20:37,  1.19s/it, loss=0.351, lr=2e-6, vram=5.7/9.7GB]#015Steps:   7%|▋         | 84/1125 [01:43<20:37,  1.19s/it, loss=0.252, lr=2e-6, vram=5.7/9.7GB]#015Steps:   8%|▊         | 85/1125 [01:43<20:32,  1.19s/it, loss=0.252, lr=2e-6, vram=5.7/9.7GB]#015Steps:   8%|▊         | 86/1125 [01:44<20:36,  1.19s/it, loss=0.252, lr=2e-6, vram=5.7/9.7GB]#015Steps:   8%|▊         | 86/1125 [01:45<20:36,  1.19s/it, loss=0.333, lr=2e-6, vram=5.7/9.7GB]#015Steps:   8%|▊         | 87/1125 [01:45<20:29,  1.18s/it, loss=0.333, lr=2e-6, vram=5.7/9.7GB]#015Steps:   8%|▊         | 88/1125 [01:47<20:26,  1.18s/it, loss=0.333, lr=2e-6, vram=5.7/9.7GB]#015Steps:   8%|▊         | 88/1125 [01:48<20:26,  1.18s/it, loss=0.438, lr=2e-6, vram=5.7/9.7GB]#015Steps:   8%|▊         | 89/1125 [01:48<20:29,  1.19s/it, loss=0.438, lr=2e-6, vram=5.7/9.7GB]#015Steps:   8%|▊         | 90/1125 [01:49<20:21,  1.18s/it, loss=0.438, lr=2e-6, vram=5.7/9.7GB]#015Steps:   8%|▊         | 90/1125 [01:50<20:21,  1.18s/it, loss=0.578, lr=2e-6, vram=5.7/9.7GB]#015Steps:   8%|▊         | 91/1125 [01:50<20:29,  1.19s/it, loss=0.578, lr=2e-6, vram=5.7/9.7GB]#015Steps:   8%|▊         | 92/1125 [01:51<20:30,  1.19s/it, loss=0.578, lr=2e-6, vram=5.7/9.7GB]#015Steps:   8%|▊         | 92/1125 [01:53<20:30,  1.19s/it, loss=0.317, lr=2e-6, vram=5.7/9.7GB]#015Steps:   8%|▊         | 93/1125 [01:53<20:30,  1.19s/it, loss=0.317, lr=2e-6, vram=5.7/9.7GB]#015Steps:   8%|▊         | 94/1125 [01:54<20:30,  1.19s/it, loss=0.317, lr=2e-6, vram=5.7/9.7GB]#015Steps:   8%|▊         | 94/1125 [01:55<20:30,  1.19s/it, loss=0.464, lr=2e-6, vram=5.7/9.7GB]#015Steps:   8%|▊         | 95/1125 [01:55<20:24,  1.19s/it, loss=0.464, lr=2e-6, vram=5.7/9.7GB]#015Steps:   9%|▊         | 96/1125 [01:56<20:29,  1.19s/it, loss=0.464, lr=2e-6, vram=5.7/9.7GB]#015Steps:   9%|▊         | 96/1125 [01:57<20:29,  1.19s/it, loss=0.361, lr=2e-6, vram=5.7/9.7GB]#015Steps:   9%|▊         | 97/1125 [01:57<20:23,  1.19s/it, loss=0.361, lr=2e-6, vram=5.7/9.7GB]#015Steps:   9%|▊         | 98/1125 [01:58<20:17,  1.19s/it, loss=0.361, lr=2e-6, vram=5.7/9.7GB]#015Steps:   9%|▊         | 98/1125 [02:00<20:17,  1.19s/it, loss=0.428, lr=2e-6, vram=5.7/9.7GB]#015Steps:   9%|▉         | 99/1125 [02:00<20:13,  1.18s/it, loss=0.428, lr=2e-6, vram=5.7/9.7GB]#015Steps:   9%|▉         | 100/1125 [02:01<20:24,  1.19s/it, loss=0.428, lr=2e-6, vram=5.7/9.7GB]#015Steps:   9%|▉         | 100/1125 [02:02<20:24,  1.19s/it, loss=0.36, lr=2e-6, vram=5.7/9.7GB] #015Steps:   9%|▉         | 101/1125 [02:02<20:24,  1.20s/it, loss=0.36, lr=2e-6, vram=5.7/9.7GB]#015Steps:   9%|▉         | 102/1125 [02:03<20:24,  1.20s/it, loss=0.36, lr=2e-6, vram=5.7/9.7GB]#015Steps:   9%|▉         | 102/1125 [02:04<20:24,  1.20s/it, loss=0.354, lr=2e-6, vram=5.7/9.7GB]#015Steps:   9%|▉         | 103/1125 [02:04<20:23,  1.20s/it, loss=0.354, lr=2e-6, vram=5.7/9.7GB]#015Steps:   9%|▉         | 104/1125 [02:06<20:16,  1.19s/it, loss=0.354, lr=2e-6, vram=5.7/9.7GB]#015Steps:   9%|▉         | 104/1125 [02:07<20:16,  1.19s/it, loss=0.494, lr=2e-6, vram=5.7/9.7GB]#015Steps:   9%|▉         | 105/1125 [02:07<20:11,  1.19s/it, loss=0.494, lr=2e-6, vram=5.7/9.7GB]#015Steps:   9%|▉         | 106/1125 [02:08<20:16,  1.19s/it, loss=0.494, lr=2e-6, vram=5.7/9.7GB]#015Steps:   9%|▉         | 106/1125 [02:09<20:16,  1.19s/it, loss=0.351, lr=2e-6, vram=5.7/9.7GB]#015Steps:  10%|▉         | 107/1125 [02:09<20:12,  1.19s/it, loss=0.351, lr=2e-6, vram=5.7/9.7GB]#015Steps:  10%|▉         | 108/1125 [02:10<20:05,  1.18s/it, loss=0.351, lr=2e-6, vram=5.7/9.7GB]#015Steps:  10%|▉         | 108/1125 [02:12<20:05,  1.18s/it, loss=0.473, lr=2e-6, vram=5.7/9.7GB]#015Steps:  10%|▉         | 109/1125 [02:12<20:18,  1.20s/it, loss=0.473, lr=2e-6, vram=5.7/9.7GB]#015Steps:  10%|▉         | 110/1125 [02:13<20:10,  1.19s/it, loss=0.473, lr=2e-6, vram=5.7/9.7GB]#015Steps:  10%|▉         | 110/1125 [02:14<20:10,  1.19s/it, loss=0.371, lr=2e-6, vram=5.7/9.7GB]#015Steps:  10%|▉         | 111/1125 [02:14<20:14,  1.20s/it, loss=0.371, lr=2e-6, vram=5.7/9.7GB]#015Steps:  10%|▉         | 112/1125 [02:15<20:18,  1.20s/it, loss=0.371, lr=2e-6, vram=5.7/9.7GB]#015Steps:  10%|▉         | 112/1125 [02:16<20:18,  1.20s/it, loss=0.308, lr=2e-6, vram=5.7/9.7GB]#015Steps:  10%|█         | 113/1125 [02:16<20:16,  1.20s/it, loss=0.308, lr=2e-6, vram=5.7/9.7GB]#015Steps:  10%|█         | 114\u001b[0m\n",
      "\u001b[34m/1125 [02:18<20:10,  1.20s/it, loss=0.308, lr=2e-6, vram=5.7/9.7GB]#015Steps:  10%|█         | 114/1125 [02:19<20:10,  1.20s/it, loss=0.254, lr=2e-6, vram=5.7/9.7GB]#015Steps:  10%|█         | 115/1125 [02:19<20:08,  1.20s/it, loss=0.254, lr=2e-6, vram=5.7/9.7GB]#015Steps:  10%|█         | 116/1125 [02:20<20:02,  1.19s/it, loss=0.254, lr=2e-6, vram=5.7/9.7GB]#015Steps:  10%|█         | 116/1125 [02:21<20:02,  1.19s/it, loss=0.307, lr=2e-6, vram=5.7/9.7GB]#015Steps:  10%|█         | 117/1125 [02:21<19:56,  1.19s/it, loss=0.307, lr=2e-6, vram=5.7/9.7GB]#015Steps:  10%|█         | 118/1125 [02:22<20:09,  1.20s/it, loss=0.307, lr=2e-6, vram=5.7/9.7GB]#015Steps:  10%|█         | 118/1125 [02:24<20:09,  1.20s/it, loss=0.346, lr=2e-6, vram=5.7/9.7GB]#015Steps:  11%|█         | 119/1125 [02:24<20:05,  1.20s/it, loss=0.346, lr=2e-6, vram=5.7/9.7GB]#015Steps:  11%|█         | 120/1125 [02:25<20:05,  1.20s/it, loss=0.346, lr=2e-6, vram=5.7/9.7GB]#015Steps:  11%|█         | 120/1125 [02:26<20:05,  1.20s/it, loss=0.254, lr=2e-6, vram=5.7/9.7GB]#015Steps:  11%|█         | 121/1125 [02:26<19:59,  1.20s/it, loss=0.254, lr=2e-6, vram=5.7/9.7GB]#015Steps:  11%|█         | 122/1125 [02:27<19:55,  1.19s/it, loss=0.254, lr=2e-6, vram=5.7/9.7GB]#015Steps:  11%|█         | 122/1125 [02:28<19:55,  1.19s/it, loss=0.279, lr=2e-6, vram=5.7/9.7GB]#015Steps:  11%|█         | 123/1125 [02:28<19:56,  1.19s/it, loss=0.279, lr=2e-6, vram=5.7/9.7GB]#015Steps:  11%|█         | 124/1125 [02:30<20:02,  1.20s/it, loss=0.279, lr=2e-6, vram=5.7/9.7GB]#015Steps:  11%|█         | 124/1125 [02:31<20:02,  1.20s/it, loss=0.389, lr=2e-6, vram=5.7/9.7GB]#015Steps:  11%|█         | 125/1125 [02:31<19:56,  1.20s/it, loss=0.389, lr=2e-6, vram=5.7/9.7GB]#015Steps:  11%|█         | 126/1125 [02:32<19:48,  1.19s/it, loss=0.389, lr=2e-6, vram=5.7/9.7GB]#015Steps:  11%|█         | 126/1125 [02:33<19:48,  1.19s/it, loss=0.349, lr=2e-6, vram=5.7/9.7GB]#015Steps:  11%|█▏        | 127/1125 [02:33<20:00,  1.20s/it, loss=0.349, lr=2e-6, vram=5.7/9.7GB]#015Steps:  11%|█▏        | 128/1125 [02:34<19:53,  1.20s/it, loss=0.349, lr=2e-6, vram=5.7/9.7GB]#015Steps:  11%|█▏        | 128/1125 [02:36<19:53,  1.20s/it, loss=0.335, lr=2e-6, vram=5.7/9.7GB]#015Steps:  11%|█▏        | 129/1125 [02:36<19:56,  1.20s/it, loss=0.335, lr=2e-6, vram=5.7/9.7GB]#015Steps:  12%|█▏        | 130/1125 [02:37<19:50,  1.20s/it, loss=0.335, lr=2e-6, vram=5.7/9.7GB]#015Steps:  12%|█▏        | 130/1125 [02:38<19:50,  1.20s/it, loss=0.355, lr=2e-6, vram=5.7/9.7GB]#015Steps:  12%|█▏        | 131/1125 [02:38<19:48,  1.20s/it, loss=0.355, lr=2e-6, vram=5.7/9.7GB]#015Steps:  12%|█▏        | 132/1125 [02:39<19:44,  1.19s/it, loss=0.355, lr=2e-6, vram=5.7/9.7GB]#015Steps:  12%|█▏        | 132/1125 [02:40<19:44,  1.19s/it, loss=0.286, lr=2e-6, vram=5.7/9.7GB]#015Steps:  12%|█▏        | 133/1125 [02:40<19:50,  1.20s/it, loss=0.286, lr=2e-6, vram=5.7/9.7GB]#015Steps:  12%|█▏        | 134/1125 [02:42<19:53,  1.20s/it, loss=0.286, lr=2e-6, vram=5.7/9.7GB]#015Steps:  12%|█▏        | 134/1125 [02:43<19:53,  1.20s/it, loss=0.33, lr=2e-6, vram=5.7/9.7GB] #015Steps:  12%|█▏        | 135/1125 [02:43<19:44,  1.20s/it, loss=0.33, lr=2e-6, vram=5.7/9.7GB]#015Steps:  12%|█▏        | 136/1125 [02:44<19:52,  1.21s/it, loss=0.33, lr=2e-6, vram=5.7/9.7GB]#015Steps:  12%|█▏        | 136/1125 [02:45<19:52,  1.21s/it, loss=0.33, lr=2e-6, vram=5.7/9.7GB]#015Steps:  12%|█▏        | 137/1125 [02:45<19:51,  1.21s/it, loss=0.33, lr=2e-6, vram=5.7/9.7GB]#015Steps:  12%|█▏        | 138/1125 [02:46<19:45,  1.20s/it, loss=0.33, lr=2e-6, vram=5.7/9.7GB]#015Steps:  12%|█▏        | 138/1125 [02:48<19:45,  1.20s/it, loss=0.383, lr=2e-6, vram=5.7/9.7GB]#015Steps:  12%|█▏        | 139/1125 [02:48<19:45,  1.20s/it, loss=0.383, lr=2e-6, vram=5.7/9.7GB]#015Steps:  12%|█▏        | 140/1125 [02:49<19:45,  1.20s/it, loss=0.383, lr=2e-6, vram=5.7/9.7GB]#015Steps:  12%|█▏        | 140/1125 [02:50<19:45,  1.20s/it, loss=0.351, lr=2e-6, vram=5.7/9.7GB]#015Steps:  13%|█▎        | 141/1125 [02:50<19:41,  1.20s/it, loss=0.351, lr=2e-6, vram=5.7/9.7GB]#015Steps:  13%|█▎        | 142/1125 [02:51<19:35,  1.20s/it, loss=0.351, lr=2e-6, vram=5.7/9.7GB]#015Steps:  13%|█▎        | 142/1125 [02:52<19:35,  1.20s/it, loss=0.311, lr=2e-6, vram=5.7/9.7GB]#015Steps:  13%|█▎        | 143/1125 [02:52<19:42,  1.20s/it, loss=0.311, lr=2e-6, vram=5.7/9.7GB]#015Steps:  13%|█▎        | 144/1125 [02:54<19:33,  1.20s/it, loss=0.311, lr=2e-6, vram=5.7/9.7GB]#015Steps:  13%|█▎        | 144/1125 [02:55<19:33,  1.20s/it, loss=0.635, lr=2e-6, vram=5.7/9.7GB]#015Steps:  13%|█▎        | 145/1125 [02:55<19:39,  1.20s/it, loss=0.635, lr=2e-6, vram=5.7/9.7GB]#015Steps:  13%|█▎        | 146/1125 [02:56<19:41,  1.21s/it, loss=0.635, lr=2e-6, vram=5.7/9.7GB]#015Steps:  13%|█▎        | 146/1125 [02:57<19:41,  1.21s/it, loss=0.405, lr=2e-6, vram=5.7/9.7GB]#015Steps:  13%|█▎        | 147/1125 [02:57<19:41,  1.21s/it, loss=0.405, lr=2e-6, vram=5.7/9.7GB]#015Steps:  13%|█▎        | 148/1125 [02:58<19:34,  1.20s/it, loss=0.405, lr=2e-6, vram=5.7/9.7GB]#015Steps:  13%|█▎        | 148/1125 [03:00<19:34,  1.20s/it, loss=0.338, lr=2e-6, vram=5.7/9.7GB]#015Steps:  13%|█▎        | 149/1125 [03:00<19:39,  1.21s/it, loss=0.338, lr=2e-6, vram=5.7/9.7GB]#015Steps:  13%|█▎        | 150/1125 [03:01<19:34,  1.20s/it, loss=0.338, lr=2e-6, vram=5.7/9.7GB]#015Steps:  13%|█▎        | 150/1125 [03:02<19:34,  1.20s/it, loss=0.319, lr=2e-6, vram=5.7/9.7GB]#015Steps:  13%|█▎        | 151/1125 [03:02<19:34,  1.21s/it, loss=0.319, lr=2e-6, vram=5.7/9.7GB]#015Steps:  14%|█▎        | 152/1125 [03:03<19:28,  1.20s/it, loss=0.319, lr=2e-6, vram=5.7/9.7GB]#015Steps:  14%|█▎        | 152/1125 [03:04<19:28,  1.20s/it, loss=0.382, lr=2e-6, vram=5.7/9.7GB]#015Steps:  14%|█▎        | 153/1125 [03:04<19:20,  1.19s/it, loss=0.382, lr=2e-6, vram=5.7/9.7GB]#015Steps:  14%|█▎        | 154/1125 [03:06<19:26,  1.20s/it, loss=0.382, lr=2e-6, vram=5.7/9.7GB]#015Steps:  14%|█▎        | 154/1125 [03:07<19:26,  1.20s/it, loss=0.288, lr=2e-6, vram=5.7/9.7GB]#015Steps:  14%|█▍        | 155/1125 [03:07<19:28,  1.20s/it, loss=0.288, lr=2e-6, vram=5.7/9.7GB]#015Steps:  14%|█▍        | 156/1125 [03:08<19:26,  1.20s/it, loss=0.288, lr=2e-6, vram=5.7/9.7GB]#015Steps:  14%|█▍        | 156/1125 [03:09<19:26,  1.20s/it, loss=0.259, lr=2e-6, vram=5.7/9.7GB]#015Steps:  14%|█▍        | 157/1125 [03:09<19:22,  1.20s/it, loss=0.259, lr=2e-6, vram=5.7/9.7GB]#015Steps:  14%|█▍        | 158/1125 [03:10<19:25,  1.20s/it, loss=0.259, lr=2e-6, vram=5.7/9.7GB]#015Steps:  14%|█▍        | 158/1125 [03:12<19:25,  1.20s/it, loss=0.303, lr=2e-6, vram=5.7/9.7GB]#015Steps:  14%|█▍        | 159/1125 [03:12<19:20,  1.20s/it, loss=0.303, lr=2e-6, vram=5.7/9.7GB]#015Steps:  14%|█▍        | 160/1125 [03:13<19:23,  1.21s/it, loss=0.303, lr=2e-6, vram=5.7/9.7GB]#015Steps:  14%|█▍        | 160/1125 [03:14<19:23,  1.21s/it, loss=0.357, lr=2e-6, vram=5.7/9.7GB]#015Steps:  14%|█▍        | 161/1125 [03:14<19:26,  1.21s/it, loss=0.357, lr=2e-6, vram=5.7/9.7GB]#015Steps:  14%|█▍        | 162/1125 [03:15<19:16,  1.20s/it, loss=0.357, lr=2e-6, vram=5.7/9.7GB]#015Steps:  14%|█▍        | 162/1125 [03:16<19:16,  1.20s/it, loss=0.293, lr=2e-6, vram=5.7/9.7GB]#015Steps:  14%|█▍        | 163/1125 [03:16<19:30,  1.22s/it, loss=0.293, lr=2e-6, vram=5.7/9.7GB]#015Steps:  15%|█▍        | 164/1125 [03:18<19:30,  1.22s/it, loss=0.293, lr=2e-6, vram=5.7/9.7GB]#015Steps:  15%|█▍        | 164/1125 [03:19<19:30,  1.22s/it, loss=0.393, lr=2e-6, vram=5.7/9.7GB]#015Steps:  15%|█▍        | 165/1125 [03:19<19:22,  1.21s/it, loss=0.393, lr=2e-6, vram=5.7/9.7GB]#015Steps:  15%|█▍        | 166/1125 [03:20<19:21,  1.21s/it, loss=0.393, lr=2e-6, vram=5.7/9.7GB]#015Steps:  15%|█▍        | 166/1125 [03:21<19:21,  1.21s/it, loss=0.278, lr=2e-6, vram=5.7/9.7GB]#015Steps:  15%|█▍        | 167/1125 [03:21<19:16,  1.21s/it, loss=0.278, lr=2e-6, vram=5.7/9.7GB]#015Steps:  15%|█▍        | 168/1125 [03:23<19:15,  1.21s/it, loss=0.278, lr=2e-6, vram=5.7/9.7GB]#015Steps:  15%|█▍        | 168/1125 [03:24<19:15,  1.21s/it, loss=0.504, lr=2e-6, vram=5.7/9.7GB]#015Steps:  15%|█▌        | 169/1125 [03:24<19:11,  1.20s/it, loss=0.504, lr=2e-6, vram=5.7/9.7GB]#015Steps:  15%|█▌        | 170/1125 [03:25<19:06,  1.20s/it, loss=0.504, lr=2e-6, vram=5.7/9.7GB]#015Steps:  15%|█▌        | 170/1125 [03:26<19:06,  1.20s/it, loss=0.32, lr=2e-6, vram=5.7/9.7GB] #015Steps:  15%|█▌        | 171/1125 [03:26<19:01,  1.20s/it, loss=0.32, lr=2e-6, vram=5.7/9.7GB]#015Steps:  15%|█▌        | 172/1125 [03:27<19:03,  1.20s/it, loss=0.32, lr=2e-6, vram=5.7/9.7GB]#015Steps:  15%|█▌        | 172/1125 [03:29<19:03,  1.20s/it, loss=0.336, lr=2e-6, vram=5.7/9.7GB]#015Steps:  15%|█▌        | 173/1125 [03:29<19:07,  1.20s/it, loss=0.336, lr=2e-6, vram=5.7/9.7GB]#015Steps:  15%|█▌        | 174/1125 [03:30<19:06,  1.21s/it, loss=0.336, lr=2e-6, vram=5.7/9.7GB]#015Steps:  15%|█▌        | 174/1125 [03:31<19:06,  1.21s/it, loss=0.401, lr=2e-6, vram=5.7/9.7GB]#015Steps:  16%|█▌        | 175/1125 [03:31<19:08,  1.21s/it, loss=0.401, lr=2e-6, vram=5.7/9.7GB]#015Steps:  16%|█▌        | 176/1125 [03:32<19:03,  1.20s/it, loss=0.401, lr=2e-6, vram=5.7/9.7GB]#015Steps:  16%|█▌        | 176/1125 [03:33<19:03,  1.20s/it, loss=0.271, lr=2e-6, vram=5.7/9.7GB]#015Steps:  16%|█▌        | 177/1125 [03:33<19:03,  1.21s/it, loss=0.271, lr=2e-6, vram=5.7/9.7GB]#015Steps:  16%|█▌        | 178/1125 [03:35<19:01,  1.21s/it, loss=0.271, lr=2e-6, vram=5.7/9.7GB]#015Steps:  16%|█▌        | 178/1125 [03:36<19:01,  1.21s/it, loss=0.335, lr=2e-6, vram=5.7/9.7GB]#015Steps:  16%|█▌        | 179/1125 [03:36<19:05,  1.21s/it, loss=0.335, lr=2e-6, vram=5.7/9.7GB]#015Steps:  16%|█▌        | 180/1125 [03:37<18:56,  1.20s/it, loss=0.335, lr=2e-6, vram=5.7/9.7GB]#015Steps:  16%|█▌        | 180/1125 [03:38<18:56,  1.20s/it, loss=0.563, lr=2e-6, vram=5.7/9.7GB]#015Steps:  16%|█▌        | 181/1125 [03:38<18:58,  1.21s/it, loss=0.563, lr=2e-6, vram=5.7/9.7GB]#015Steps:  16%|█▌        | 182/1125 [03:39<18:57,  1.21s/it, loss=0.563, lr=2e-6, vram=5.7/9.7GB]#015Steps:  16%|█▌        | 182/1125 [03:41<18:57,  1.21s/it, loss=0.322, lr=2e-6, vram=5.7/9.7GB]#015Steps:  16%|█▋        | 183/1125 [03:41<19:00,  1.21s/it, loss=0.322, lr=2e-6, vram=5.7/9.7GB]#015Steps:  16%|█▋        | 184/1125 [03:42<18:55,  1.21s/it, loss=0.322, lr=2e-6, vram=5.7/9.7GB]#015Steps:  16%|█▋        | 184/1125 [03:43<18:55,  1.21s/it, loss=0.424, lr=2e-6, vram=5.7/9.7GB]#015Steps:  16%|█▋        | 185/1125 [03:43<18:57,  1.21s/it, loss=0.424, lr=2e-6, vram=5.7/9.7GB]#015Steps:  17%|█▋        | 186/1125 [03:44<18:52,  1.21s/it, loss=0.424, lr=2e-6, vram=5.7/9.7GB]#015Steps:  17%|█▋        | 186/1125 [03:45<18:52,  1.21s/it, loss=0.288, lr=2e-6, vram=5.7/9.7GB]#015Steps:  17%|█▋        | 187/1125 [03:45<18:57,  1.21s/it, loss=0.288, lr=2e-6, vram=5.7/9.7GB]#015Steps:  17%|█▋        | 188/1125 [03:47<18:57,  1.21s/it, loss=0.288, lr=2e-6, vram=5.7/9.7GB]#015Steps:  17%|█▋        | 188/1125 [03:48<18:57,  1.21s/it, loss=0.376, lr=2e-6, vram=5.7/9.7GB]#015Steps:  17%|█▋        | 189/1125 [03:48<18:49,  1.21s/it, loss=0.376, lr=2e-6, vram=5.7/9.7GB]#015Steps:  17%|█▋        | 190/1125 [03:49<18:51,  1.21s/it, loss=0.376, lr=2e-6, vram=5.7/9.7GB]#015Steps:  17%|█▋        | 190/1125 [03:50<18:51,  1.21s/it, loss=0.363, lr=2e-6, vram=5.7/9.7GB]#015Steps:  17%|█▋        | 191/1125 [03:50<18:45,  1.21s/it, loss=0.363, lr=2e-6, vram=5.7/9.7GB]#015Steps:  17%|█▋        | 192/1125 [03:51<18:47,  1.21s/it, loss=0.363, lr=2e-6, vram=5.7/9.7GB]#015Steps:  17%|█▋        | 192/1125 [03:53<18:47,  1.21s/it, loss=0.369, lr=2e-6, vram=5.7/9.7GB]#015Steps:  17%|█▋        | 193/1125 [03:53<18:43,  1.21s/it, loss=0.369, lr=2e-6, vram=5.7/9.7GB]#015Steps:  17%|█▋        | 194/1125 [03:54<18:42,  1.21s/it, loss=0.369, lr=2e-6, vram=5.7/9.7GB]#015Steps:  17%|█▋        | 194/1125 [03:55<18:42,  1.21s/it, loss=0.284, lr=2e-6, vram=5.7/9.7GB]#015Steps:  17%|█▋        | 195/1125 [03:55<18:46,  1.21s/it, loss=0.284, lr=2e-6, vram=5.7/9.7GB]#015Steps:  17%|█▋        | 196/1125 [03:56<18:48,  1.21s/it, loss=0.284, lr=2e-6, vram=5.7/9.7GB]#015Steps:  17%|█▋        | 196/1125 [03:58<18:48,  1.21s/it, loss=0.302, lr=2e-6, vram=5.7/9.7GB]#015Steps:  18%|█▊        | 197/1125 [03:58<18:48,  1.22s/it, loss=0.302, lr=2e-6, vram=5.7/9.7GB]#015Steps:  18%|█▊        | 198/1125 [03:59<18:38,  1.21s/it, loss=0.302, lr=2e-6, vram=5.7/9.7GB]#015Steps:  18%|█▊        | 198/1125 [04:00<18:38,  1.21s/it, loss=0.235, lr=2e-6, vram=5.7/9.7GB]#015Steps:  18%|█▊        | 199/1125 [04:00<18:44,  1.21s/it, loss=0.235, lr=2e-6, vram=5.7/9.7GB]#015Steps:  18%|█▊        | 200/1125 [04:01<18:38,  1.21s/it, loss=0.235, lr=2e-6, vram=5.7/9.7GB]#015Steps:  18%|█▊        | 200/1125 [04:02<18:38,  1.21s/it, loss=0.369, lr=2e-6, vram=5.7/9.7GB]#015Steps:  18%|█▊        | 201/1125 [04:02<18:40,  1.21s/it, loss=0.369, lr=2e-6, vram=5.7/9.7GB]#015Steps:  18%|█▊        | 202/1125 [04:04<18:36,  1.21s/it, loss=0.369, lr=2e-6, vram=5.7/9.7GB]#015Steps:  18%|█▊        | 202/1125 [04:05<18:36,  1.21s/it, loss=0.234, lr=2e-6, vram=5.7/9.7GB]#015Steps:  18%|█▊        | 203/1125 [04:05<18:34,  1.21s/it, loss=0.234, lr=2e-6, vram=5.7/9.7GB]#015Steps:  18%|█▊        | 204/1125 [04:06<18:30,  1.21s/it, loss=0.234, lr=2e-6, vram=5.7/9.7GB]#015Steps:  18%|█▊        | 204/1125 [04:07<18:30,  1.21s/it, loss=0.61, lr=2e-6, vram=5.7/9.7GB] #015Steps:  18%|█▊        | 205/1125 [04:07<18:32,  1.21s/it, loss=0.61, lr=2e-6, vram=5.7/9.7GB]#015Steps:  18%|█▊        | 206/1125 [04:08<18:35,  1.21s/it, loss=0.61, lr=2e-6, vram=5.7/9.7GB]#015Steps:  18%|█▊        | 206/1125 [04:10<18:35,  1.21s/it, loss=0.391, lr=2e-6, vram=5.7/9.7GB]#015Steps:  18%|█▊        | 207/1125 [04:10<18:27,  1.21s/it, loss=0.391, lr=2e-6, vram=5.7/9.7GB]#015Steps:  18%|█▊        | 208/1125 [04:11<18:39,  1.22s/it, loss=0.391, lr=2e-6, vram=5.7/9.7GB]#015Steps:  18%|█▊        | 208/1125 [04:12<18:39,  1.22s/it, loss=0.365, lr=2e-6, vram=5.7/9.7GB]#015Steps:  19%|█▊        | 209/1125 [04:12<18:37,  1.22s/it, loss=0.365, lr=2e-6, vram=5.7/9.7GB]#015Steps:  19%|█▊        | 210/1125 [04:13<18:29,  1.21s/it, loss=0.365, lr=2e-6, vram=5.7/9.7GB]#015Steps:  19%|█▊        | 210/1125 [04:15<18:29,  1.21s/it, loss=0.222, lr=2e-6, vram=5.7/9.7GB]#015Steps:  19%|█▉        | 211/1125 [04:15<18:30,  1.21s/it, loss=0.222, lr=2e-6, vram=5.7/9.7GB]#015Steps:  19%|█▉        | 212/1125 [04:16<18:29,  1.22s/it, loss=0.222, lr=2e-6, vram=5.7/9.7GB]#015Steps:  19%|█▉        | 212/1125 [04:17<18:29,  1.22s/it, loss=0.344, lr=2e-6, vram=5.7/9.7GB]#015Steps:  19%|█▉        | 213/1125 [04:17<18:23,  1.21s/it, loss=0.344, lr=2e-6, vram=5.7/9.7GB]#015Steps:  19%|█▉        | 214/1125 [04:18<18:21,  1.21s/it, loss=0.344, lr=2e-6, vram=5.7/9.7GB]#015Steps:  19%|█▉        | 214/1125 [04:19<18:21,  1.21s/it, loss=0.348, lr=2e-6, vram=5.7/9.7GB]#015Steps:  19%|█▉        | 215/1125 [04:19<18:17,  1.21s/it, loss=0.348, lr=2e-6, vram=5.7/9.7GB]#015Steps:  19%|█▉        | 216/1125 [04:21<18:11,  1.20s/it, loss=0.348, lr=2e-6, vram=5.7/9.7GB]#015Steps:  19%|█▉        | 216/1125 [04:22<18:11,  1.20s/it, loss=0.307, lr=2e-6, vram=5.7/9.7GB]#015Steps:  19%|█▉        | 217/1125 [04:22<18:19,  1.21s/it, loss=0.307, lr=2e-6, vram=5.7/9.7GB]#015Steps:  19%|█▉        | 218/1125 [04:23<18:19,  1.21s/it, loss=0.307, lr=2e-6, vram=5.7/9.7GB]#015Steps:  19%|█▉        | 218/1125 [04:24<18:19,  1.21s/it, loss=0.387, lr=2e-6, vram=5.7/9.7GB]#015Steps:  19%|█▉        | 219/1125 [04:24<18:23,  1.22s/it, loss=0.387, lr=2e-6, vram=5.7/9.7GB]#015Steps:  20%|█▉        | 220/1125 [04:25<18:21,  1.22s/it, loss=0.387, lr=2e-6, vram=5.7/9.7GB]#015Steps:  20%|█▉        | 220/1125 [04:27<18:21,  1.22s/it, loss=0.503, lr=2e-6, vram=5.7/9.7GB]#015Steps:  20%|█▉        | 221/1125 [04:27<18:17,  1.21s/it, loss=0.503, lr=2e-6, vram=5.7/9.7GB]#015Steps:  20%|█▉        | 222/1125 [04:28<18:11,  1.21s/it, loss=0.503, lr=2e-6, vram=5.7/9.7GB]#015Steps:  20%|█▉        | 222/1125 [04:29<18:11,  1.21s/it, loss=0.299, lr=2e-6, vram=5.7/9.7GB]#015Steps:  20%|█▉        | 223/1125 [04:29<18:06,  1.21s/it, loss=0.299, lr=2e-6, vram=5.7/9.7GB]#015Steps:  20%|█▉        | 224/1125 [04:30<18:09,  1.21s/it, loss=0.299, lr=2e-6, vram=5.7/9.7GB]#015Steps:  20%|█▉        | \u001b[0m\n",
      "\u001b[34m224/1125 [04:31<18:09,  1.21s/it, loss=0.396, lr=2e-6, vram=5.7/9.7GB]#015Steps:  20%|██        | 225/1125 [04:31<18:02,  1.20s/it, loss=0.396, lr=2e-6, vram=5.7/9.7GB]#015Steps:  20%|██        | 226/1125 [04:33<18:13,  1.22s/it, loss=0.396, lr=2e-6, vram=5.7/9.7GB]#015Steps:  20%|██        | 226/1125 [04:34<18:13,  1.22s/it, loss=0.396, lr=2e-6, vram=5.7/9.7GB]#015Steps:  20%|██        | 227/1125 [04:34<18:14,  1.22s/it, loss=0.396, lr=2e-6, vram=5.7/9.7GB]#015Steps:  20%|██        | 228/1125 [04:35<18:14,  1.22s/it, loss=0.396, lr=2e-6, vram=5.7/9.7GB]#015Steps:  20%|██        | 228/1125 [04:36<18:14,  1.22s/it, loss=0.448, lr=2e-6, vram=5.7/9.7GB]#015Steps:  20%|██        | 229/1125 [04:36<18:08,  1.22s/it, loss=0.448, lr=2e-6, vram=5.7/9.7GB]#015Steps:  20%|██        | 230/1125 [04:38<18:02,  1.21s/it, loss=0.448, lr=2e-6, vram=5.7/9.7GB]#015Steps:  20%|██        | 230/1125 [04:39<18:02,  1.21s/it, loss=0.325, lr=2e-6, vram=5.7/9.7GB]#015Steps:  21%|██        | 231/1125 [04:39<18:03,  1.21s/it, loss=0.325, lr=2e-6, vram=5.7/9.7GB]#015Steps:  21%|██        | 232/1125 [04:40<17:58,  1.21s/it, loss=0.325, lr=2e-6, vram=5.7/9.7GB]#015Steps:  21%|██        | 232/1125 [04:41<17:58,  1.21s/it, loss=0.452, lr=2e-6, vram=5.7/9.7GB]#015Steps:  21%|██        | 233/1125 [04:41<17:54,  1.20s/it, loss=0.452, lr=2e-6, vram=5.7/9.7GB]#015Steps:  21%|██        | 234/1125 [04:42<17:48,  1.20s/it, loss=0.452, lr=2e-6, vram=5.7/9.7GB]#015Steps:  21%|██        | 234/1125 [04:44<17:48,  1.20s/it, loss=0.299, lr=2e-6, vram=5.7/9.7GB]#015Steps:  21%|██        | 235/1125 [04:44<17:57,  1.21s/it, loss=0.299, lr=2e-6, vram=5.7/9.7GB]#015Steps:  21%|██        | 236/1125 [04:45<17:53,  1.21s/it, loss=0.299, lr=2e-6, vram=5.7/9.7GB]#015Steps:  21%|██        | 236/1125 [04:46<17:53,  1.21s/it, loss=0.436, lr=2e-6, vram=5.7/9.7GB]#015Steps:  21%|██        | 237/1125 [04:46<17:49,  1.20s/it, loss=0.436, lr=2e-6, vram=5.7/9.7GB]#015Steps:  21%|██        | 238/1125 [04:47<17:55,  1.21s/it, loss=0.436, lr=2e-6, vram=5.7/9.7GB]#015Steps:  21%|██        | 238/1125 [04:48<17:55,  1.21s/it, loss=0.255, lr=2e-6, vram=5.7/9.7GB]#015Steps:  21%|██        | 239/1125 [04:48<17:56,  1.21s/it, loss=0.255, lr=2e-6, vram=5.7/9.7GB]#015Steps:  21%|██▏       | 240/1125 [04:50<17:53,  1.21s/it, loss=0.255, lr=2e-6, vram=5.7/9.7GB]#015Steps:  21%|██▏       | 240/1125 [04:51<17:53,  1.21s/it, loss=0.55, lr=2e-6, vram=5.7/9.7GB] #015Steps:  21%|██▏       | 241/1125 [04:51<17:50,  1.21s/it, loss=0.55, lr=2e-6, vram=5.7/9.7GB]#015Steps:  22%|██▏       | 242/1125 [04:52<17:51,  1.21s/it, loss=0.55, lr=2e-6, vram=5.7/9.7GB]#015Steps:  22%|██▏       | 242/1125 [04:53<17:51,  1.21s/it, loss=0.373, lr=2e-6, vram=5.7/9.7GB]#015Steps:  22%|██▏       | 243/1125 [04:53<17:42,  1.21s/it, loss=0.373, lr=2e-6, vram=5.7/9.7GB]#015Steps:  22%|██▏       | 244/1125 [04:54<17:49,  1.21s/it, loss=0.373, lr=2e-6, vram=5.7/9.7GB]#015Steps:  22%|██▏       | 244/1125 [04:56<17:49,  1.21s/it, loss=0.32, lr=2e-6, vram=5.7/9.7GB] #015Steps:  22%|██▏       | 245/1125 [04:56<17:45,  1.21s/it, loss=0.32, lr=2e-6, vram=5.7/9.7GB]#015Steps:  22%|██▏       | 246/1125 [04:57<17:47,  1.21s/it, loss=0.32, lr=2e-6, vram=5.7/9.7GB]#015Steps:  22%|██▏       | 246/1125 [04:58<17:47,  1.21s/it, loss=0.385, lr=2e-6, vram=5.7/9.7GB]#015Steps:  22%|██▏       | 247/1125 [04:58<17:41,  1.21s/it, loss=0.385, lr=2e-6, vram=5.7/9.7GB]#015Steps:  22%|██▏       | 248/1125 [04:59<17:40,  1.21s/it, loss=0.385, lr=2e-6, vram=5.7/9.7GB]#015Steps:  22%|██▏       | 248/1125 [05:01<17:40,  1.21s/it, loss=0.362, lr=2e-6, vram=5.7/9.7GB]#015Steps:  22%|██▏       | 249/1125 [05:01<17:43,  1.21s/it, loss=0.362, lr=2e-6, vram=5.7/9.7GB]#015Steps:  22%|██▏       | 250/1125 [05:02<17:39,  1.21s/it, loss=0.362, lr=2e-6, vram=5.7/9.7GB]#015Steps:  22%|██▏       | 250/1125 [05:03<17:39,  1.21s/it, loss=0.267, lr=2e-6, vram=5.7/9.7GB]#015Steps:  22%|██▏       | 251/1125 [05:03<17:42,  1.22s/it, loss=0.267, lr=2e-6, vram=5.7/9.7GB]#015Steps:  22%|██▏       | 252/1125 [05:04<17:34,  1.21s/it, loss=0.267, lr=2e-6, vram=5.7/9.7GB]#015Steps:  22%|██▏       | 252/1125 [05:05<17:34,  1.21s/it, loss=0.624, lr=2e-6, vram=5.7/9.7GB]#015Steps:  22%|██▏       | 253/1125 [05:05<17:43,  1.22s/it, loss=0.624, lr=2e-6, vram=5.7/9.7GB]#015Steps:  23%|██▎       | 254/1125 [05:07<17:39,  1.22s/it, loss=0.624, lr=2e-6, vram=5.7/9.7GB]#015Steps:  23%|██▎       | 254/1125 [05:08<17:39,  1.22s/it, loss=0.327, lr=2e-6, vram=5.7/9.7GB]#015Steps:  23%|██▎       | 255/1125 [05:08<17:41,  1.22s/it, loss=0.327, lr=2e-6, vram=5.7/9.7GB]#015Steps:  23%|██▎       | 256/1125 [05:09<17:39,  1.22s/it, loss=0.327, lr=2e-6, vram=5.7/9.7GB]#015Steps:  23%|██▎       | 256/1125 [05:10<17:39,  1.22s/it, loss=0.385, lr=2e-6, vram=5.7/9.7GB]#015Steps:  23%|██▎       | 257/1125 [05:10<17:36,  1.22s/it, loss=0.385, lr=2e-6, vram=5.7/9.7GB]#015Steps:  23%|██▎       | 258/1125 [05:11<17:35,  1.22s/it, loss=0.385, lr=2e-6, vram=5.7/9.7GB]#015Steps:  23%|██▎       | 258/1125 [05:13<17:35,  1.22s/it, loss=0.369, lr=2e-6, vram=5.7/9.7GB]#015Steps:  23%|██▎       | 259/1125 [05:13<17:30,  1.21s/it, loss=0.369, lr=2e-6, vram=5.7/9.7GB]#015Steps:  23%|██▎       | 260/1125 [05:14<17:25,  1.21s/it, loss=0.369, lr=2e-6, vram=5.7/9.7GB]#015Steps:  23%|██▎       | 260/1125 [05:15<17:25,  1.21s/it, loss=0.426, lr=2e-6, vram=5.7/9.7GB]#015Steps:  23%|██▎       | 261/1125 [05:15<17:19,  1.20s/it, loss=0.426, lr=2e-6, vram=5.7/9.7GB]#015Steps:  23%|██▎       | 262/1125 [05:16<17:27,  1.21s/it, loss=0.426, lr=2e-6, vram=5.7/9.7GB]#015Steps:  23%|██▎       | 262/1125 [05:18<17:27,  1.21s/it, loss=0.443, lr=2e-6, vram=5.7/9.7GB]#015Steps:  23%|██▎       | 263/1125 [05:18<17:26,  1.21s/it, loss=0.443, lr=2e-6, vram=5.7/9.7GB]#015Steps:  23%|██▎       | 264/1125 [05:19<17:21,  1.21s/it, loss=0.443, lr=2e-6, vram=5.7/9.7GB]#015Steps:  23%|██▎       | 264/1125 [05:20<17:21,  1.21s/it, loss=0.263, lr=2e-6, vram=5.7/9.7GB]#015Steps:  24%|██▎       | 265/1125 [05:20<17:18,  1.21s/it, loss=0.263, lr=2e-6, vram=5.7/9.7GB]#015Steps:  24%|██▎       | 266/1125 [05:21<17:19,  1.21s/it, loss=0.263, lr=2e-6, vram=5.7/9.7GB]#015Steps:  24%|██▎       | 266/1125 [05:22<17:19,  1.21s/it, loss=0.365, lr=2e-6, vram=5.7/9.7GB]#015Steps:  24%|██▎       | 267/1125 [05:22<17:21,  1.21s/it, loss=0.365, lr=2e-6, vram=5.7/9.7GB]#015Steps:  24%|██▍       | 268/1125 [05:24<17:17,  1.21s/it, loss=0.365, lr=2e-6, vram=5.7/9.7GB]#015Steps:  24%|██▍       | 268/1125 [05:25<17:17,  1.21s/it, loss=0.265, lr=2e-6, vram=5.7/9.7GB]#015Steps:  24%|██▍       | 269/1125 [05:25<17:21,  1.22s/it, loss=0.265, lr=2e-6, vram=5.7/9.7GB]#015Steps:  24%|██▍       | 270/1125 [05:26<17:14,  1.21s/it, loss=0.265, lr=2e-6, vram=5.7/9.7GB]#015Steps:  24%|██▍       | 270/1125 [05:27<17:14,  1.21s/it, loss=0.305, lr=2e-6, vram=5.7/9.7GB]#015Steps:  24%|██▍       | 271/1125 [05:27<17:22,  1.22s/it, loss=0.305, lr=2e-6, vram=5.7/9.7GB]#015Steps:  24%|██▍       | 272/1125 [05:28<17:17,  1.22s/it, loss=0.305, lr=2e-6, vram=5.7/9.7GB]#015Steps:  24%|██▍       | 272/1125 [05:30<17:17,  1.22s/it, loss=0.304, lr=2e-6, vram=5.7/9.7GB]#015Steps:  24%|██▍       | 273/1125 [05:30<17:18,  1.22s/it, loss=0.304, lr=2e-6, vram=5.7/9.7GB]#015Steps:  24%|██▍       | 274/1125 [05:31<17:11,  1.21s/it, loss=0.304, lr=2e-6, vram=5.7/9.7GB]#015Steps:  24%|██▍       | 274/1125 [05:32<17:11,  1.21s/it, loss=0.357, lr=2e-6, vram=5.7/9.7GB]#015Steps:  24%|██▍       | 275/1125 [05:32<17:11,  1.21s/it, loss=0.357, lr=2e-6, vram=5.7/9.7GB]#015Steps:  25%|██▍       | 276/1125 [05:33<17:07,  1.21s/it, loss=0.357, lr=2e-6, vram=5.7/9.7GB]#015Steps:  25%|██▍       | 276/1125 [05:35<17:07,  1.21s/it, loss=0.231, lr=2e-6, vram=5.7/9.7GB]#015Steps:  25%|██▍       | 277/1125 [05:35<17:10,  1.21s/it, loss=0.231, lr=2e-6, vram=5.7/9.7GB]#015Steps:  25%|██▍       | 278/1125 [05:36<17:10,  1.22s/it, loss=0.231, lr=2e-6, vram=5.7/9.7GB]#015Steps:  25%|██▍       | 278/1125 [05:37<17:10,  1.22s/it, loss=0.435, lr=2e-6, vram=5.7/9.7GB]#015Steps:  25%|██▍       | 279/1125 [05:37<17:03,  1.21s/it, loss=0.435, lr=2e-6, vram=5.7/9.7GB]#015Steps:  25%|██▍       | 280/1125 [05:38<17:17,  1.23s/it, loss=0.435, lr=2e-6, vram=5.7/9.7GB]#015Steps:  25%|██▍       | 280/1125 [05:39<17:17,  1.23s/it, loss=0.379, lr=2e-6, vram=5.7/9.7GB]#015Steps:  25%|██▍       | 281/1125 [05:39<17:14,  1.23s/it, loss=0.379, lr=2e-6, vram=5.7/9.7GB]#015Steps:  25%|██▌       | 282/1125 [05:41<17:08,  1.22s/it, loss=0.379, lr=2e-6, vram=5.7/9.7GB]#015Steps:  25%|██▌       | 282/1125 [05:42<17:08,  1.22s/it, loss=0.252, lr=2e-6, vram=5.7/9.7GB]#015Steps:  25%|██▌       | 283/1125 [05:42<17:06,  1.22s/it, loss=0.252, lr=2e-6, vram=5.7/9.7GB]#015Steps:  25%|██▌       | 284/1125 [05:43<17:00,  1.21s/it, loss=0.252, lr=2e-6, vram=5.7/9.7GB]#015Steps:  25%|██▌       | 284/1125 [05:44<17:00,  1.21s/it, loss=0.328, lr=2e-6, vram=5.7/9.7GB]#015Steps:  25%|██▌       | 285/1125 [05:44<16:56,  1.21s/it, loss=0.328, lr=2e-6, vram=5.7/9.7GB]#015Steps:  25%|██▌       | 286/1125 [05:45<16:58,  1.21s/it, loss=0.328, lr=2e-6, vram=5.7/9.7GB]#015Steps:  25%|██▌       | 286/1125 [05:47<16:58,  1.21s/it, loss=0.369, lr=2e-6, vram=5.7/9.7GB]#015Steps:  26%|██▌       | 287/1125 [05:47<16:54,  1.21s/it, loss=0.369, lr=2e-6, vram=5.7/9.7GB]#015Steps:  26%|██▌       | 288/1125 [05:48<16:48,  1.21s/it, loss=0.369, lr=2e-6, vram=5.7/9.7GB]#015Steps:  26%|██▌       | 288/1125 [05:49<16:48,  1.21s/it, loss=0.284, lr=2e-6, vram=5.7/9.7GB]#015Steps:  26%|██▌       | 289/1125 [05:49<16:56,  1.22s/it, loss=0.284, lr=2e-6, vram=5.7/9.7GB]#015Steps:  26%|██▌       | 290/1125 [05:50<16:51,  1.21s/it, loss=0.284, lr=2e-6, vram=5.7/9.7GB]#015Steps:  26%|██▌       | 290/1125 [05:52<16:51,  1.21s/it, loss=0.427, lr=2e-6, vram=5.7/9.7GB]#015Steps:  26%|██▌       | 291/1125 [05:52<16:50,  1.21s/it, loss=0.427, lr=2e-6, vram=5.7/9.7GB]#015Steps:  26%|██▌       | 292/1125 [05:53<16:52,  1.22s/it, loss=0.427, lr=2e-6, vram=5.7/9.7GB]#015Steps:  26%|██▌       | 292/1125 [05:54<16:52,  1.22s/it, loss=0.436, lr=2e-6, vram=5.7/9.7GB]#015Steps:  26%|██▌       | 293/1125 [05:54<16:53,  1.22s/it, loss=0.436, lr=2e-6, vram=5.7/9.7GB]#015Steps:  26%|██▌       | 294/1125 [05:55<16:55,  1.22s/it, loss=0.436, lr=2e-6, vram=5.7/9.7GB]#015Steps:  26%|██▌       | 294/1125 [05:56<16:55,  1.22s/it, loss=0.315, lr=2e-6, vram=5.7/9.7GB]#015Steps:  26%|██▌       | 295/1125 [05:56<16:52,  1.22s/it, loss=0.315, lr=2e-6, vram=5.7/9.7GB]#015Steps:  26%|██▋       | 296/1125 [05:58<16:46,  1.21s/it, loss=0.315, lr=2e-6, vram=5.7/9.7GB]#015Steps:  26%|██▋       | 296/1125 [05:59<16:46,  1.21s/it, loss=0.353, lr=2e-6, vram=5.7/9.7GB]#015Steps:  26%|██▋       | 297/1125 [05:59<16:40,  1.21s/it, loss=0.353, lr=2e-6, vram=5.7/9.7GB]#015Steps:  26%|██▋       | 298/1125 [06:00<16:41,  1.21s/it, loss=0.353, lr=2e-6, vram=5.7/9.7GB]#015Steps:  26%|██▋       | 298/1125 [06:01<16:41,  1.21s/it, loss=0.268, lr=2e-6, vram=5.7/9.7GB]#015Steps:  27%|██▋       | 299/1125 [06:01<16:41,  1.21s/it, loss=0.268, lr=2e-6, vram=5.7/9.7GB]#015Steps:  27%|██▋       | 300/1125 [06:02<16:43,  1.22s/it, loss=0.268, lr=2e-6, vram=5.7/9.7GB]#015Steps:  27%|██▋       | 300/1125 [06:04<16:43,  1.22s/it, loss=0.367, lr=2e-6, vram=5.7/9.7GB]#015Steps:  27%|██▋       | 301/1125 [06:04<16:44,  1.22s/it, loss=0.367, lr=2e-6, vram=5.7/9.7GB]#015Steps:  27%|██▋       | 302/1125 [06:05<16:44,  1.22s/it, loss=0.367, lr=2e-6, vram=5.7/9.7GB]#015Steps:  27%|██▋       | 302/1125 [06:06<16:44,  1.22s/it, loss=0.351, lr=2e-6, vram=5.7/9.7GB]#015Steps:  27%|██▋       | 303/1125 [06:06<16:40,  1.22s/it, loss=0.351, lr=2e-6, vram=5.7/9.7GB]#015Steps:  27%|██▋       | 304/1125 [06:07<16:43,  1.22s/it, loss=0.351, lr=2e-6, vram=5.7/9.7GB]#015Steps:  27%|██▋       | 304/1125 [06:09<16:43,  1.22s/it, loss=0.491, lr=2e-6, vram=5.7/9.7GB]#015Steps:  27%|██▋       | 305/1125 [06:09<16:37,  1.22s/it, loss=0.491, lr=2e-6, vram=5.7/9.7GB]#015Steps:  27%|██▋       | 306/1125 [06:10<16:30,  1.21s/it, loss=0.491, lr=2e-6, vram=5.7/9.7GB]#015Steps:  27%|██▋       | 306/1125 [06:11<16:30,  1.21s/it, loss=0.334, lr=2e-6, vram=5.7/9.7GB]#015Steps:  27%|██▋       | 307/1125 [06:11<16:32,  1.21s/it, loss=0.334, lr=2e-6, vram=5.7/9.7GB]#015Steps:  27%|██▋       | 308/1125 [06:12<16:34,  1.22s/it, loss=0.334, lr=2e-6, vram=5.7/9.7GB]#015Steps:  27%|██▋       | 308/1125 [06:13<16:34,  1.22s/it, loss=0.356, lr=2e-6, vram=5.7/9.7GB]#015Steps:  27%|██▋       | 309/1125 [06:13<16:33,  1.22s/it, loss=0.356, lr=2e-6, vram=5.7/9.7GB]#015Steps:  28%|██▊       | 310/1125 [06:15<16:32,  1.22s/it, loss=0.356, lr=2e-6, vram=5.7/9.7GB]#015Steps:  28%|██▊       | 310/1125 [06:16<16:32,  1.22s/it, loss=0.377, lr=2e-6, vram=5.7/9.7GB]#015Steps:  28%|██▊       | 311/1125 [06:16<16:32,  1.22s/it, loss=0.377, lr=2e-6, vram=5.7/9.7GB]#015Steps:  28%|██▊       | 312/1125 [06:17<16:35,  1.22s/it, loss=0.377, lr=2e-6, vram=5.7/9.7GB]#015Steps:  28%|██▊       | 312/1125 [06:18<16:35,  1.22s/it, loss=0.268, lr=2e-6, vram=5.7/9.7GB]#015Steps:  28%|██▊       | 313/1125 [06:18<16:29,  1.22s/it, loss=0.268, lr=2e-6, vram=5.7/9.7GB]#015Steps:  28%|██▊       | 314/1125 [06:19<16:24,  1.21s/it, loss=0.268, lr=2e-6, vram=5.7/9.7GB]#015Steps:  28%|██▊       | 314/1125 [06:21<16:24,  1.21s/it, loss=0.294, lr=2e-6, vram=5.7/9.7GB]#015Steps:  28%|██▊       | 315/1125 [06:21<16:17,  1.21s/it, loss=0.294, lr=2e-6, vram=5.7/9.7GB]#015Steps:  28%|██▊       | 316/1125 [06:22<16:31,  1.23s/it, loss=0.294, lr=2e-6, vram=5.7/9.7GB]#015Steps:  28%|██▊       | 316/1125 [06:23<16:31,  1.23s/it, loss=0.31, lr=2e-6, vram=5.7/9.7GB] #015Steps:  28%|██▊       | 317/1125 [06:23<16:25,  1.22s/it, loss=0.31, lr=2e-6, vram=5.7/9.7GB]#015Steps:  28%|██▊       | 318/1125 [06:24<16:25,  1.22s/it, loss=0.31, lr=2e-6, vram=5.7/9.7GB]#015Steps:  28%|██▊       | 318/1125 [06:26<16:25,  1.22s/it, loss=0.403, lr=2e-6, vram=5.7/9.7GB]#015Steps:  28%|██▊       | 319/1125 [06:26<16:20,  1.22s/it, loss=0.403, lr=2e-6, vram=5.7/9.7GB]#015Steps:  28%|██▊       | 320/1125 [06:27<16:20,  1.22s/it, loss=0.403, lr=2e-6, vram=5.7/9.7GB]#015Steps:  28%|██▊       | 320/1125 [06:28<16:20,  1.22s/it, loss=0.386, lr=2e-6, vram=5.7/9.7GB]#015Steps:  29%|██▊       | 321/1125 [06:28<16:17,  1.22s/it, loss=0.386, lr=2e-6, vram=5.7/9.7GB]#015Steps:  29%|██▊       | 322/1125 [06:29<16:12,  1.21s/it, loss=0.386, lr=2e-6, vram=5.7/9.7GB]#015Steps:  29%|██▊       | 322/1125 [06:30<16:12,  1.21s/it, loss=0.32, lr=2e-6, vram=5.7/9.7GB] #015Steps:  29%|██▊       | 323/1125 [06:30<16:12,  1.21s/it, loss=0.32, lr=2e-6, vram=5.7/9.7GB]#015Steps:  29%|██▉       | 324/1125 [06:32<16:06,  1.21s/it, loss=0.32, lr=2e-6, vram=5.7/9.7GB]#015Steps:  29%|██▉       | 324/1125 [06:33<16:06,  1.21s/it, loss=0.482, lr=2e-6, vram=5.7/9.7GB]#015Steps:  29%|██▉       | 325/1125 [06:33<16:13,  1.22s/it, loss=0.482, lr=2e-6, vram=5.7/9.7GB]#015Steps:  29%|██▉       | 326/1125 [06:34<16:09,  1.21s/it, loss=0.482, lr=2e-6, vram=5.7/9.7GB]#015Steps:  29%|██▉       | 326/1125 [06:35<16:09,  1.21s/it, loss=0.447, lr=2e-6, vram=5.7/9.7GB]#015Steps:  29%|██▉       | 327/1125 [06:35<16:12,  1.22s/it, loss=0.447, lr=2e-6, vram=5.7/9.7GB]#015Steps:  29%|██▉       | 328/1125 [06:37<16:11,  1.22s/it, loss=0.447, lr=2e-6, vram=5.7/9.7GB]#015Steps:  29%|██▉       | 328/1125 [06:38<16:11,  1.22s/it, loss=0.299, lr=2e-6, vram=5.7/9.7GB]#015Steps:  29%|██▉       | 329/1125 [06:38<16:06,  1.21s/it, loss=0.299, lr=2e-6, vram=5.7/9.7GB]#015Steps:  29%|██▉       | 330/1125 [06:39<16:08,  1.22s/it, loss=0.299, lr=2e-6, vram=5.7/9.7GB]#015Steps:  29%|██▉       | 330/1125 [06:40<16:08,  1.22s/it, loss=0.384, lr=2e-6, vram=5.7/9.7GB]#015Steps:  29%|██▉       | 331/1125 [06:40<16:05,  1.22s/it, loss=0.384, lr=2e-6, vram=5.7/9.7GB]#015Steps:  30%|██▉       | 332/1125 [06:41<16:05,  1.22s/it, loss=0.384, lr=2e-6, vram=5.7/9.7GB]#015Steps:  30%|██▉       | 332/1125 [06:43<16:05,  1.22s/it, loss=0.344, lr=2e-6, vram=5.7/9.7GB]#015Ste\u001b[0m\n",
      "\u001b[34mps:  30%|██▉       | 333/1125 [06:43<15:59,  1.21s/it, loss=0.344, lr=2e-6, vram=5.7/9.7GB]#015Steps:  30%|██▉       | 334/1125 [06:44<16:04,  1.22s/it, loss=0.344, lr=2e-6, vram=5.7/9.7GB]#015Steps:  30%|██▉       | 334/1125 [06:45<16:04,  1.22s/it, loss=0.514, lr=2e-6, vram=5.7/9.7GB]#015Steps:  30%|██▉       | 335/1125 [06:45<16:03,  1.22s/it, loss=0.514, lr=2e-6, vram=5.7/9.7GB]#015Steps:  30%|██▉       | 336/1125 [06:46<16:05,  1.22s/it, loss=0.514, lr=2e-6, vram=5.7/9.7GB]#015Steps:  30%|██▉       | 336/1125 [06:47<16:05,  1.22s/it, loss=0.293, lr=2e-6, vram=5.7/9.7GB]#015Steps:  30%|██▉       | 337/1125 [06:47<15:59,  1.22s/it, loss=0.293, lr=2e-6, vram=5.7/9.7GB]#015Steps:  30%|███       | 338/1125 [06:49<16:00,  1.22s/it, loss=0.293, lr=2e-6, vram=5.7/9.7GB]#015Steps:  30%|███       | 338/1125 [06:50<16:00,  1.22s/it, loss=0.422, lr=2e-6, vram=5.7/9.7GB]#015Steps:  30%|███       | 339/1125 [06:50<15:59,  1.22s/it, loss=0.422, lr=2e-6, vram=5.7/9.7GB]#015Steps:  30%|███       | 340/1125 [06:51<15:54,  1.22s/it, loss=0.422, lr=2e-6, vram=5.7/9.7GB]#015Steps:  30%|███       | 340/1125 [06:52<15:54,  1.22s/it, loss=0.275, lr=2e-6, vram=5.7/9.7GB]#015Steps:  30%|███       | 341/1125 [06:52<15:53,  1.22s/it, loss=0.275, lr=2e-6, vram=5.7/9.7GB]#015Steps:  30%|███       | 342/1125 [06:54<15:47,  1.21s/it, loss=0.275, lr=2e-6, vram=5.7/9.7GB]#015Steps:  30%|███       | 342/1125 [06:55<15:47,  1.21s/it, loss=0.237, lr=2e-6, vram=5.7/9.7GB]#015Steps:  30%|███       | 343/1125 [06:55<15:54,  1.22s/it, loss=0.237, lr=2e-6, vram=5.7/9.7GB]#015Steps:  31%|███       | 344/1125 [06:56<15:56,  1.22s/it, loss=0.237, lr=2e-6, vram=5.7/9.7GB]#015Steps:  31%|███       | 344/1125 [06:57<15:56,  1.22s/it, loss=0.243, lr=2e-6, vram=5.7/9.7GB]#015Steps:  31%|███       | 345/1125 [06:57<15:51,  1.22s/it, loss=0.243, lr=2e-6, vram=5.7/9.7GB]#015Steps:  31%|███       | 346/1125 [06:58<15:45,  1.21s/it, loss=0.243, lr=2e-6, vram=5.7/9.7GB]#015Steps:  31%|███       | 346/1125 [07:00<15:45,  1.21s/it, loss=0.317, lr=2e-6, vram=5.7/9.7GB]#015Steps:  31%|███       | 347/1125 [07:00<15:44,  1.21s/it, loss=0.317, lr=2e-6, vram=5.7/9.7GB]#015Steps:  31%|███       | 348/1125 [07:01<15:43,  1.21s/it, loss=0.317, lr=2e-6, vram=5.7/9.7GB]#015Steps:  31%|███       | 348/1125 [07:02<15:43,  1.21s/it, loss=0.318, lr=2e-6, vram=5.7/9.7GB]#015Steps:  31%|███       | 349/1125 [07:02<15:45,  1.22s/it, loss=0.318, lr=2e-6, vram=5.7/9.7GB]#015Steps:  31%|███       | 350/1125 [07:03<15:45,  1.22s/it, loss=0.318, lr=2e-6, vram=5.7/9.7GB]#015Steps:  31%|███       | 350/1125 [07:05<15:45,  1.22s/it, loss=0.333, lr=2e-6, vram=5.7/9.7GB]#015Steps:  31%|███       | 351/1125 [07:05<15:38,  1.21s/it, loss=0.333, lr=2e-6, vram=5.7/9.7GB]#015Steps:  31%|███▏      | 352/1125 [07:06<15:48,  1.23s/it, loss=0.333, lr=2e-6, vram=5.7/9.7GB]#015Steps:  31%|███▏      | 352/1125 [07:07<15:48,  1.23s/it, loss=0.287, lr=2e-6, vram=5.7/9.7GB]#015Steps:  31%|███▏      | 353/1125 [07:07<15:45,  1.23s/it, loss=0.287, lr=2e-6, vram=5.7/9.7GB]#015Steps:  31%|███▏      | 354/1125 [07:08<15:40,  1.22s/it, loss=0.287, lr=2e-6, vram=5.7/9.7GB]#015Steps:  31%|███▏      | 354/1125 [07:09<15:40,  1.22s/it, loss=0.372, lr=2e-6, vram=5.7/9.7GB]#015Steps:  32%|███▏      | 355/1125 [07:09<15:35,  1.22s/it, loss=0.372, lr=2e-6, vram=5.7/9.7GB]#015Steps:  32%|███▏      | 356/1125 [07:11<15:32,  1.21s/it, loss=0.372, lr=2e-6, vram=5.7/9.7GB]#015Steps:  32%|███▏      | 356/1125 [07:12<15:32,  1.21s/it, loss=0.44, lr=2e-6, vram=5.7/9.7GB] #015Steps:  32%|███▏      | 357/1125 [07:12<15:32,  1.21s/it, loss=0.44, lr=2e-6, vram=5.7/9.7GB]#015Steps:  32%|███▏      | 358/1125 [07:13<15:34,  1.22s/it, loss=0.44, lr=2e-6, vram=5.7/9.7GB]#015Steps:  32%|███▏      | 358/1125 [07:14<15:34,  1.22s/it, loss=0.46, lr=2e-6, vram=5.7/9.7GB]#015Steps:  32%|███▏      | 359/1125 [07:14<15:34,  1.22s/it, loss=0.46, lr=2e-6, vram=5.7/9.7GB]#015Steps:  32%|███▏      | 360/1125 [07:15<15:27,  1.21s/it, loss=0.46, lr=2e-6, vram=5.7/9.7GB]#015Steps:  32%|███▏      | 360/1125 [07:17<15:27,  1.21s/it, loss=0.399, lr=2e-6, vram=5.7/9.7GB]#015Steps:  32%|███▏      | 361/1125 [07:17<15:37,  1.23s/it, loss=0.399, lr=2e-6, vram=5.7/9.7GB]#015Steps:  32%|███▏      | 362/1125 [07:18<15:34,  1.22s/it, loss=0.399, lr=2e-6, vram=5.7/9.7GB]#015Steps:  32%|███▏      | 362/1125 [07:19<15:34,  1.22s/it, loss=0.348, lr=2e-6, vram=5.7/9.7GB]#015Steps:  32%|███▏      | 363/1125 [07:19<15:31,  1.22s/it, loss=0.348, lr=2e-6, vram=5.7/9.7GB]#015Steps:  32%|███▏      | 364/1125 [07:20<15:26,  1.22s/it, loss=0.348, lr=2e-6, vram=5.7/9.7GB]#015Steps:  32%|███▏      | 364/1125 [07:22<15:26,  1.22s/it, loss=0.381, lr=2e-6, vram=5.7/9.7GB]#015Steps:  32%|███▏      | 365/1125 [07:22<15:29,  1.22s/it, loss=0.381, lr=2e-6, vram=5.7/9.7GB]#015Steps:  33%|███▎      | 366/1125 [07:23<15:26,  1.22s/it, loss=0.381, lr=2e-6, vram=5.7/9.7GB]#015Steps:  33%|███▎      | 366/1125 [07:24<15:26,  1.22s/it, loss=0.329, lr=2e-6, vram=5.7/9.7GB]#015Steps:  33%|███▎      | 367/1125 [07:24<15:21,  1.22s/it, loss=0.329, lr=2e-6, vram=5.7/9.7GB]#015Steps:  33%|███▎      | 368/1125 [07:25<15:18,  1.21s/it, loss=0.329, lr=2e-6, vram=5.7/9.7GB]#015Steps:  33%|███▎      | 368/1125 [07:26<15:18,  1.21s/it, loss=0.307, lr=2e-6, vram=5.7/9.7GB]#015Steps:  33%|███▎      | 369/1125 [07:26<15:13,  1.21s/it, loss=0.307, lr=2e-6, vram=5.7/9.7GB]#015Steps:  33%|███▎      | 370/1125 [07:28<15:17,  1.22s/it, loss=0.307, lr=2e-6, vram=5.7/9.7GB]#015Steps:  33%|███▎      | 370/1125 [07:29<15:17,  1.22s/it, loss=0.521, lr=2e-6, vram=5.7/9.7GB]#015Steps:  33%|███▎      | 371/1125 [07:29<15:14,  1.21s/it, loss=0.521, lr=2e-6, vram=5.7/9.7GB]#015Steps:  33%|███▎      | 372/1125 [07:30<15:12,  1.21s/it, loss=0.521, lr=2e-6, vram=5.7/9.7GB]#015Steps:  33%|███▎      | 372/1125 [07:31<15:12,  1.21s/it, loss=0.311, lr=2e-6, vram=5.7/9.7GB]#015Steps:  33%|███▎      | 373/1125 [07:31<15:14,  1.22s/it, loss=0.311, lr=2e-6, vram=5.7/9.7GB]#015Steps:  33%|███▎      | 374/1125 [07:33<15:15,  1.22s/it, loss=0.311, lr=2e-6, vram=5.7/9.7GB]#015Steps:  33%|███▎      | 374/1125 [07:34<15:15,  1.22s/it, loss=0.446, lr=2e-6, vram=5.7/9.7GB]#015Steps:  33%|███▎      | 375/1125 [07:34<15:17,  1.22s/it, loss=0.446, lr=2e-6, vram=5.7/9.7GB]#015Steps:  33%|███▎      | 376/1125 [07:35<15:12,  1.22s/it, loss=0.446, lr=2e-6, vram=5.7/9.7GB]#015Steps:  33%|███▎      | 376/1125 [07:36<15:12,  1.22s/it, loss=0.294, lr=2e-6, vram=5.7/9.7GB]#015Steps:  34%|███▎      | 377/1125 [07:36<15:13,  1.22s/it, loss=0.294, lr=2e-6, vram=5.7/9.7GB]#015Steps:  34%|███▎      | 378/1125 [07:37<15:07,  1.21s/it, loss=0.294, lr=2e-6, vram=5.7/9.7GB]#015Steps:  34%|███▎      | 378/1125 [07:39<15:07,  1.21s/it, loss=0.375, lr=2e-6, vram=5.7/9.7GB]#015Steps:  34%|███▎      | 379/1125 [07:39<15:08,  1.22s/it, loss=0.375, lr=2e-6, vram=5.7/9.7GB]#015Steps:  34%|███▍      | 380/1125 [07:40<15:08,  1.22s/it, loss=0.375, lr=2e-6, vram=5.7/9.7GB]#015Steps:  34%|███▍      | 380/1125 [07:41<15:08,  1.22s/it, loss=0.339, lr=2e-6, vram=5.7/9.7GB]#015Steps:  34%|███▍      | 381/1125 [07:41<15:04,  1.22s/it, loss=0.339, lr=2e-6, vram=5.7/9.7GB]#015Steps:  34%|███▍      | 382/1125 [07:42<15:07,  1.22s/it, loss=0.339, lr=2e-6, vram=5.7/9.7GB]#015Steps:  34%|███▍      | 382/1125 [07:44<15:07,  1.22s/it, loss=0.318, lr=2e-6, vram=5.7/9.7GB]#015Steps:  34%|███▍      | 383/1125 [07:44<15:07,  1.22s/it, loss=0.318, lr=2e-6, vram=5.7/9.7GB]#015Steps:  34%|███▍      | 384/1125 [07:45<15:03,  1.22s/it, loss=0.318, lr=2e-6, vram=5.7/9.7GB]#015Steps:  34%|███▍      | 384/1125 [07:46<15:03,  1.22s/it, loss=0.364, lr=2e-6, vram=5.7/9.7GB]#015Steps:  34%|███▍      | 385/1125 [07:46<15:04,  1.22s/it, loss=0.364, lr=2e-6, vram=5.7/9.7GB]#015Steps:  34%|███▍      | 386/1125 [07:47<15:01,  1.22s/it, loss=0.364, lr=2e-6, vram=5.7/9.7GB]#015Steps:  34%|███▍      | 386/1125 [07:48<15:01,  1.22s/it, loss=0.437, lr=2e-6, vram=5.7/9.7GB]#015Steps:  34%|███▍      | 387/1125 [07:48<14:54,  1.21s/it, loss=0.437, lr=2e-6, vram=5.7/9.7GB]#015Steps:  34%|███▍      | 388/1125 [07:50<14:54,  1.21s/it, loss=0.437, lr=2e-6, vram=5.7/9.7GB]#015Steps:  34%|███▍      | 388/1125 [07:51<14:54,  1.21s/it, loss=0.42, lr=2e-6, vram=5.7/9.7GB] #015Steps:  35%|███▍      | 389/1125 [07:51<14:55,  1.22s/it, loss=0.42, lr=2e-6, vram=5.7/9.7GB]#015Steps:  35%|███▍      | 390/1125 [07:52<14:56,  1.22s/it, loss=0.42, lr=2e-6, vram=5.7/9.7GB]#015Steps:  35%|███▍      | 390/1125 [07:53<14:56,  1.22s/it, loss=0.359, lr=2e-6, vram=5.7/9.7GB]#015Steps:  35%|███▍      | 391/1125 [07:53<14:54,  1.22s/it, loss=0.359, lr=2e-6, vram=5.7/9.7GB]#015Steps:  35%|███▍      | 392/1125 [07:54<14:50,  1.21s/it, loss=0.359, lr=2e-6, vram=5.7/9.7GB]#015Steps:  35%|███▍      | 392/1125 [07:56<14:50,  1.21s/it, loss=0.388, lr=2e-6, vram=5.7/9.7GB]#015Steps:  35%|███▍      | 393/1125 [07:56<14:52,  1.22s/it, loss=0.388, lr=2e-6, vram=5.7/9.7GB]#015Steps:  35%|███▌      | 394/1125 [07:57<14:54,  1.22s/it, loss=0.388, lr=2e-6, vram=5.7/9.7GB]#015Steps:  35%|███▌      | 394/1125 [07:58<14:54,  1.22s/it, loss=0.306, lr=2e-6, vram=5.7/9.7GB]#015Steps:  35%|███▌      | 395/1125 [07:58<14:50,  1.22s/it, loss=0.306, lr=2e-6, vram=5.7/9.7GB]#015Steps:  35%|███▌      | 396/1125 [07:59<14:43,  1.21s/it, loss=0.306, lr=2e-6, vram=5.7/9.7GB]#015Steps:  35%|███▌      | 396/1125 [08:01<14:43,  1.21s/it, loss=0.43, lr=2e-6, vram=5.7/9.7GB] #015Steps:  35%|███▌      | 397/1125 [08:01<14:47,  1.22s/it, loss=0.43, lr=2e-6, vram=5.7/9.7GB]#015Steps:  35%|███▌      | 398/1125 [08:02<14:43,  1.22s/it, loss=0.43, lr=2e-6, vram=5.7/9.7GB]#015Steps:  35%|███▌      | 398/1125 [08:03<14:43,  1.22s/it, loss=0.323, lr=2e-6, vram=5.7/9.7GB]#015Steps:  35%|███▌      | 399/1125 [08:03<14:45,  1.22s/it, loss=0.323, lr=2e-6, vram=5.7/9.7GB]#015Steps:  36%|███▌      | 400/1125 [08:04<14:47,  1.22s/it, loss=0.323, lr=2e-6, vram=5.7/9.7GB]#015Steps:  36%|███▌      | 400/1125 [08:05<14:47,  1.22s/it, loss=0.342, lr=2e-6, vram=5.7/9.7GB]#015Steps:  36%|███▌      | 401/1125 [08:05<14:43,  1.22s/it, loss=0.342, lr=2e-6, vram=5.7/9.7GB]#015Steps:  36%|███▌      | 402/1125 [08:07<14:43,  1.22s/it, loss=0.342, lr=2e-6, vram=5.7/9.7GB]#015Steps:  36%|███▌      | 402/1125 [08:08<14:43,  1.22s/it, loss=0.257, lr=2e-6, vram=5.7/9.7GB]#015Steps:  36%|███▌      | 403/1125 [08:08<14:40,  1.22s/it, loss=0.257, lr=2e-6, vram=5.7/9.7GB]#015Steps:  36%|███▌      | 404/1125 [08:09<14:40,  1.22s/it, loss=0.257, lr=2e-6, vram=5.7/9.7GB]#015Steps:  36%|███▌      | 404/1125 [08:10<14:40,  1.22s/it, loss=0.339, lr=2e-6, vram=5.7/9.7GB]#015Steps:  36%|███▌      | 405/1125 [08:10<14:33,  1.21s/it, loss=0.339, lr=2e-6, vram=5.7/9.7GB]#015Steps:  36%|███▌      | 406/1125 [08:12<14:44,  1.23s/it, loss=0.339, lr=2e-6, vram=5.7/9.7GB]#015Steps:  36%|███▌      | 406/1125 [08:13<14:44,  1.23s/it, loss=0.457, lr=2e-6, vram=5.7/9.7GB]#015Steps:  36%|███▌      | 407/1125 [08:13<14:42,  1.23s/it, loss=0.457, lr=2e-6, vram=5.7/9.7GB]#015Steps:  36%|███▋      | 408/1125 [08:14<14:37,  1.22s/it, loss=0.457, lr=2e-6, vram=5.7/9.7GB]#015Steps:  36%|███▋      | 408/1125 [08:15<14:37,  1.22s/it, loss=0.339, lr=2e-6, vram=5.7/9.7GB]#015Steps:  36%|███▋      | 409/1125 [08:15<14:31,  1.22s/it, loss=0.339, lr=2e-6, vram=5.7/9.7GB]#015Steps:  36%|███▋      | 410/1125 [08:16<14:27,  1.21s/it, loss=0.339, lr=2e-6, vram=5.7/9.7GB]#015Steps:  36%|███▋      | 410/1125 [08:18<14:27,  1.21s/it, loss=0.286, lr=2e-6, vram=5.7/9.7GB]#015Steps:  37%|███▋      | 411/1125 [08:18<14:25,  1.21s/it, loss=0.286, lr=2e-6, vram=5.7/9.7GB]#015Steps:  37%|███▋      | 412/1125 [08:19<14:25,  1.21s/it, loss=0.286, lr=2e-6, vram=5.7/9.7GB]#015Steps:  37%|███▋      | 412/1125 [08:20<14:25,  1.21s/it, loss=0.283, lr=2e-6, vram=5.7/9.7GB]#015Steps:  37%|███▋      | 413/1125 [08:20<14:26,  1.22s/it, loss=0.283, lr=2e-6, vram=5.7/9.7GB]#015Steps:  37%|███▋      | 414/1125 [08:21<14:20,  1.21s/it, loss=0.283, lr=2e-6, vram=5.7/9.7GB]#015Steps:  37%|███▋      | 414/1125 [08:23<14:20,  1.21s/it, loss=0.294, lr=2e-6, vram=5.7/9.7GB]#015Steps:  37%|███▋      | 415/1125 [08:23<14:30,  1.23s/it, loss=0.294, lr=2e-6, vram=5.7/9.7GB]#015Steps:  37%|███▋      | 416/1125 [08:24<14:24,  1.22s/it, loss=0.294, lr=2e-6, vram=5.7/9.7GB]#015Steps:  37%|███▋      | 416/1125 [08:25<14:24,  1.22s/it, loss=0.298, lr=2e-6, vram=5.7/9.7GB]#015Steps:  37%|███▋      | 417/1125 [08:25<14:20,  1.22s/it, loss=0.298, lr=2e-6, vram=5.7/9.7GB]#015Steps:  37%|███▋      | 418/1125 [08:26<14:22,  1.22s/it, loss=0.298, lr=2e-6, vram=5.7/9.7GB]#015Steps:  37%|███▋      | 418/1125 [08:27<14:22,  1.22s/it, loss=0.305, lr=2e-6, vram=5.7/9.7GB]#015Steps:  37%|███▋      | 419/1125 [08:27<14:24,  1.22s/it, loss=0.305, lr=2e-6, vram=5.7/9.7GB]#015Steps:  37%|███▋      | 420/1125 [08:29<14:23,  1.22s/it, loss=0.305, lr=2e-6, vram=5.7/9.7GB]#015Steps:  37%|███▋      | 420/1125 [08:30<14:23,  1.22s/it, loss=0.435, lr=2e-6, vram=5.7/9.7GB]#015Steps:  37%|███▋      | 421/1125 [08:30<14:19,  1.22s/it, loss=0.435, lr=2e-6, vram=5.7/9.7GB]#015Steps:  38%|███▊      | 422/1125 [08:31<14:16,  1.22s/it, loss=0.435, lr=2e-6, vram=5.7/9.7GB]#015Steps:  38%|███▊      | 422/1125 [08:32<14:16,  1.22s/it, loss=0.317, lr=2e-6, vram=5.7/9.7GB]#015Steps:  38%|███▊      | 423/1125 [08:32<14:10,  1.21s/it, loss=0.317, lr=2e-6, vram=5.7/9.7GB]#015Steps:  38%|███▊      | 424/1125 [08:34<14:19,  1.23s/it, loss=0.317, lr=2e-6, vram=5.7/9.7GB]#015Steps:  38%|███▊      | 424/1125 [08:35<14:19,  1.23s/it, loss=0.309, lr=2e-6, vram=5.7/9.7GB]#015Steps:  38%|███▊      | 425/1125 [08:35<14:19,  1.23s/it, loss=0.309, lr=2e-6, vram=5.7/9.7GB]#015Steps:  38%|███▊      | 426/1125 [08:36<14:13,  1.22s/it, loss=0.309, lr=2e-6, vram=5.7/9.7GB]#015Steps:  38%|███▊      | 426/1125 [08:37<14:13,  1.22s/it, loss=0.313, lr=2e-6, vram=5.7/9.7GB]#015Steps:  38%|███▊      | 427/1125 [08:37<14:08,  1.22s/it, loss=0.313, lr=2e-6, vram=5.7/9.7GB]#015Steps:  38%|███▊      | 428/1125 [08:38<14:09,  1.22s/it, loss=0.313, lr=2e-6, vram=5.7/9.7GB]#015Steps:  38%|███▊      | 428/1125 [08:40<14:09,  1.22s/it, loss=0.432, lr=2e-6, vram=5.7/9.7GB]#015Steps:  38%|███▊      | 429/1125 [08:40<14:06,  1.22s/it, loss=0.432, lr=2e-6, vram=5.7/9.7GB]#015Steps:  38%|███▊      | 430/1125 [08:41<14:05,  1.22s/it, loss=0.432, lr=2e-6, vram=5.7/9.7GB]#015Steps:  38%|███▊      | 430/1125 [08:42<14:05,  1.22s/it, loss=0.314, lr=2e-6, vram=5.7/9.7GB]#015Steps:  38%|███▊      | 431/1125 [08:42<14:05,  1.22s/it, loss=0.314, lr=2e-6, vram=5.7/9.7GB]#015Steps:  38%|███▊      | 432/1125 [08:43<13:59,  1.21s/it, loss=0.314, lr=2e-6, vram=5.7/9.7GB]#015Steps:  38%|███▊      | 432/1125 [08:44<13:59,  1.21s/it, loss=0.363, lr=2e-6, vram=5.7/9.7GB]#015Steps:  38%|███▊      | 433/1125 [08:44<14:04,  1.22s/it, loss=0.363, lr=2e-6, vram=5.7/9.7GB]#015Steps:  39%|███▊      | 434/1125 [08:46<14:00,  1.22s/it, loss=0.363, lr=2e-6, vram=5.7/9.7GB]#015Steps:  39%|███▊      | 434/1125 [08:47<14:00,  1.22s/it, loss=0.355, lr=2e-6, vram=5.7/9.7GB]#015Steps:  39%|███▊      | 435/1125 [08:47<13:59,  1.22s/it, loss=0.355, lr=2e-6, vram=5.7/9.7GB]#015Steps:  39%|███▉      | 436/1125 [08:48<13:55,  1.21s/it, loss=0.355, lr=2e-6, vram=5.7/9.7GB]#015Steps:  39%|███▉      | 436/1125 [08:49<13:55,  1.21s/it, loss=0.403, lr=2e-6, vram=5.7/9.7GB]#015Steps:  39%|███▉      | 437/1125 [08:49<13:57,  1.22s/it, loss=0.403, lr=2e-6, vram=5.7/9.7GB]#015Steps:  39%|███▉      | 438/1125 [08:51<13:54,  1.21s/it, loss=0.403, lr=2e-6, vram=5.7/9.7GB]#015Steps:  39%|███▉      | 438/1125 [08:52<13:54,  1.21s/it, loss=0.367, lr=2e-6, vram=5.7/9.7GB]#015Steps:  39%|███▉      | 439/1125 [08:52<13:54,  1.22s/it, loss=0.36\u001b[0m\n",
      "\u001b[34m Step 0 completed. \n",
      " Allocated: 5.7GB \n",
      " Reserved: 9.0GB \n",
      " Step 5 completed. \n",
      " Allocated: 5.7GB \u001b[0m\n",
      "\u001b[34m7, lr=2e-6, vram=5.7/9.7GB]#015Steps:  39%|███▉      | 440/1125 [08:53<13:56,  1.22s/it, loss=0.367, lr=2e-6, vram=5.7/9.7GB]#015Steps:  39%|███▉      | 440/1125 [08:54<13:56,  1.22s/it, loss=0.445, lr=2e-6, vram=5.7/9.7GB]#015Steps:  39%|███▉      | 441/1125 [08:54<13:50,  1.21s/it, loss=0.445, lr=2e-6, vram=5.7/9.7GB]#015Steps:  39%|███▉      | 442/1125 [08:55<13:56,  1.22s/it, loss=0.445, lr=2e-6, vram=5.7/9.7GB]#015Steps:  39%|███▉      | 442/1125 [08:57<13:56,  1.22s/it, loss=0.272, lr=2e-6, vram=5.7/9.7GB]#015Steps:  39%|███▉      | 443/1125 [08:57<13:52,  1.22s/it, loss=0.272, lr=2e-6, vram=5.7/9.7GB]#015Steps:  39%|███▉      | 444/1125 [08:58<13:48,  1.22s/it, loss=0.272, lr=2e-6, vram=5.7/9.7GB]#015Steps:  39%|███▉      | 444/1125 [08:59<13:48,  1.22s/it, loss=0.303, lr=2e-6, vram=5.7/9.7GB]#015Steps:  40%|███▉      | 445/1125 [08:59<13:51,  1.22s/it, loss=0.303, lr=2e-6, vram=5.7/9.7GB]#015Steps:  40%|███▉      | 446/1125 [09:00<13:46,  1.22s/it, loss=0.303, lr=2e-6, vram=5.7/9.7GB]#015Steps:  40%|███▉      | 446/1125 [09:02<13:46,  1.22s/it, loss=0.319, lr=2e-6, vram=5.7/9.7GB]#015Steps:  40%|███▉      | 447/1125 [09:02<13:47,  1.22s/it, loss=0.319, lr=2e-6, vram=5.7/9.7GB]#015Steps:  40%|███▉      | 448/1125 [09:03<13:47,  1.22s/it, loss=0.319, lr=2e-6, vram=5.7/9.7GB]#015Steps:  40%|███▉      | 448/1125 [09:04<13:47,  1.22s/it, loss=0.358, lr=2e-6, vram=5.7/9.7GB]#015Steps:  40%|███▉      | 449/1125 [09:04<13:44,  1.22s/it, loss=0.358, lr=2e-6, vram=5.7/9.7GB]#015Steps:  40%|████      | 450/1125 [09:05<13:38,  1.21s/it, loss=0.358, lr=2e-6, vram=5.7/9.7GB]#015Steps:  40%|████      | 450/1125 [09:06<13:38,  1.21s/it, loss=0.375, lr=2e-6, vram=5.7/9.7GB]#015Steps:  40%|████      | 451/1125 [09:06<13:43,  1.22s/it, loss=0.375, lr=2e-6, vram=5.7/9.7GB]#015Steps:  40%|████      | 452/1125 [09:08<13:40,  1.22s/it, loss=0.375, lr=2e-6, vram=5.7/9.7GB]#015Steps:  40%|████      | 452/1125 [09:09<13:40,  1.22s/it, loss=0.407, lr=2e-6, vram=5.7/9.7GB]#015Steps:  40%|████      | 453/1125 [09:09<13:38,  1.22s/it, loss=0.407, lr=2e-6, vram=5.7/9.7GB]#015Steps:  40%|████      | 454/1125 [09:10<13:35,  1.22s/it, loss=0.407, lr=2e-6, vram=5.7/9.7GB]#015Steps:  40%|████      | 454/1125 [09:11<13:35,  1.22s/it, loss=0.308, lr=2e-6, vram=5.7/9.7GB]#015Steps:  40%|████      | 455/1125 [09:11<13:38,  1.22s/it, loss=0.308, lr=2e-6, vram=5.7/9.7GB]#015Steps:  41%|████      | 456/1125 [09:13<13:39,  1.22s/it, loss=0.308, lr=2e-6, vram=5.7/9.7GB]#015Steps:  41%|████      | 456/1125 [09:14<13:39,  1.22s/it, loss=0.339, lr=2e-6, vram=5.7/9.7GB]#015Steps:  41%|████      | 457/1125 [09:14<13:39,  1.23s/it, loss=0.339, lr=2e-6, vram=5.7/9.7GB]#015Steps:  41%|████      | 458/1125 [09:15<13:33,  1.22s/it, loss=0.339, lr=2e-6, vram=5.7/9.7GB]#015Steps:  41%|████      | 458/1125 [09:16<13:33,  1.22s/it, loss=0.224, lr=2e-6, vram=5.7/9.7GB]#015Steps:  41%|████      | 459/1125 [09:16<13:27,  1.21s/it, loss=0.224, lr=2e-6, vram=5.7/9.7GB]#015Steps:  41%|████      | 460/1125 [09:17<13:32,  1.22s/it, loss=0.224, lr=2e-6, vram=5.7/9.7GB]#015Steps:  41%|████      | 460/1125 [09:19<13:32,  1.22s/it, loss=0.427, lr=2e-6, vram=5.7/9.7GB]#015Steps:  41%|████      | 461/1125 [09:19<13:33,  1.22s/it, loss=0.427, lr=2e-6, vram=5.7/9.7GB]#015Steps:  41%|████      | 462/1125 [09:20<13:28,  1.22s/it, loss=0.427, lr=2e-6, vram=5.7/9.7GB]#015Steps:  41%|████      | 462/1125 [09:21<13:28,  1.22s/it, loss=0.293, lr=2e-6, vram=5.7/9.7GB]#015Steps:  41%|████      | 463/1125 [09:21<13:28,  1.22s/it, loss=0.293, lr=2e-6, vram=5.7/9.7GB]#015Steps:  41%|████      | 464/1125 [09:22<13:30,  1.23s/it, loss=0.293, lr=2e-6, vram=5.7/9.7GB]#015Steps:  41%|████      | 464/1125 [09:23<13:30,  1.23s/it, loss=0.381, lr=2e-6, vram=5.7/9.7GB]#015Steps:  41%|████▏     | 465/1125 [09:23<13:25,  1.22s/it, loss=0.381, lr=2e-6, vram=5.7/9.7GB]#015Steps:  41%|████▏     | 466/1125 [09:25<13:22,  1.22s/it, loss=0.381, lr=2e-6, vram=5.7/9.7GB]#015Steps:  41%|████▏     | 466/1125 [09:26<13:22,  1.22s/it, loss=0.315, lr=2e-6, vram=5.7/9.7GB]#015Steps:  42%|████▏     | 467/1125 [09:26<13:22,  1.22s/it, loss=0.315, lr=2e-6, vram=5.7/9.7GB]#015Steps:  42%|████▏     | 468/1125 [09:27<13:16,  1.21s/it, loss=0.315, lr=2e-6, vram=5.7/9.7GB]#015Steps:  42%|████▏     | 468/1125 [09:28<13:16,  1.21s/it, loss=0.357, lr=2e-6, vram=5.7/9.7GB]#015Steps:  42%|████▏     | 469/1125 [09:28<13:16,  1.21s/it, loss=0.357, lr=2e-6, vram=5.7/9.7GB]#015Steps:  42%|████▏     | 470/1125 [09:30<13:15,  1.21s/it, loss=0.357, lr=2e-6, vram=5.7/9.7GB]#015Steps:  42%|████▏     | 470/1125 [09:31<13:15,  1.21s/it, loss=0.326, lr=2e-6, vram=5.7/9.7GB]#015Steps:  42%|████▏     | 471/1125 [09:31<13:16,  1.22s/it, loss=0.326, lr=2e-6, vram=5.7/9.7GB]#015Steps:  42%|████▏     | 472/1125 [09:32<13:19,  1.22s/it, loss=0.326, lr=2e-6, vram=5.7/9.7GB]#015Steps:  42%|████▏     | 472/1125 [09:33<13:19,  1.22s/it, loss=0.353, lr=2e-6, vram=5.7/9.7GB]#015Steps:  42%|████▏     | 473/1125 [09:33<13:17,  1.22s/it, loss=0.353, lr=2e-6, vram=5.7/9.7GB]#015Steps:  42%|████▏     | 474/1125 [09:34<13:17,  1.23s/it, loss=0.353, lr=2e-6, vram=5.7/9.7GB]#015Steps:  42%|████▏     | 474/1125 [09:36<13:17,  1.23s/it, loss=0.403, lr=2e-6, vram=5.7/9.7GB]#015Steps:  42%|████▏     | 475/1125 [09:36<13:17,  1.23s/it, loss=0.403, lr=2e-6, vram=5.7/9.7GB]#015Steps:  42%|████▏     | 476/1125 [09:37<13:11,  1.22s/it, loss=0.403, lr=2e-6, vram=5.7/9.7GB]#015Steps:  42%|████▏     | 476/1125 [09:38<13:11,  1.22s/it, loss=0.33, lr=2e-6, vram=5.7/9.7GB] #015Steps:  42%|████▏     | 477/1125 [09:38<13:05,  1.21s/it, loss=0.33, lr=2e-6, vram=5.7/9.7GB]#015Steps:  42%|████▏     | 478/1125 [09:39<13:09,  1.22s/it, loss=0.33, lr=2e-6, vram=5.7/9.7GB]#015Steps:  42%|████▏     | 478/1125 [09:41<13:09,  1.22s/it, loss=0.295, lr=2e-6, vram=5.7/9.7GB]#015Steps:  43%|████▎     | 479/1125 [09:41<13:07,  1.22s/it, loss=0.295, lr=2e-6, vram=5.7/9.7GB]#015Steps:  43%|████▎     | 480/1125 [09:42<13:07,  1.22s/it, loss=0.295, lr=2e-6, vram=5.7/9.7GB]#015Steps:  43%|████▎     | 480/1125 [09:43<13:07,  1.22s/it, loss=0.391, lr=2e-6, vram=5.7/9.7GB]#015Steps:  43%|████▎     | 481/1125 [09:43<13:03,  1.22s/it, loss=0.391, lr=2e-6, vram=5.7/9.7GB]#015Steps:  43%|████▎     | 482/1125 [09:44<13:02,  1.22s/it, loss=0.391, lr=2e-6, vram=5.7/9.7GB]#015Steps:  43%|████▎     | 482/1125 [09:45<13:02,  1.22s/it, loss=0.321, lr=2e-6, vram=5.7/9.7GB]#015Steps:  43%|████▎     | 483/1125 [09:45<12:59,  1.21s/it, loss=0.321, lr=2e-6, vram=5.7/9.7GB]#015Steps:  43%|████▎     | 484/1125 [09:47<13:01,  1.22s/it, loss=0.321, lr=2e-6, vram=5.7/9.7GB]#015Steps:  43%|████▎     | 484/1125 [09:48<13:01,  1.22s/it, loss=0.319, lr=2e-6, vram=5.7/9.7GB]#015Steps:  43%|████▎     | 485/1125 [09:48<13:01,  1.22s/it, loss=0.319, lr=2e-6, vram=5.7/9.7GB]#015Steps:  43%|████▎     | 486/1125 [09:49<12:55,  1.21s/it, loss=0.319, lr=2e-6, vram=5.7/9.7GB]#015Steps:  43%|████▎     | 486/1125 [09:50<12:55,  1.21s/it, loss=0.376, lr=2e-6, vram=5.7/9.7GB]#015Steps:  43%|████▎     | 487/1125 [09:50<13:00,  1.22s/it, loss=0.376, lr=2e-6, vram=5.7/9.7GB]#015Steps:  43%|████▎     | 488/1125 [09:52<13:02,  1.23s/it, loss=0.376, lr=2e-6, vram=5.7/9.7GB]#015Steps:  43%|████▎     | 488/1125 [09:53<13:02,  1.23s/it, loss=0.315, lr=2e-6, vram=5.7/9.7GB]#015Steps:  43%|████▎     | 489/1125 [09:53<13:00,  1.23s/it, loss=0.315, lr=2e-6, vram=5.7/9.7GB]#015Steps:  44%|████▎     | 490/1125 [09:54<12:55,  1.22s/it, loss=0.315, lr=2e-6, vram=5.7/9.7GB]#015Steps:  44%|████▎     | 490/1125 [09:55<12:55,  1.22s/it, loss=0.381, lr=2e-6, vram=5.7/9.7GB]#015Steps:  44%|████▎     | 491/1125 [09:55<12:53,  1.22s/it, loss=0.381, lr=2e-6, vram=5.7/9.7GB]#015Steps:  44%|████▎     | 492/1125 [09:56<12:53,  1.22s/it, loss=0.381, lr=2e-6, vram=5.7/9.7GB]#015Steps:  44%|████▎     | 492/1125 [09:58<12:53,  1.22s/it, loss=0.352, lr=2e-6, vram=5.7/9.7GB]#015Steps:  44%|████▍     | 493/1125 [09:58<12:49,  1.22s/it, loss=0.352, lr=2e-6, vram=5.7/9.7GB]#015Steps:  44%|████▍     | 494/1125 [09:59<12:45,  1.21s/it, loss=0.352, lr=2e-6, vram=5.7/9.7GB]#015Steps:  44%|████▍     | 494/1125 [10:00<12:45,  1.21s/it, loss=0.398, lr=2e-6, vram=5.7/9.7GB]#015Steps:  44%|████▍     | 495/1125 [10:00<12:41,  1.21s/it, loss=0.398, lr=2e-6, vram=5.7/9.7GB]#015Steps:  44%|████▍     | 496/1125 [10:01<12:46,  1.22s/it, loss=0.398, lr=2e-6, vram=5.7/9.7GB]#015Steps:  44%|████▍     | 496/1125 [10:02<12:46,  1.22s/it, loss=0.344, lr=2e-6, vram=5.7/9.7GB]#015Steps:  44%|████▍     | 497/1125 [10:02<12:46,  1.22s/it, loss=0.344, lr=2e-6, vram=5.7/9.7GB]#015Steps:  44%|████▍     | 498/1125 [10:04<12:43,  1.22s/it, loss=0.344, lr=2e-6, vram=5.7/9.7GB]#015Steps:  44%|████▍     | 498/1125 [10:05<12:43,  1.22s/it, loss=0.204, lr=2e-6, vram=5.7/9.7GB]#015Steps:  44%|████▍     | 499/1125 [10:05<12:39,  1.21s/it, loss=0.204, lr=2e-6, vram=5.7/9.7GB]#015Steps:  44%|████▍     | 500/1125 [10:06<12:36,  1.21s/it, loss=0.204, lr=2e-6, vram=5.7/9.7GB]#015Steps:  44%|████▍     | 500/1125 [10:07<12:36,  1.21s/it, loss=0.329, lr=2e-6, vram=5.7/9.7GB]\n",
      " Reserved: 9.7GB \n",
      " Allocated 7.0/9.2GB \n",
      " Reserved: 7.8/9.7GB \u001b[0m\n",
      "\u001b[34mCompiling checkpoint for aws-db-new-model...\u001b[0m\n",
      "\u001b[34mSaving checkpoint to /opt/ml/input/data/models/aws-db-new-model_500.ckpt...\u001b[0m\n",
      "\u001b[34m#015Generating samples:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Generating samples: 100%|██████████| 1/1 [00:14<00:00, 14.42s/it]#033[A#015Generating samples: 100%|██████████| 1/1 [00:14<00:00, 14.42s/it]\u001b[0m\n",
      "\u001b[34m#015Steps:  45%|████▍     | 501/1125 [11:29<4:26:59, 25.67s/it, loss=0.329, lr=2e-6, vram=5.7/9.7GB]#015Steps:  45%|████▍     | 502/1125 [11:30<3:10:20, 18.33s/it, loss=0.329, lr=2e-6, vram=5.7/9.7GB]#015Steps:  45%|████▍     | 502/1125 [11:31<3:10:20, 18.33s/it, loss=0.338, lr=2e-6, vram=5.7/11.9GB]#015Steps:  45%|████▍     | 503/1125 [11:31<2:16:43, 13.19s/it, loss=0.338, lr=2e-6, vram=5.7/11.9GB]#015Steps:  45%|████▍     | 504/1125 [11:32<1:39:10,  9.58s/it, loss=0.338, lr=2e-6, vram=5.7/11.9GB]#015Steps:  45%|████▍     | 504/1125 [11:34<1:39:10,  9.58s/it, loss=0.406, lr=2e-6, vram=5.7/11.9GB]#015Steps:  45%|████▍     | 505/1125 [11:34<1:13:04,  7.07s/it, loss=0.406, lr=2e-6, vram=5.7/11.9GB]#015Steps:  45%|████▍     | 506/1125 [11:35<54:43,  5.30s/it, loss=0.406, lr=2e-6, vram=5.7/11.9GB]  #015Steps:  45%|████▍     | 506/1125 [11:36<54:43,  5.30s/it, loss=0.339, lr=2e-6, vram=5.7/11.9GB]#015Steps:  45%|████▌     | 507/1125 [11:36<41:56,  4.07s/it, loss=0.339, lr=2e-6, vram=5.7/11.9GB]#015Steps:  45%|████▌     | 508/1125 [11:37<33:00,  3.21s/it, loss=0.339, lr=2e-6, vram=5.7/11.9GB]#015Steps:  45%|████▌     | 508/1125 [11:38<33:00,  3.21s/it, loss=0.471, lr=2e-6, vram=5.7/11.9GB]#015Steps:  45%|████▌     | 509/1125 [11:38<26:45,  2.61s/it, loss=0.471, lr=2e-6, vram=5.7/11.9GB]#015Steps:  45%|████▌     | 510/1125 [11:40<22:19,  2.18s/it, loss=0.471, lr=2e-6, vram=5.7/11.9GB]#015Steps:  45%|████▌     | 510/1125 [11:41<22:19,  2.18s/it, loss=0.319, lr=2e-6, vram=5.7/11.9GB]#015Steps:  45%|████▌     | 511/1125 [11:41<19:18,  1.89s/it, loss=0.319, lr=2e-6, vram=5.7/11.9GB]#015Steps:  46%|████▌     | 512/1125 [11:42<17:07,  1.68s/it, loss=0.319, lr=2e-6, vram=5.7/11.9GB]#015Steps:  46%|████▌     | 512/1125 [11:43<17:07,  1.68s/it, loss=0.564, lr=2e-6, vram=5.7/11.9GB]#015Steps:  46%|████▌     | 513/1125 [11:43<15:33,  1.53s/it, loss=0.564, lr=2e-6, vram=5.7/11.9GB]#015Steps:  46%|████▌     | 514/1125 [11:44<14:38,  1.44s/it, loss=0.564, lr=2e-6, vram=5.7/11.9GB]#015Steps:  46%|████▌     | 514/1125 [11:46<14:38,  1.44s/it, loss=0.323, lr=2e-6, vram=5.7/11.9GB]#015Steps:  46%|████▌     | 515/1125 [11:46<13:53,  1.37s/it, loss=0.323, lr=2e-6, vram=5.7/11.9GB]#015Steps:  46%|████▌     | 516/1125 [11:47<13:17,  1.31s/it, loss=0.323, lr=2e-6, vram=5.7/11.9GB]#015Steps:  46%|████▌     | 516/1125 [11:48<13:17,  1.31s/it, loss=0.509, lr=2e-6, vram=5.7/11.9GB]#015Steps:  46%|████▌     | 517/1125 [11:48<12:55,  1.28s/it, loss=0.509, lr=2e-6, vram=5.7/11.9GB]#015Steps:  46%|████▌     | 518/1125 [11:49<12:40,  1.25s/it, loss=0.509, lr=2e-6, vram=5.7/11.9GB]#015Steps:  46%|████▌     | 518/1125 [11:50<12:40,  1.25s/it, loss=0.283, lr=2e-6, vram=5.7/11.9GB]#015Steps:  46%|████▌     | 519/1125 [11:50<12:29,  1.24s/it, loss=0.283, lr=2e-6, vram=5.7/11.9GB]#015Steps:  46%|████▌     | 520/1125 [11:52<12:18,  1.22s/it, loss=0.283, lr=2e-6, vram=5.7/11.9GB]#015Steps:  46%|████▌     | 520/1125 [11:53<12:18,  1.22s/it, loss=0.309, lr=2e-6, vram=5.7/11.9GB]#015Steps:  46%|████▋     | 521/1125 [11:53<12:10,  1.21s/it, loss=0.309, lr=2e-6, vram=5.7/11.9GB]#015Steps:  46%|████▋     | 522/1125 [11:54<12:01,  1.20s/it, loss=0.309, lr=2e-6, vram=5.7/11.9GB]#015Steps:  46%|████▋     | 522/1125 [11:55<12:01,  1.20s/it, loss=0.268, lr=2e-6, vram=5.7/11.9GB]#015Steps:  46%|████▋     | 523/1125 [11:55<12:04,  1.20s/it, loss=0.268, lr=2e-6, vram=5.7/11.9GB]#015Steps:  47%|████▋     | 524/1125 [11:56<12:03,  1.20s/it, loss=0.268, lr=2e-6, vram=5.7/11.9GB]#015Steps:  47%|████▋     | 524/1125 [11:58<12:03,  1.20s/it, loss=0.274, lr=2e-6, vram=5.7/11.9GB]#015Steps:  47%|████▋     | 525/1125 [11:58<11:59,  1.20s/it, loss=0.274, lr=2e-6, vram=5.7/11.9GB]#015Steps:  47%|████▋     | 526/1125 [11:59<11:59,  1.20s/it, loss=0.274, lr=2e-6, vram=5.7/11.9GB]#015Steps:  47%|████▋     | 526/1125 [12:00<11:59,  1.20s/it, loss=0.384, lr=2e-6, vram=5.7/11.9GB]#015Steps:  47%|████▋     | 527/1125 [12:00<11:56,  1.20s/it, loss=0.384, lr=2e-6, vram=5.7/11.9GB]#015Steps:  47%|████▋     | 528/1125 [12:01<11:59,  1.20s/it, loss=0.384, lr=2e-6, vram=5.7/11.9GB]#015Steps:  47%|████▋     | 528/1125 [12:02<11:59,  1.20s/it, loss=0.288, lr=2e-6, vram=5.7/11.9GB]#015Steps:  47%|████▋     | 529/1125 [12:02<11:54,  1.20s/it, loss=0.288, lr=2e-6, vram=5.7/11.9GB]#015Steps:  47%|████▋     | 530/1125 [12:04<11:53,  1.20s/it, loss=0.288, lr=2e-6, vram=5.7/11.9GB]#015Steps:  47%|████▋     | 530/1125 [12:05<11:53,  1.20s/it, loss=0.446, lr=2e-6, vram=5.7/11.9GB]#015Steps:  47%|████▋     | 531/1125 [12:05<11:48,  1.19s/it, loss=0.446, lr=2e-6, vram=5.7/11.9GB]#015Steps:  47%|████▋     | 532/1125 [12:06<11:56,  1.21s/it, loss=0.446, lr=2e-6, vram=5.7/11.9GB]#015Steps:  47%|████▋     | 532/1125 [12:07<11:56,  1.21s/it, loss=0.455, lr=2e-6, vram=5.7/11.9GB]#015Steps:  47%|████▋     | 533/1125 [12:07<11:55,  1.21s/it, loss=0.455, lr=2e-6, vram=5.7/11.9GB]#015Steps:  47%|████▋     | 534/1125 [12:08<11:54,  1.21s/it, loss=0.455, lr=2e-6, vram=5.7/11.9GB]#015Steps:  47%|████▋     | 534/1125 [12:10<11:54,  1.21s/it, loss=0.294, lr=2e-6, vram=5.7/11.9GB]#015Steps:  48%|████▊     | 535/1125 [12:10<11:50,  1.20s/it, loss=0.294, lr=2e-6, vram=5.7/11.9GB]#015Steps:  48%|████▊     | 536/1125 [12:11<11:46,  1.20s/it, loss=0.294, lr=2e-6, vram=5.7/11.9GB]#015Steps:  48%|████▊     | 536/1125 [12:12<11:46,  1.20s/it, loss=0.241, lr=2e-6, vram=5.7/11.9GB]#015Steps:  48%|████▊     | 537/1125 [12:12<11:43,  1.20s/it, loss=0.241, lr=2e-6, vram=5.7/11.9GB]#015Steps:  48%|████▊     | 538/1125 [12:13<11:43,  1.20s/it, loss=0.241, lr=2e-6, vram=5.7/11.9GB]#015Steps:  48%|████▊     | 538/1125 [12:14<11:43,  1.20s/it, loss=0.318, lr=2e-6, vram=5.7/11.9GB]#015Steps:  48%|████▊     | 539/1125 [12:14<11:40,  1.20s/it, loss=0.318, lr=2e-6, vram=5.7/11.9GB]#015Steps:  48%|████▊     | 540/1125 [12:15<11:36,  1.19s/it, loss=0.318, lr=2e-6, vram=5.7/11.9GB]#015Steps:  48%|████▊     | 540/1125 [12:17<11:36,  1.19s/it, loss=0.338, lr=2e-6, vram=5.7/11.9GB]#015Steps:  48%|████▊     | 541/1125 [12:17<11:40,  1.20s/it, loss=0.338, lr=2e-6, vram=5.7/11.9GB]#015Steps:  48%|████▊     | 542/1125 [12:18<11:37,  1.20s/it, loss=0.338, lr=2e-6, vram=5.7/11.9GB]#015Steps:  48%|████▊     | 542/1125 [12:19<11:37,  1.20s/it, loss=0.36, lr=2e-6, vram=5.7/11.9GB] #015Steps:  48%|████▊     | 543/1125 [12:19<11:39,  1.20s/it, loss=0.36, lr=2e-6, vram=5.7/11.9GB]#015Steps:  48%|████▊     | 544/1125 [12:20<11:39,  1.20s/it, loss=0.36, lr=2e-6, vram=5.7/11.9GB]#015Steps:  48%|████▊     | 544/1125 [12:22<11:39,  1.20s/it, loss=0.398, lr=2e-6, vram=5.7/11.9GB]#015Steps:  48%|████▊     | 545/1125 [12:22<11:35,  1.20s/it, loss=0.398, lr=2e-6, vram=5.7/11.9GB]#015Steps:  49%|████▊     | 546/1125 [12:23<11:37,  1.21s/it, loss=0.398, lr=2e-6, vram=5.7/11.9GB]#015Steps:  49%|████▊     | 546/1125 [12:24<11:37,  1.21s/it, loss=0.293, lr=2e-6, vram=5.7/11.9GB]#015Steps:  49%|████▊     | 547/1125 [12:24<11:34,  1.20s/it, loss=0.293, lr=2e-6, vram=5.7/11.9GB]#015Steps:  49%|████▊     | 548/1125 [12:25<11:33,  1.20s/it, loss=0.293, lr=2e-6, vram=5.7/11.9GB]#015Steps:  49%|████▊     | 548/1125 [12:26<11:33,  1.20s/it, loss=0.357, lr=2e-6, vram=5.7/11.9GB]#015Steps:  49%|████▉     | 549/1125 [12:26<11:28,  1.20s/it, loss=0.357, lr=2e-6, vram=5.7/11.9GB]#015Steps:  49%|████▉     | 550/1125 [12:28<11:37,  1.21s/it, loss=0.357, lr=2e-6, vram=5.7/11.9GB]#015Steps:  49%|████▉     | 550/1125 [12:29<11:37,  1.21s/it, loss=0.465, lr=2e-6, vram=5.7/11.9GB]#015Steps:  49%|████▉     | 551/1125 [12:29<11:32,  1.21s/it, loss=0.465, lr=2e-6, vram=5.7/11.9GB]#015Steps:  49%|████▉     | 552/1125 [12:30<11:28,  1.20s/it, loss=0.465, lr=2e-6, vram=5.7/11.9GB]#015Steps:  49%|████▉     | 552/1125 [12:31<11:28,  1.20s/it, loss=0.524, lr=2e-6, vram=5.7/11.9GB]#015Steps:  49%|████▉     | 553/1125 [12:31<11:29,  1.20s/it, loss=0.524, lr=2e-6, vram=5.7/11.9GB]#015Steps:  49%|████▉     | 554/1125 [12:32<11:29,  1.21s/it, loss=0.524, lr=2e-6, vram=5.7/11.9GB]#015Steps:  49%|████▉     | 554/1125 [12:34<11:29,  1.21s/it, loss=0.353, lr=2e-6, vram=5.7/11.9GB]#015Steps:  49%|████▉     | 555/1125 [12:34<11:26,  1.20s/it, loss=0.353, lr=2e-6, vram=5.7/11.9GB]#015Steps:  49%|████▉     | 556/1125 [12:35<11:26,  1.21s/it, loss=0.353, lr=2e-6, vram=5.7/11.9GB]#015Steps:  49%|████▉     | 556/1125 [12:36<11:26,  1.21s/it, loss=0.407, lr=2e-6, vram=5.7/11.9GB]#015Steps:  50%|████▉     | 557/1125 [12:36<11:24,  1.20s/it, loss=0.407, lr=2e-6, vram=5.7/11.9GB]#015Steps:  50%|████▉     | 558/1125 [12:37<11:19,  1.20s/it, loss=0.407, lr=2e-6, vram=5.7/11.9GB]#015Steps:  50%|████▉     | 558/1125 [12:38<11:19,  1.20s/it, loss=0.624, lr=2e-6, vram=5.7/11.9GB]#015Steps:  50%|████▉     | 559/1125 [12:38<11:25,  1.21s/it, loss=0.624, lr=2e-6, vram=5.7/11.9GB]#015Steps:  50%|████▉     | 560/1125 [12:40<11:20,  1.20s/it, loss=0.624, lr=2e-6, vram=5.7/11.9GB]#015Steps:  50%|████▉     | 560/1125 [12:41<11:20,  1.20s/it, loss=0.285, lr=2e-6, vram=5.7/11.9GB]#015Steps:  50%|████▉     | 561/1125 [12:41<11:17,  1.20s/it, loss=0.285, lr=2e-6, vram=5.7/11.9GB]#015Steps:  50%|████▉     | 562/1125 [12:42<11:16,  1.20s/it, loss=0.285, lr=2e-6, vram=5.7/11.9GB]#015Steps:  50%|████▉     | 562/1125 [12:43<11:16,  1.20s/it, loss=0.535, lr=2e-6, vram=5.7/11.9GB]#015Steps:  50%|█████     | 563/1125 [12:43<11:14,  1.20s/it, loss=0.535, lr=2e-6, vram=5.7/11.9GB]#015Steps:  50%|█████     | 564/1125 [12:44<11:15,  1.20s/it, loss=0.535, lr=2e-6, vram=5.7/11.9GB]#015Steps:  50%|█████     | 564/1125 [12:46<11:15,  1.20s/it, loss=0.281, lr=2e-6, vram=5.7/11.9GB]#015Steps:  50%|█████     | 565/1125 [12:46<11:15,  1.21s/it, loss=0.281, lr=2e-6, vram=5.7/11.9GB]#015Steps:  50%|█████     | 566/1125 [12:47<11:17,  1.21s/it, loss=0.281, lr=2e-6, vram=5.7/11.9GB]#015Steps:  50%|█████     | 566/1125 [12:48<11:17,  1.21s/it, loss=0.335, lr=2e-6, vram=5.7/11.9GB]#015Steps:  50%|█████     | 567/1125 [12:48<11:11,  1.20s/it, loss=0.335, lr=2e-6, vram=5.7/11.9GB]#015Steps:  50%|█████     | 568/1125 [12:49<11:17,  1.22s/it, loss=0.335, lr=2e-6, vram=5.7/11.9GB]#015Steps:  50%|█████     | 568/1125 [12:50<11:17,  1.22s/it, loss=0.396, lr=2e-6, vram=5.7/11.9GB]#015Steps:  51%|█████     | 569/1125 [12:50<11:13,  1.21s/it, loss=0.396, lr=2e-6, vram=5.7/11.9GB]#015Steps:  51%|█████     | 570/1125 [12:52<11:11,  1.21s/it, loss=0.396, lr=2e-6, vram=5.7/11.9GB]#015Steps:  51%|█████     | 570/1125 [12:53<11:11,  1.21s/it, loss=0.402, lr=2e-6, vram=5.7/11.9GB]#015Steps:  51%|█████     | 571/1125 [12:53<11:10,  1.21s/it, loss=0.402, lr=2e-6, vram=5.7/11.9GB]#015Steps:  51%|█████     | 572/1125 [12:54<11:06,  1.21s/it, loss=0.402, lr=2e-6, vram=5.7/11.9GB]#015Steps:  51%|█████     | 572/1125 [12:55<11:06,  1.21s/it, loss=0.246, lr=2e-6, vram=5.7/11.9GB]#015Steps:  51%|█████     | 573/1125 [12:55<11:04,  1.20s/it, loss=0.246, lr=2e-6, vram=5.7/11.9GB]#015Steps:  51%|█████     | 574/1125 [12:56<11:05,  1.21s/it, loss=0.246, lr=2e-6, vram=5.7/11.9GB]#015Steps:  51%|█████     | 574/1125 [12:58<11:05,  1.21s/it, loss=0.51, lr=2e-6, vram=5.7/11.9GB] #015Steps:  51%|█████     | 575/1125 [12:58<11:05,  1.21s/it, loss=0.51, lr=2e-6, vram=5.7/11.9GB]#015Steps:  51%|█████     | 576/1125 [12:59<11:00,  1.20s/it, loss=0.51, lr=2e-6, vram=5.7/11.9GB]#015Steps:  51%|█████     | 576/1125 [13:00<11:00,  1.20s/it, loss=0.281, lr=2e-6, vram=5.7/11.9GB]#015Steps:  51%|█████▏    | 577/1125 [13:00<11:02,  1.21s/it, loss=0.281, lr=2e-6, vram=5.7/11.9GB]#015Steps:  51%|█████▏    | 578/1125 [13:01<11:01,  1.21s/it, loss=0.281, lr=2e-6, vram=5.7/11.9GB]#015Steps:  51%|█████▏    | 578/1125 [13:03<11:01,  1.21s/it, loss=0.308, lr=2e-6, vram=5.7/11.9GB]#015Steps:  51%|█████▏    | 579/1125 [13:03<10:58,  1.21s/it, loss=0.308, lr=2e-6, vram=5.7/11.9GB]#015Steps:  52%|█████▏    | 580/1125 [13:04<10:58,  1.21s/it, loss=0.308, lr=2e-6, vram=5.7/11.9GB]#015Steps:  52%|█████▏    | 580/1125 [13:05<10:58,  1.21s/it, loss=0.366, lr=2e-6, vram=5.7/11.9GB]#015Steps:  52%|█████▏    | 581/1125 [13:05<10:58,  1.21s/it, loss=0.366, lr=2e-6, vram=5.7/11.9GB]#015Steps:  52%|█████▏    | 582/1125 [13:06<10:57,  1.21s/it, loss=0.366, lr=2e-6, vram=5.7/11.9GB]#015Steps:  52%|█████▏    | 582/1125 [13:07<10:57,  1.21s/it, loss=0.413, lr=2e-6, vram=5.7/11.9GB]#015Steps:  52%|█████▏    | 583/1125 [13:07<10:53,  1.21s/it, loss=0.413, lr=2e-6, vram=5.7/11.9GB]#015Steps:  52%|█████▏    | 584/1125 [13:09<10:56,  1.21s/it, loss=0.413, lr=2e-6, vram=5.7/11.9GB]#015Steps:  52%|█████▏    | 584/1125 [13:10<10:56,  1.21s/it, loss=0.379, lr=2e-6, vram=5.7/11.9GB]#015Steps:  52%|█████▏    | 585/1125 [13:10<10:51,  1.21s/it, loss=0.379, lr=2e-6, vram=5.7/11.9GB]#015Steps:  52%|█████▏    | 586/1125 [13:11<10:56,  1.22s/it, loss=0.379, lr=2e-6, vram=5.7/11.9GB]#015Steps:  52%|█████▏    | 586/1125 [13:12<10:56,  1.22s/it, loss=0.421, lr=2e-6, vram=5.7/11.9GB]#015Steps:  52%|█████▏    | 587/1125 [13:12<10:52,  1.21s/it, loss=0.421, lr=2e-6, vram=5.7/11.9GB]#015Steps:  52%|█████▏    | 588/1125 [13:13<10:48,  1.21s/it, loss=0.421, lr=2e-6, vram=5.7/11.9GB]#015Steps:  52%|█████▏    | 588/1125 [13:15<10:48,  1.21s/it, loss=0.328, lr=2e-6, vram=5.7/11.9GB]#015Steps:  52%|█████▏    | 589/1125 [13:15<10:48,  1.21s/it, loss=0.328, lr=2e-6, vram=5.7/11.9GB]#015Steps:  52%|█████▏    | 590/1125 [13:16<10:49,  1.21s/it, loss=0.328, lr=2e-6, vram=5.7/11.9GB]#015Steps:  52%|█████▏    | 590/1125 [13:17<10:49,  1.21s/it, loss=0.384, lr=2e-6, vram=5.7/11.9GB]#015Steps:  53%|█████▎    | 591/1125 [13:17<10:46,  1.21s/it, loss=0.384, lr=2e-6, vram=5.7/11.9GB]#015Steps:  53%|█████▎    | 592/1125 [13:18<10:45,  1.21s/it, loss=0.384, lr=2e-6, vram=5.7/11.9GB]#015Steps:  53%|█████▎    | 592/1125 [13:19<10:45,  1.21s/it, loss=0.3, lr=2e-6, vram=5.7/11.9GB]  #015Steps:  53%|█████▎    | 593/1125 [13:19<10:45,  1.21s/it, loss=0.3, lr=2e-6, vram=5.7/11.9GB]#015Steps:  53%|█████▎    | 594/1125 [13:21<10:40,  1.21s/it, loss=0.3, lr=2e-6, vram=5.7/11.9GB]#015Steps:  53%|█████▎    | 594/1125 [13:22<10:40,  1.21s/it, loss=0.311, lr=2e-6, vram=5.7/11.9GB]#015Steps:  53%|█████▎    | 595/1125 [13:22<10:44,  1.22s/it, loss=0.311, lr=2e-6, vram=5.7/11.9GB]#015Steps:  53%|█████▎    | 596/1125 [13:23<10:45,  1.22s/it, loss=0.311, lr=2e-6, vram=5.7/11.9GB]#015Steps:  53%|█████▎    | 596/1125 [13:24<10:45,  1.22s/it, loss=0.307, lr=2e-6, vram=5.7/11.9GB]#015Steps:  53%|█████▎    | 597/1125 [13:24<10:40,  1.21s/it, loss=0.307, lr=2e-6, vram=5.7/11.9GB]#015Steps:  53%|█████▎    | 598/1125 [13:26<10:39,  1.21s/it, loss=0.307, lr=2e-6, vram=5.7/11.9GB]#015Steps:  53%|█████▎    | 598/1125 [13:27<10:39,  1.21s/it, loss=0.387, lr=2e-6, vram=5.7/11.9GB]#015Steps:  53%|█████▎    | 599/1125 [13:27<10:39,  1.21s/it, loss=0.387, lr=2e-6, vram=5.7/11.9GB]#015Steps:  53%|█████▎    | 600/1125 [13:28<10:38,  1.22s/it, loss=0.387, lr=2e-6, vram=5.7/11.9GB]#015Steps:  53%|█████▎    | 600/1125 [13:29<10:38,  1.22s/it, loss=0.526, lr=2e-6, vram=5.7/11.9GB]#015Steps:  53%|█████▎    | 601/1125 [13:29<10:34,  1.21s/it, loss=0.526, lr=2e-6, vram=5.7/11.9GB]#015Steps:  54%|█████▎    | 602/1125 [13:30<10:32,  1.21s/it, loss=0.526, lr=2e-6, vram=5.7/11.9GB]#015Steps:  54%|█████▎    | 602/1125 [13:32<10:32,  1.21s/it, loss=0.315, lr=2e-6, vram=5.7/11.9GB]#015Steps:  54%|█████▎    | 603/1125 [13:32<10:27,  1.20s/it, loss=0.315,\u001b[0m\n",
      "\u001b[34m lr=2e-6, vram=5.7/11.9GB]#015Steps:  54%|█████▎    | 604/1125 [13:33<10:30,  1.21s/it, loss=0.315, lr=2e-6, vram=5.7/11.9GB]#015Steps:  54%|█████▎    | 604/1125 [13:34<10:30,  1.21s/it, loss=0.462, lr=2e-6, vram=5.7/11.9GB]#015Steps:  54%|█████▍    | 605/1125 [13:34<10:33,  1.22s/it, loss=0.462, lr=2e-6, vram=5.7/11.9GB]#015Steps:  54%|█████▍    | 606/1125 [13:35<10:33,  1.22s/it, loss=0.462, lr=2e-6, vram=5.7/11.9GB]#015Steps:  54%|█████▍    | 606/1125 [13:36<10:33,  1.22s/it, loss=0.443, lr=2e-6, vram=5.7/11.9GB]#015Steps:  54%|█████▍    | 607/1125 [13:36<10:30,  1.22s/it, loss=0.443, lr=2e-6, vram=5.7/11.9GB]#015Steps:  54%|█████▍    | 608/1125 [13:38<10:29,  1.22s/it, loss=0.443, lr=2e-6, vram=5.7/11.9GB]#015Steps:  54%|█████▍    | 608/1125 [13:39<10:29,  1.22s/it, loss=0.378, lr=2e-6, vram=5.7/11.9GB]#015Steps:  54%|█████▍    | 609/1125 [13:39<10:26,  1.21s/it, loss=0.378, lr=2e-6, vram=5.7/11.9GB]#015Steps:  54%|█████▍    | 610/1125 [13:40<10:26,  1.22s/it, loss=0.378, lr=2e-6, vram=5.7/11.9GB]#015Steps:  54%|█████▍    | 610/1125 [13:41<10:26,  1.22s/it, loss=0.274, lr=2e-6, vram=5.7/11.9GB]#015Steps:  54%|█████▍    | 611/1125 [13:41<10:23,  1.21s/it, loss=0.274, lr=2e-6, vram=5.7/11.9GB]#015Steps:  54%|█████▍    | 612/1125 [13:43<10:18,  1.21s/it, loss=0.274, lr=2e-6, vram=5.7/11.9GB]#015Steps:  54%|█████▍    | 612/1125 [13:44<10:18,  1.21s/it, loss=0.244, lr=2e-6, vram=5.7/11.9GB]#015Steps:  54%|█████▍    | 613/1125 [13:44<10:22,  1.22s/it, loss=0.244, lr=2e-6, vram=5.7/11.9GB]#015Steps:  55%|█████▍    | 614/1125 [13:45<10:21,  1.22s/it, loss=0.244, lr=2e-6, vram=5.7/11.9GB]#015Steps:  55%|█████▍    | 614/1125 [13:46<10:21,  1.22s/it, loss=0.394, lr=2e-6, vram=5.7/11.9GB]#015Steps:  55%|█████▍    | 615/1125 [13:46<10:23,  1.22s/it, loss=0.394, lr=2e-6, vram=5.7/11.9GB]#015Steps:  55%|█████▍    | 616/1125 [13:47<10:20,  1.22s/it, loss=0.394, lr=2e-6, vram=5.7/11.9GB]#015Steps:  55%|█████▍    | 616/1125 [13:49<10:20,  1.22s/it, loss=0.498, lr=2e-6, vram=5.7/11.9GB]#015Steps:  55%|█████▍    | 617/1125 [13:49<10:20,  1.22s/it, loss=0.498, lr=2e-6, vram=5.7/11.9GB]#015Steps:  55%|█████▍    | 618/1125 [13:50<10:15,  1.21s/it, loss=0.498, lr=2e-6, vram=5.7/11.9GB]#015Steps:  55%|█████▍    | 618/1125 [13:51<10:15,  1.21s/it, loss=0.354, lr=2e-6, vram=5.7/11.9GB]#015Steps:  55%|█████▌    | 619/1125 [13:51<10:12,  1.21s/it, loss=0.354, lr=2e-6, vram=5.7/11.9GB]#015Steps:  55%|█████▌    | 620/1125 [13:52<10:11,  1.21s/it, loss=0.354, lr=2e-6, vram=5.7/11.9GB]#015Steps:  55%|█████▌    | 620/1125 [13:53<10:11,  1.21s/it, loss=0.469, lr=2e-6, vram=5.7/11.9GB]#015Steps:  55%|█████▌    | 621/1125 [13:53<10:07,  1.21s/it, loss=0.469, lr=2e-6, vram=5.7/11.9GB]#015Steps:  55%|█████▌    | 622/1125 [13:55<10:10,  1.21s/it, loss=0.469, lr=2e-6, vram=5.7/11.9GB]#015Steps:  55%|█████▌    | 622/1125 [13:56<10:10,  1.21s/it, loss=0.38, lr=2e-6, vram=5.7/11.9GB] #015Steps:  55%|█████▌    | 623/1125 [13:56<10:11,  1.22s/it, loss=0.38, lr=2e-6, vram=5.7/11.9GB]#015Steps:  55%|█████▌    | 624/1125 [13:57<10:07,  1.21s/it, loss=0.38, lr=2e-6, vram=5.7/11.9GB]#015Steps:  55%|█████▌    | 624/1125 [13:58<10:07,  1.21s/it, loss=0.585, lr=2e-6, vram=5.7/11.9GB]#015Steps:  56%|█████▌    | 625/1125 [13:58<10:07,  1.22s/it, loss=0.585, lr=2e-6, vram=5.7/11.9GB]#015Steps:  56%|█████▌    | 626/1125 [14:00<10:05,  1.21s/it, loss=0.585, lr=2e-6, vram=5.7/11.9GB]#015Steps:  56%|█████▌    | 626/1125 [14:01<10:05,  1.21s/it, loss=0.341, lr=2e-6, vram=5.7/11.9GB]#015Steps:  56%|█████▌    | 627/1125 [14:01<10:06,  1.22s/it, loss=0.341, lr=2e-6, vram=5.7/11.9GB]#015Steps:  56%|█████▌    | 628/1125 [14:02<10:04,  1.22s/it, loss=0.341, lr=2e-6, vram=5.7/11.9GB]#015Steps:  56%|█████▌    | 628/1125 [14:03<10:04,  1.22s/it, loss=0.424, lr=2e-6, vram=5.7/11.9GB]#015Steps:  56%|█████▌    | 629/1125 [14:03<10:01,  1.21s/it, loss=0.424, lr=2e-6, vram=5.7/11.9GB]#015Steps:  56%|█████▌    | 630/1125 [14:04<09:56,  1.21s/it, loss=0.424, lr=2e-6, vram=5.7/11.9GB]#015Steps:  56%|█████▌    | 630/1125 [14:06<09:56,  1.21s/it, loss=0.197, lr=2e-6, vram=5.7/11.9GB]#015Steps:  56%|█████▌    | 631/1125 [14:06<10:03,  1.22s/it, loss=0.197, lr=2e-6, vram=5.7/11.9GB]#015Steps:  56%|█████▌    | 632/1125 [14:07<09:58,  1.21s/it, loss=0.197, lr=2e-6, vram=5.7/11.9GB]#015Steps:  56%|█████▌    | 632/1125 [14:08<09:58,  1.21s/it, loss=0.227, lr=2e-6, vram=5.7/11.9GB]#015Steps:  56%|█████▋    | 633/1125 [14:08<09:55,  1.21s/it, loss=0.227, lr=2e-6, vram=5.7/11.9GB]#015Steps:  56%|█████▋    | 634/1125 [14:09<09:56,  1.21s/it, loss=0.227, lr=2e-6, vram=5.7/11.9GB]#015Steps:  56%|█████▋    | 634/1125 [14:10<09:56,  1.21s/it, loss=0.44, lr=2e-6, vram=5.7/11.9GB] #015Steps:  56%|█████▋    | 635/1125 [14:10<09:53,  1.21s/it, loss=0.44, lr=2e-6, vram=5.7/11.9GB]#015Steps:  57%|█████▋    | 636/1125 [14:12<09:55,  1.22s/it, loss=0.44, lr=2e-6, vram=5.7/11.9GB]#015Steps:  57%|█████▋    | 636/1125 [14:13<09:55,  1.22s/it, loss=0.295, lr=2e-6, vram=5.7/11.9GB]#015Steps:  57%|█████▋    | 637/1125 [14:13<09:53,  1.22s/it, loss=0.295, lr=2e-6, vram=5.7/11.9GB]#015Steps:  57%|█████▋    | 638/1125 [14:14<09:50,  1.21s/it, loss=0.295, lr=2e-6, vram=5.7/11.9GB]#015Steps:  57%|█████▋    | 638/1125 [14:15<09:50,  1.21s/it, loss=0.284, lr=2e-6, vram=5.7/11.9GB]#015Steps:  57%|█████▋    | 639/1125 [14:15<09:46,  1.21s/it, loss=0.284, lr=2e-6, vram=5.7/11.9GB]#015Steps:  57%|█████▋    | 640/1125 [14:17<09:51,  1.22s/it, loss=0.284, lr=2e-6, vram=5.7/11.9GB]#015Steps:  57%|█████▋    | 640/1125 [14:18<09:51,  1.22s/it, loss=0.334, lr=2e-6, vram=5.7/11.9GB]#015Steps:  57%|█████▋    | 641/1125 [14:18<09:47,  1.21s/it, loss=0.334, lr=2e-6, vram=5.7/11.9GB]#015Steps:  57%|█████▋    | 642/1125 [14:19<09:47,  1.22s/it, loss=0.334, lr=2e-6, vram=5.7/11.9GB]#015Steps:  57%|█████▋    | 642/1125 [14:20<09:47,  1.22s/it, loss=0.376, lr=2e-6, vram=5.7/11.9GB]#015Steps:  57%|█████▋    | 643/1125 [14:20<09:46,  1.22s/it, loss=0.376, lr=2e-6, vram=5.7/11.9GB]#015Steps:  57%|█████▋    | 644/1125 [14:21<09:43,  1.21s/it, loss=0.376, lr=2e-6, vram=5.7/11.9GB]#015Steps:  57%|█████▋    | 644/1125 [14:23<09:43,  1.21s/it, loss=0.23, lr=2e-6, vram=5.7/11.9GB] #015Steps:  57%|█████▋    | 645/1125 [14:23<09:43,  1.22s/it, loss=0.23, lr=2e-6, vram=5.7/11.9GB]#015Steps:  57%|█████▋    | 646/1125 [14:24<09:45,  1.22s/it, loss=0.23, lr=2e-6, vram=5.7/11.9GB]#015Steps:  57%|█████▋    | 646/1125 [14:25<09:45,  1.22s/it, loss=0.45, lr=2e-6, vram=5.7/11.9GB]#015Steps:  58%|█████▊    | 647/1125 [14:25<09:41,  1.22s/it, loss=0.45, lr=2e-6, vram=5.7/11.9GB]#015Steps:  58%|█████▊    | 648/1125 [14:26<09:36,  1.21s/it, loss=0.45, lr=2e-6, vram=5.7/11.9GB]#015Steps:  58%|█████▊    | 648/1125 [14:27<09:36,  1.21s/it, loss=0.364, lr=2e-6, vram=5.7/11.9GB]#015Steps:  58%|█████▊    | 649/1125 [14:27<09:36,  1.21s/it, loss=0.364, lr=2e-6, vram=5.7/11.9GB]#015Steps:  58%|█████▊    | 650/1125 [14:29<09:34,  1.21s/it, loss=0.364, lr=2e-6, vram=5.7/11.9GB]#015Steps:  58%|█████▊    | 650/1125 [14:30<09:34,  1.21s/it, loss=0.317, lr=2e-6, vram=5.7/11.9GB]#015Steps:  58%|█████▊    | 651/1125 [14:30<09:35,  1.21s/it, loss=0.317, lr=2e-6, vram=5.7/11.9GB]#015Steps:  58%|█████▊    | 652/1125 [14:31<09:36,  1.22s/it, loss=0.317, lr=2e-6, vram=5.7/11.9GB]#015Steps:  58%|█████▊    | 652/1125 [14:32<09:36,  1.22s/it, loss=0.46, lr=2e-6, vram=5.7/11.9GB] #015Steps:  58%|█████▊    | 653/1125 [14:32<09:35,  1.22s/it, loss=0.46, lr=2e-6, vram=5.7/11.9GB]#015Steps:  58%|█████▊    | 654/1125 [14:34<09:33,  1.22s/it, loss=0.46, lr=2e-6, vram=5.7/11.9GB]#015Steps:  58%|█████▊    | 654/1125 [14:35<09:33,  1.22s/it, loss=0.399, lr=2e-6, vram=5.7/11.9GB]#015Steps:  58%|█████▊    | 655/1125 [14:35<09:32,  1.22s/it, loss=0.399, lr=2e-6, vram=5.7/11.9GB]#015Steps:  58%|█████▊    | 656/1125 [14:36<09:29,  1.21s/it, loss=0.399, lr=2e-6, vram=5.7/11.9GB]#015Steps:  58%|█████▊    | 656/1125 [14:37<09:29,  1.21s/it, loss=0.312, lr=2e-6, vram=5.7/11.9GB]#015Steps:  58%|█████▊    | 657/1125 [14:37<09:25,  1.21s/it, loss=0.312, lr=2e-6, vram=5.7/11.9GB]#015Steps:  58%|█████▊    | 658/1125 [14:38<09:32,  1.23s/it, loss=0.312, lr=2e-6, vram=5.7/11.9GB]#015Steps:  58%|█████▊    | 658/1125 [14:40<09:32,  1.23s/it, loss=0.357, lr=2e-6, vram=5.7/11.9GB]#015Steps:  59%|█████▊    | 659/1125 [14:40<09:29,  1.22s/it, loss=0.357, lr=2e-6, vram=5.7/11.9GB]#015Steps:  59%|█████▊    | 660/1125 [14:41<09:25,  1.22s/it, loss=0.357, lr=2e-6, vram=5.7/11.9GB]#015Steps:  59%|█████▊    | 660/1125 [14:42<09:25,  1.22s/it, loss=0.264, lr=2e-6, vram=5.7/11.9GB]#015Steps:  59%|█████▉    | 661/1125 [14:42<09:23,  1.21s/it, loss=0.264, lr=2e-6, vram=5.7/11.9GB]#015Steps:  59%|█████▉    | 662/1125 [14:43<09:22,  1.21s/it, loss=0.264, lr=2e-6, vram=5.7/11.9GB]#015Steps:  59%|█████▉    | 662/1125 [14:45<09:22,  1.21s/it, loss=0.296, lr=2e-6, vram=5.7/11.9GB]#015Steps:  59%|█████▉    | 663/1125 [14:45<09:18,  1.21s/it, loss=0.296, lr=2e-6, vram=5.7/11.9GB]#015Steps:  59%|█████▉    | 664/1125 [14:46<09:16,  1.21s/it, loss=0.296, lr=2e-6, vram=5.7/11.9GB]#015Steps:  59%|█████▉    | 664/1125 [14:47<09:16,  1.21s/it, loss=0.353, lr=2e-6, vram=5.7/11.9GB]#015Steps:  59%|█████▉    | 665/1125 [14:47<09:18,  1.21s/it, loss=0.353, lr=2e-6, vram=5.7/11.9GB]#015Steps:  59%|█████▉    | 666/1125 [14:48<09:13,  1.21s/it, loss=0.353, lr=2e-6, vram=5.7/11.9GB]#015Steps:  59%|█████▉    | 666/1125 [14:49<09:13,  1.21s/it, loss=0.357, lr=2e-6, vram=5.7/11.9GB]#015Steps:  59%|█████▉    | 667/1125 [14:49<09:16,  1.22s/it, loss=0.357, lr=2e-6, vram=5.7/11.9GB]#015Steps:  59%|█████▉    | 668/1125 [14:51<09:13,  1.21s/it, loss=0.357, lr=2e-6, vram=5.7/11.9GB]#015Steps:  59%|█████▉    | 668/1125 [14:52<09:13,  1.21s/it, loss=0.588, lr=2e-6, vram=5.7/11.9GB]#015Steps:  59%|█████▉    | 669/1125 [14:52<09:15,  1.22s/it, loss=0.588, lr=2e-6, vram=5.7/11.9GB]#015Steps:  60%|█████▉    | 670/1125 [14:53<09:11,  1.21s/it, loss=0.588, lr=2e-6, vram=5.7/11.9GB]#015Steps:  60%|█████▉    | 670/1125 [14:54<09:11,  1.21s/it, loss=0.249, lr=2e-6, vram=5.7/11.9GB]#015Steps:  60%|█████▉    | 671/1125 [14:54<09:11,  1.22s/it, loss=0.249, lr=2e-6, vram=5.7/11.9GB]#015Steps:  60%|█████▉    | 672/1125 [14:55<09:11,  1.22s/it, loss=0.249, lr=2e-6, vram=5.7/11.9GB]#015Steps:  60%|█████▉    | 672/1125 [14:57<09:11,  1.22s/it, loss=0.422, lr=2e-6, vram=5.7/11.9GB]#015Steps:  60%|█████▉    | 673/1125 [14:57<09:10,  1.22s/it, loss=0.422, lr=2e-6, vram=5.7/11.9GB]#015Steps:  60%|█████▉    | 674/1125 [14:58<09:07,  1.21s/it, loss=0.422, lr=2e-6, vram=5.7/11.9GB]#015Steps:  60%|█████▉    | 674/1125 [14:59<09:07,  1.21s/it, loss=0.447, lr=2e-6, vram=5.7/11.9GB]#015Steps:  60%|██████    | 675/1125 [14:59<09:03,  1.21s/it, loss=0.447, lr=2e-6, vram=5.7/11.9GB]#015Steps:  60%|██████    | 676/1125 [15:00<09:04,  1.21s/it, loss=0.447, lr=2e-6, vram=5.7/11.9GB]#015Steps:  60%|██████    | 676/1125 [15:01<09:04,  1.21s/it, loss=0.292, lr=2e-6, vram=5.7/11.9GB]#015Steps:  60%|██████    | 677/1125 [15:01<09:01,  1.21s/it, loss=0.292, lr=2e-6, vram=5.7/11.9GB]#015Steps:  60%|██████    | 678/1125 [15:03<09:03,  1.22s/it, loss=0.292, lr=2e-6, vram=5.7/11.9GB]#015Steps:  60%|██████    | 678/1125 [15:04<09:03,  1.22s/it, loss=0.332, lr=2e-6, vram=5.7/11.9GB]#015Steps:  60%|██████    | 679/1125 [15:04<09:03,  1.22s/it, loss=0.332, lr=2e-6, vram=5.7/11.9GB]#015Steps:  60%|██████    | 680/1125 [15:05<09:00,  1.21s/it, loss=0.332, lr=2e-6, vram=5.7/11.9GB]#015Steps:  60%|██████    | 680/1125 [15:06<09:00,  1.21s/it, loss=0.245, lr=2e-6, vram=5.7/11.9GB]#015Steps:  61%|██████    | 681/1125 [15:06<09:00,  1.22s/it, loss=0.245, lr=2e-6, vram=5.7/11.9GB]#015Steps:  61%|██████    | 682/1125 [15:08<08:59,  1.22s/it, loss=0.245, lr=2e-6, vram=5.7/11.9GB]#015Steps:  61%|██████    | 682/1125 [15:09<08:59,  1.22s/it, loss=0.323, lr=2e-6, vram=5.7/11.9GB]#015Steps:  61%|██████    | 683/1125 [15:09<08:57,  1.22s/it, loss=0.323, lr=2e-6, vram=5.7/11.9GB]#015Steps:  61%|██████    | 684/1125 [15:10<08:52,  1.21s/it, loss=0.323, lr=2e-6, vram=5.7/11.9GB]#015Steps:  61%|██████    | 684/1125 [15:11<08:52,  1.21s/it, loss=0.321, lr=2e-6, vram=5.7/11.9GB]#015Steps:  61%|██████    | 685/1125 [15:11<08:55,  1.22s/it, loss=0.321, lr=2e-6, vram=5.7/11.9GB]#015Steps:  61%|██████    | 686/1125 [15:12<08:53,  1.21s/it, loss=0.321, lr=2e-6, vram=5.7/11.9GB]#015Steps:  61%|██████    | 686/1125 [15:14<08:53,  1.21s/it, loss=0.297, lr=2e-6, vram=5.7/11.9GB]#015Steps:  61%|██████    | 687/1125 [15:14<08:53,  1.22s/it, loss=0.297, lr=2e-6, vram=5.7/11.9GB]#015Steps:  61%|██████    | 688/1125 [15:15<08:51,  1.22s/it, loss=0.297, lr=2e-6, vram=5.7/11.9GB]#015Steps:  61%|██████    | 688/1125 [15:16<08:51,  1.22s/it, loss=0.433, lr=2e-6, vram=5.7/11.9GB]#015Steps:  61%|██████    | 689/1125 [15:16<08:52,  1.22s/it, loss=0.433, lr=2e-6, vram=5.7/11.9GB]#015Steps:  61%|██████▏   | 690/1125 [15:17<08:49,  1.22s/it, loss=0.433, lr=2e-6, vram=5.7/11.9GB]#015Steps:  61%|██████▏   | 690/1125 [15:19<08:49,  1.22s/it, loss=0.662, lr=2e-6, vram=5.7/11.9GB]#015Steps:  61%|██████▏   | 691/1125 [15:19<08:48,  1.22s/it, loss=0.662, lr=2e-6, vram=5.7/11.9GB]#015Steps:  62%|██████▏   | 692/1125 [15:20<08:45,  1.21s/it, loss=0.662, lr=2e-6, vram=5.7/11.9GB]#015Steps:  62%|██████▏   | 692/1125 [15:21<08:45,  1.21s/it, loss=0.32, lr=2e-6, vram=5.7/11.9GB] #015Steps:  62%|██████▏   | 693/1125 [15:21<08:42,  1.21s/it, loss=0.32, lr=2e-6, vram=5.7/11.9GB]#015Steps:  62%|██████▏   | 694/1125 [15:22<08:43,  1.21s/it, loss=0.32, lr=2e-6, vram=5.7/11.9GB]#015Steps:  62%|██████▏   | 694/1125 [15:23<08:43,  1.21s/it, loss=0.324, lr=2e-6, vram=5.7/11.9GB]#015Steps:  62%|██████▏   | 695/1125 [15:23<08:40,  1.21s/it, loss=0.324, lr=2e-6, vram=5.7/11.9GB]#015Steps:  62%|██████▏   | 696/1125 [15:25<08:39,  1.21s/it, loss=0.324, lr=2e-6, vram=5.7/11.9GB]#015Steps:  62%|██████▏   | 696/1125 [15:26<08:39,  1.21s/it, loss=0.274, lr=2e-6, vram=5.7/11.9GB]#015Steps:  62%|██████▏   | 697/1125 [15:26<08:39,  1.21s/it, loss=0.274, lr=2e-6, vram=5.7/11.9GB]#015Steps:  62%|██████▏   | 698/1125 [15:27<08:39,  1.22s/it, loss=0.274, lr=2e-6, vram=5.7/11.9GB]#015Steps:  62%|██████▏   | 698/1125 [15:28<08:39,  1.22s/it, loss=0.368, lr=2e-6, vram=5.7/11.9GB]#015Steps:  62%|██████▏   | 699/1125 [15:28<08:39,  1.22s/it, loss=0.368, lr=2e-6, vram=5.7/11.9GB]#015Steps:  62%|██████▏   | 700/1125 [15:29<08:39,  1.22s/it, loss=0.368, lr=2e-6, vram=5.7/11.9GB]#015Steps:  62%|██████▏   | 700/1125 [15:31<08:39,  1.22s/it, loss=0.354, lr=2e-6, vram=5.7/11.9GB]#015Steps:  62%|██████▏   | 701/1125 [15:31<08:36,  1.22s/it, loss=0.354, lr=2e-6, vram=5.7/11.9GB]#015Steps:  62%|██████▏   | 702/1125 [15:32<08:31,  1.21s/it, loss=0.354, lr=2e-6, vram=5.7/11.9GB]#015Steps:  62%|██████▏   | 702/1125 [15:33<08:31,  1.21s/it, loss=0.426, lr=2e-6, vram=5.7/11.9GB]#015Steps:  62%|██████▏   | 703/1125 [15:33<08:34,  1.22s/it, loss=0.426, lr=2e-6, vram=5.7/11.9GB]#015Steps:  63%|██████▎   | 704/1125 [15:34<08:32,  1.22s/it, loss=0.426, lr=2e-6, vram=5.7/11.9GB]#015Steps:  63%|██\u001b[0m\n",
      "\u001b[34m████▎   | 704/1125 [15:36<08:32,  1.22s/it, loss=0.266, lr=2e-6, vram=5.7/11.9GB]#015Steps:  63%|██████▎   | 705/1125 [15:36<08:33,  1.22s/it, loss=0.266, lr=2e-6, vram=5.7/11.9GB]#015Steps:  63%|██████▎   | 706/1125 [15:37<08:30,  1.22s/it, loss=0.266, lr=2e-6, vram=5.7/11.9GB]#015Steps:  63%|██████▎   | 706/1125 [15:38<08:30,  1.22s/it, loss=0.319, lr=2e-6, vram=5.7/11.9GB]#015Steps:  63%|██████▎   | 707/1125 [15:38<08:26,  1.21s/it, loss=0.319, lr=2e-6, vram=5.7/11.9GB]#015Steps:  63%|██████▎   | 708/1125 [15:39<08:26,  1.22s/it, loss=0.319, lr=2e-6, vram=5.7/11.9GB]#015Steps:  63%|██████▎   | 708/1125 [15:40<08:26,  1.22s/it, loss=0.371, lr=2e-6, vram=5.7/11.9GB]#015Steps:  63%|██████▎   | 709/1125 [15:40<08:24,  1.21s/it, loss=0.371, lr=2e-6, vram=5.7/11.9GB]#015Steps:  63%|██████▎   | 710/1125 [15:42<08:24,  1.21s/it, loss=0.371, lr=2e-6, vram=5.7/11.9GB]#015Steps:  63%|██████▎   | 710/1125 [15:43<08:24,  1.21s/it, loss=0.304, lr=2e-6, vram=5.7/11.9GB]#015Steps:  63%|██████▎   | 711/1125 [15:43<08:19,  1.21s/it, loss=0.304, lr=2e-6, vram=5.7/11.9GB]#015Steps:  63%|██████▎   | 712/1125 [15:44<08:22,  1.22s/it, loss=0.304, lr=2e-6, vram=5.7/11.9GB]#015Steps:  63%|██████▎   | 712/1125 [15:45<08:22,  1.22s/it, loss=0.418, lr=2e-6, vram=5.7/11.9GB]#015Steps:  63%|██████▎   | 713/1125 [15:45<08:23,  1.22s/it, loss=0.418, lr=2e-6, vram=5.7/11.9GB]#015Steps:  63%|██████▎   | 714/1125 [15:46<08:19,  1.22s/it, loss=0.418, lr=2e-6, vram=5.7/11.9GB]#015Steps:  63%|██████▎   | 714/1125 [15:48<08:19,  1.22s/it, loss=0.327, lr=2e-6, vram=5.7/11.9GB]#015Steps:  64%|██████▎   | 715/1125 [15:48<08:20,  1.22s/it, loss=0.327, lr=2e-6, vram=5.7/11.9GB]#015Steps:  64%|██████▎   | 716/1125 [15:49<08:18,  1.22s/it, loss=0.327, lr=2e-6, vram=5.7/11.9GB]#015Steps:  64%|██████▎   | 716/1125 [15:50<08:18,  1.22s/it, loss=0.4, lr=2e-6, vram=5.7/11.9GB]  #015Steps:  64%|██████▎   | 717/1125 [15:50<08:16,  1.22s/it, loss=0.4, lr=2e-6, vram=5.7/11.9GB]#015Steps:  64%|██████▍   | 718/1125 [15:51<08:16,  1.22s/it, loss=0.4, lr=2e-6, vram=5.7/11.9GB]#015Steps:  64%|██████▍   | 718/1125 [15:53<08:16,  1.22s/it, loss=0.427, lr=2e-6, vram=5.7/11.9GB]#015Steps:  64%|██████▍   | 719/1125 [15:53<08:13,  1.21s/it, loss=0.427, lr=2e-6, vram=5.7/11.9GB]#015Steps:  64%|██████▍   | 720/1125 [15:54<08:09,  1.21s/it, loss=0.427, lr=2e-6, vram=5.7/11.9GB]#015Steps:  64%|██████▍   | 720/1125 [15:55<08:09,  1.21s/it, loss=0.36, lr=2e-6, vram=5.7/11.9GB] #015Steps:  64%|██████▍   | 721/1125 [15:55<08:13,  1.22s/it, loss=0.36, lr=2e-6, vram=5.7/11.9GB]#015Steps:  64%|██████▍   | 722/1125 [15:56<08:09,  1.21s/it, loss=0.36, lr=2e-6, vram=5.7/11.9GB]#015Steps:  64%|██████▍   | 722/1125 [15:57<08:09,  1.21s/it, loss=0.285, lr=2e-6, vram=5.7/11.9GB]#015Steps:  64%|██████▍   | 723/1125 [15:57<08:08,  1.21s/it, loss=0.285, lr=2e-6, vram=5.7/11.9GB]#015Steps:  64%|██████▍   | 724/1125 [15:59<08:05,  1.21s/it, loss=0.285, lr=2e-6, vram=5.7/11.9GB]#015Steps:  64%|██████▍   | 724/1125 [16:00<08:05,  1.21s/it, loss=0.38, lr=2e-6, vram=5.7/11.9GB] #015Steps:  64%|██████▍   | 725/1125 [16:00<08:06,  1.22s/it, loss=0.38, lr=2e-6, vram=5.7/11.9GB]#015Steps:  65%|██████▍   | 726/1125 [16:01<08:07,  1.22s/it, loss=0.38, lr=2e-6, vram=5.7/11.9GB]#015Steps:  65%|██████▍   | 726/1125 [16:02<08:07,  1.22s/it, loss=0.275, lr=2e-6, vram=5.7/11.9GB]#015Steps:  65%|██████▍   | 727/1125 [16:02<08:05,  1.22s/it, loss=0.275, lr=2e-6, vram=5.7/11.9GB]#015Steps:  65%|██████▍   | 728/1125 [16:04<08:02,  1.21s/it, loss=0.275, lr=2e-6, vram=5.7/11.9GB]#015Steps:  65%|██████▍   | 728/1125 [16:05<08:02,  1.21s/it, loss=0.315, lr=2e-6, vram=5.7/11.9GB]#015Steps:  65%|██████▍   | 729/1125 [16:05<07:58,  1.21s/it, loss=0.315, lr=2e-6, vram=5.7/11.9GB]#015Steps:  65%|██████▍   | 730/1125 [16:06<07:58,  1.21s/it, loss=0.315, lr=2e-6, vram=5.7/11.9GB]#015Steps:  65%|██████▍   | 730/1125 [16:07<07:58,  1.21s/it, loss=0.329, lr=2e-6, vram=5.7/11.9GB]#015Steps:  65%|██████▍   | 731/1125 [16:07<07:58,  1.22s/it, loss=0.329, lr=2e-6, vram=5.7/11.9GB]#015Steps:  65%|██████▌   | 732/1125 [16:08<07:58,  1.22s/it, loss=0.329, lr=2e-6, vram=5.7/11.9GB]#015Steps:  65%|██████▌   | 732/1125 [16:10<07:58,  1.22s/it, loss=0.629, lr=2e-6, vram=5.7/11.9GB]#015Steps:  65%|██████▌   | 733/1125 [16:10<07:58,  1.22s/it, loss=0.629, lr=2e-6, vram=5.7/11.9GB]#015Steps:  65%|██████▌   | 734/1125 [16:11<07:55,  1.22s/it, loss=0.629, lr=2e-6, vram=5.7/11.9GB]#015Steps:  65%|██████▌   | 734/1125 [16:12<07:55,  1.22s/it, loss=0.286, lr=2e-6, vram=5.7/11.9GB]#015Steps:  65%|██████▌   | 735/1125 [16:12<07:53,  1.21s/it, loss=0.286, lr=2e-6, vram=5.7/11.9GB]#015Steps:  65%|██████▌   | 736/1125 [16:13<07:52,  1.21s/it, loss=0.286, lr=2e-6, vram=5.7/11.9GB]#015Steps:  65%|██████▌   | 736/1125 [16:14<07:52,  1.21s/it, loss=0.372, lr=2e-6, vram=5.7/11.9GB]#015Steps:  66%|██████▌   | 737/1125 [16:14<07:52,  1.22s/it, loss=0.372, lr=2e-6, vram=5.7/11.9GB]#015Steps:  66%|██████▌   | 738/1125 [16:16<07:48,  1.21s/it, loss=0.372, lr=2e-6, vram=5.7/11.9GB]#015Steps:  66%|██████▌   | 738/1125 [16:17<07:48,  1.21s/it, loss=0.402, lr=2e-6, vram=5.7/11.9GB]#015Steps:  66%|██████▌   | 739/1125 [16:17<07:50,  1.22s/it, loss=0.402, lr=2e-6, vram=5.7/11.9GB]#015Steps:  66%|██████▌   | 740/1125 [16:18<07:48,  1.22s/it, loss=0.402, lr=2e-6, vram=5.7/11.9GB]#015Steps:  66%|██████▌   | 740/1125 [16:19<07:48,  1.22s/it, loss=0.279, lr=2e-6, vram=5.7/11.9GB]#015Steps:  66%|██████▌   | 741/1125 [16:19<07:46,  1.21s/it, loss=0.279, lr=2e-6, vram=5.7/11.9GB]#015Steps:  66%|██████▌   | 742/1125 [16:21<07:46,  1.22s/it, loss=0.279, lr=2e-6, vram=5.7/11.9GB]#015Steps:  66%|██████▌   | 742/1125 [16:22<07:46,  1.22s/it, loss=0.284, lr=2e-6, vram=5.7/11.9GB]#015Steps:  66%|██████▌   | 743/1125 [16:22<07:47,  1.22s/it, loss=0.284, lr=2e-6, vram=5.7/11.9GB]#015Steps:  66%|██████▌   | 744/1125 [16:23<07:43,  1.22s/it, loss=0.284, lr=2e-6, vram=5.7/11.9GB]#015Steps:  66%|██████▌   | 744/1125 [16:24<07:43,  1.22s/it, loss=0.424, lr=2e-6, vram=5.7/11.9GB]#015Steps:  66%|██████▌   | 745/1125 [16:24<07:42,  1.22s/it, loss=0.424, lr=2e-6, vram=5.7/11.9GB]#015Steps:  66%|██████▋   | 746/1125 [16:25<07:41,  1.22s/it, loss=0.424, lr=2e-6, vram=5.7/11.9GB]#015Steps:  66%|██████▋   | 746/1125 [16:27<07:41,  1.22s/it, loss=0.483, lr=2e-6, vram=5.7/11.9GB]#015Steps:  66%|██████▋   | 747/1125 [16:27<07:38,  1.21s/it, loss=0.483, lr=2e-6, vram=5.7/11.9GB]#015Steps:  66%|██████▋   | 748/1125 [16:28<07:40,  1.22s/it, loss=0.483, lr=2e-6, vram=5.7/11.9GB]#015Steps:  66%|██████▋   | 748/1125 [16:29<07:40,  1.22s/it, loss=0.321, lr=2e-6, vram=5.7/11.9GB]#015Steps:  67%|██████▋   | 749/1125 [16:29<07:37,  1.22s/it, loss=0.321, lr=2e-6, vram=5.7/11.9GB]#015Steps:  67%|██████▋   | 750/1125 [16:30<07:35,  1.21s/it, loss=0.321, lr=2e-6, vram=5.7/11.9GB]#015Steps:  67%|██████▋   | 750/1125 [16:31<07:35,  1.21s/it, loss=0.394, lr=2e-6, vram=5.7/11.9GB]#015Steps:  67%|██████▋   | 751/1125 [16:31<07:33,  1.21s/it, loss=0.394, lr=2e-6, vram=5.7/11.9GB]#015Steps:  67%|██████▋   | 752/1125 [16:33<07:33,  1.21s/it, loss=0.394, lr=2e-6, vram=5.7/11.9GB]#015Steps:  67%|██████▋   | 752/1125 [16:34<07:33,  1.21s/it, loss=0.302, lr=2e-6, vram=5.7/11.9GB]#015Steps:  67%|██████▋   | 753/1125 [16:34<07:32,  1.22s/it, loss=0.302, lr=2e-6, vram=5.7/11.9GB]#015Steps:  67%|██████▋   | 754/1125 [16:35<07:32,  1.22s/it, loss=0.302, lr=2e-6, vram=5.7/11.9GB]#015Steps:  67%|██████▋   | 754/1125 [16:36<07:32,  1.22s/it, loss=0.518, lr=2e-6, vram=5.7/11.9GB]#015Steps:  67%|██████▋   | 755/1125 [16:36<07:32,  1.22s/it, loss=0.518, lr=2e-6, vram=5.7/11.9GB]#015Steps:  67%|██████▋   | 756/1125 [16:38<07:27,  1.21s/it, loss=0.518, lr=2e-6, vram=5.7/11.9GB]#015Steps:  67%|██████▋   | 756/1125 [16:39<07:27,  1.21s/it, loss=0.471, lr=2e-6, vram=5.7/11.9GB]#015Steps:  67%|██████▋   | 757/1125 [16:39<07:32,  1.23s/it, loss=0.471, lr=2e-6, vram=5.7/11.9GB]#015Steps:  67%|██████▋   | 758/1125 [16:40<07:29,  1.23s/it, loss=0.471, lr=2e-6, vram=5.7/11.9GB]#015Steps:  67%|██████▋   | 758/1125 [16:41<07:29,  1.23s/it, loss=0.34, lr=2e-6, vram=5.7/11.9GB] #015Steps:  67%|██████▋   | 759/1125 [16:41<07:27,  1.22s/it, loss=0.34, lr=2e-6, vram=5.7/11.9GB]#015Steps:  68%|██████▊   | 760/1125 [16:42<07:25,  1.22s/it, loss=0.34, lr=2e-6, vram=5.7/11.9GB]#015Steps:  68%|██████▊   | 760/1125 [16:44<07:25,  1.22s/it, loss=0.419, lr=2e-6, vram=5.7/11.9GB]#015Steps:  68%|██████▊   | 761/1125 [16:44<07:22,  1.22s/it, loss=0.419, lr=2e-6, vram=5.7/11.9GB]#015Steps:  68%|██████▊   | 762/1125 [16:45<07:20,  1.21s/it, loss=0.419, lr=2e-6, vram=5.7/11.9GB]#015Steps:  68%|██████▊   | 762/1125 [16:46<07:20,  1.21s/it, loss=0.397, lr=2e-6, vram=5.7/11.9GB]#015Steps:  68%|██████▊   | 763/1125 [16:46<07:20,  1.22s/it, loss=0.397, lr=2e-6, vram=5.7/11.9GB]#015Steps:  68%|██████▊   | 764/1125 [16:47<07:18,  1.21s/it, loss=0.397, lr=2e-6, vram=5.7/11.9GB]#015Steps:  68%|██████▊   | 764/1125 [16:49<07:18,  1.21s/it, loss=0.35, lr=2e-6, vram=5.7/11.9GB] #015Steps:  68%|██████▊   | 765/1125 [16:49<07:14,  1.21s/it, loss=0.35, lr=2e-6, vram=5.7/11.9GB]#015Steps:  68%|██████▊   | 766/1125 [16:50<07:14,  1.21s/it, loss=0.35, lr=2e-6, vram=5.7/11.9GB]#015Steps:  68%|██████▊   | 766/1125 [16:51<07:14,  1.21s/it, loss=0.338, lr=2e-6, vram=5.7/11.9GB]#015Steps:  68%|██████▊   | 767/1125 [16:51<07:15,  1.22s/it, loss=0.338, lr=2e-6, vram=5.7/11.9GB]#015Steps:  68%|██████▊   | 768/1125 [16:52<07:15,  1.22s/it, loss=0.338, lr=2e-6, vram=5.7/11.9GB]#015Steps:  68%|██████▊   | 768/1125 [16:53<07:15,  1.22s/it, loss=0.374, lr=2e-6, vram=5.7/11.9GB]#015Steps:  68%|██████▊   | 769/1125 [16:53<07:12,  1.22s/it, loss=0.374, lr=2e-6, vram=5.7/11.9GB]#015Steps:  68%|██████▊   | 770/1125 [16:55<07:13,  1.22s/it, loss=0.374, lr=2e-6, vram=5.7/11.9GB]#015Steps:  68%|██████▊   | 770/1125 [16:56<07:13,  1.22s/it, loss=0.237, lr=2e-6, vram=5.7/11.9GB]#015Steps:  69%|██████▊   | 771/1125 [16:56<07:12,  1.22s/it, loss=0.237, lr=2e-6, vram=5.7/11.9GB]#015Steps:  69%|██████▊   | 772/1125 [16:57<07:08,  1.21s/it, loss=0.237, lr=2e-6, vram=5.7/11.9GB]#015Steps:  69%|██████▊   | 772/1125 [16:58<07:08,  1.21s/it, loss=0.484, lr=2e-6, vram=5.7/11.9GB]#015Steps:  69%|██████▊   | 773/1125 [16:58<07:08,  1.22s/it, loss=0.484, lr=2e-6, vram=5.7/11.9GB]#015Steps:  69%|██████▉   | 774/1125 [16:59<07:04,  1.21s/it, loss=0.484, lr=2e-6, vram=5.7/11.9GB]#015Steps:  69%|██████▉   | 774/1125 [17:01<07:04,  1.21s/it, loss=0.315, lr=2e-6, vram=5.7/11.9GB]#015Steps:  69%|██████▉   | 775/1125 [17:01<07:09,  1.23s/it, loss=0.315, lr=2e-6, vram=5.7/11.9GB]#015Steps:  69%|██████▉   | 776/1125 [17:02<07:05,  1.22s/it, loss=0.315, lr=2e-6, vram=5.7/11.9GB]#015Steps:  69%|██████▉   | 776/1125 [17:03<07:05,  1.22s/it, loss=0.261, lr=2e-6, vram=5.7/11.9GB]#015Steps:  69%|██████▉   | 777/1125 [17:03<07:03,  1.22s/it, loss=0.261, lr=2e-6, vram=5.7/11.9GB]#015Steps:  69%|██████▉   | 778/1125 [17:04<07:04,  1.22s/it, loss=0.261, lr=2e-6, vram=5.7/11.9GB]#015Steps:  69%|██████▉   | 778/1125 [17:06<07:04,  1.22s/it, loss=0.321, lr=2e-6, vram=5.7/11.9GB]#015Steps:  69%|██████▉   | 779/1125 [17:06<07:02,  1.22s/it, loss=0.321, lr=2e-6, vram=5.7/11.9GB]#015Steps:  69%|██████▉   | 780/1125 [17:07<06:59,  1.22s/it, loss=0.321, lr=2e-6, vram=5.7/11.9GB]#015Steps:  69%|██████▉   | 780/1125 [17:08<06:59,  1.22s/it, loss=0.464, lr=2e-6, vram=5.7/11.9GB]#015Steps:  69%|██████▉   | 781/1125 [17:08<06:59,  1.22s/it, loss=0.464, lr=2e-6, vram=5.7/11.9GB]#015Steps:  70%|██████▉   | 782/1125 [17:09<06:57,  1.22s/it, loss=0.464, lr=2e-6, vram=5.7/11.9GB]#015Steps:  70%|██████▉   | 782/1125 [17:10<06:57,  1.22s/it, loss=0.364, lr=2e-6, vram=5.7/11.9GB]#015Steps:  70%|██████▉   | 783/1125 [17:10<06:53,  1.21s/it, loss=0.364, lr=2e-6, vram=5.7/11.9GB]#015Steps:  70%|██████▉   | 784/1125 [17:12<06:54,  1.22s/it, loss=0.364, lr=2e-6, vram=5.7/11.9GB]#015Steps:  70%|██████▉   | 784/1125 [17:13<06:54,  1.22s/it, loss=0.309, lr=2e-6, vram=5.7/11.9GB]#015Steps:  70%|██████▉   | 785/1125 [17:13<06:52,  1.21s/it, loss=0.309, lr=2e-6, vram=5.7/11.9GB]#015Steps:  70%|██████▉   | 786/1125 [17:14<06:50,  1.21s/it, loss=0.309, lr=2e-6, vram=5.7/11.9GB]#015Steps:  70%|██████▉   | 786/1125 [17:15<06:50,  1.21s/it, loss=0.345, lr=2e-6, vram=5.7/11.9GB]#015Steps:  70%|██████▉   | 787/1125 [17:15<06:50,  1.22s/it, loss=0.345, lr=2e-6, vram=5.7/11.9GB]#015Steps:  70%|███████   | 788/1125 [17:17<06:48,  1.21s/it, loss=0.345, lr=2e-6, vram=5.7/11.9GB]#015Steps:  70%|███████   | 788/1125 [17:18<06:48,  1.21s/it, loss=0.637, lr=2e-6, vram=5.7/11.9GB]#015Steps:  70%|███████   | 789/1125 [17:18<06:48,  1.22s/it, loss=0.637, lr=2e-6, vram=5.7/11.9GB]#015Steps:  70%|███████   | 790/1125 [17:19<06:49,  1.22s/it, loss=0.637, lr=2e-6, vram=5.7/11.9GB]#015Steps:  70%|███████   | 790/1125 [17:20<06:49,  1.22s/it, loss=0.498, lr=2e-6, vram=5.7/11.9GB]#015Steps:  70%|███████   | 791/1125 [17:20<06:47,  1.22s/it, loss=0.498, lr=2e-6, vram=5.7/11.9GB]#015Steps:  70%|███████   | 792/1125 [17:21<06:43,  1.21s/it, loss=0.498, lr=2e-6, vram=5.7/11.9GB]#015Steps:  70%|███████   | 792/1125 [17:23<06:43,  1.21s/it, loss=0.403, lr=2e-6, vram=5.7/11.9GB]#015Steps:  70%|███████   | 793/1125 [17:23<06:43,  1.22s/it, loss=0.403, lr=2e-6, vram=5.7/11.9GB]#015Steps:  71%|███████   | 794/1125 [17:24<06:41,  1.21s/it, loss=0.403, lr=2e-6, vram=5.7/11.9GB]#015Steps:  71%|███████   | 794/1125 [17:25<06:41,  1.21s/it, loss=0.225, lr=2e-6, vram=5.7/11.9GB]#015Steps:  71%|███████   | 795/1125 [17:25<06:42,  1.22s/it, loss=0.225, lr=2e-6, vram=5.7/11.9GB]#015Steps:  71%|███████   | 796/1125 [17:26<06:42,  1.22s/it, loss=0.225, lr=2e-6, vram=5.7/11.9GB]#015Steps:  71%|███████   | 796/1125 [17:28<06:42,  1.22s/it, loss=0.399, lr=2e-6, vram=5.7/11.9GB]#015Steps:  71%|███████   | 797/1125 [17:28<06:42,  1.23s/it, loss=0.399, lr=2e-6, vram=5.7/11.9GB]#015Steps:  71%|███████   | 798/1125 [17:29<06:40,  1.22s/it, loss=0.399, lr=2e-6, vram=5.7/11.9GB]#015Steps:  71%|███████   | 798/1125 [17:30<06:40,  1.22s/it, loss=0.462, lr=2e-6, vram=5.7/11.9GB]#015Steps:  71%|███████   | 799/1125 [17:30<06:38,  1.22s/it, loss=0.462, lr=2e-6, vram=5.7/11.9GB]#015Steps:  71%|███████   | 800/1125 [17:31<06:35,  1.22s/it, loss=0.462, lr=2e-6, vram=5.7/11.9GB]#015Steps:  71%|███████   | 800/1125 [17:32<06:35,  1.22s/it, loss=0.714, lr=2e-6, vram=5.7/11.9GB]#015Steps:  71%|███████   | 801/1125 [17:32<06:32,  1.21s/it, loss=0.714, lr=2e-6, vram=5.7/11.9GB]#015Steps:  71%|███████▏  | 802/1125 [17:34<06:34,  1.22s/it, loss=0.714, lr=2e-6, vram=5.7/11.9GB]#015Steps:  71%|███████▏  | 802/1125 [17:35<06:34,  1.22s/it, loss=0.59, lr=2e-6, vram=5.7/11.9GB] #015Steps:  71%|███████▏  | 803/1125 [17:35<06:32,  1.22s/it, loss=0.59, lr=2e-6, vram=5.7/11.9GB]#015Steps:  71%|██�\u001b[0m\n",
      "\u001b[34m��████▏  | 804/1125 [17:36<06:32,  1.22s/it, loss=0.59, lr=2e-6, vram=5.7/11.9GB]#015Steps:  71%|███████▏  | 804/1125 [17:37<06:32,  1.22s/it, loss=0.467, lr=2e-6, vram=5.7/11.9GB]#015Steps:  72%|███████▏  | 805/1125 [17:37<06:29,  1.22s/it, loss=0.467, lr=2e-6, vram=5.7/11.9GB]#015Steps:  72%|███████▏  | 806/1125 [17:38<06:30,  1.22s/it, loss=0.467, lr=2e-6, vram=5.7/11.9GB]#015Steps:  72%|███████▏  | 806/1125 [17:40<06:30,  1.22s/it, loss=0.311, lr=2e-6, vram=5.7/11.9GB]#015Steps:  72%|███████▏  | 807/1125 [17:40<06:29,  1.23s/it, loss=0.311, lr=2e-6, vram=5.7/11.9GB]#015Steps:  72%|███████▏  | 808/1125 [17:41<06:27,  1.22s/it, loss=0.311, lr=2e-6, vram=5.7/11.9GB]#015Steps:  72%|███████▏  | 808/1125 [17:42<06:27,  1.22s/it, loss=0.278, lr=2e-6, vram=5.7/11.9GB]#015Steps:  72%|███████▏  | 809/1125 [17:42<06:25,  1.22s/it, loss=0.278, lr=2e-6, vram=5.7/11.9GB]#015Steps:  72%|███████▏  | 810/1125 [17:43<06:21,  1.21s/it, loss=0.278, lr=2e-6, vram=5.7/11.9GB]#015Steps:  72%|███████▏  | 810/1125 [17:45<06:21,  1.21s/it, loss=0.294, lr=2e-6, vram=5.7/11.9GB]#015Steps:  72%|███████▏  | 811/1125 [17:45<06:25,  1.23s/it, loss=0.294, lr=2e-6, vram=5.7/11.9GB]#015Steps:  72%|███████▏  | 812/1125 [17:46<06:22,  1.22s/it, loss=0.294, lr=2e-6, vram=5.7/11.9GB]#015Steps:  72%|███████▏  | 812/1125 [17:47<06:22,  1.22s/it, loss=0.402, lr=2e-6, vram=5.7/11.9GB]#015Steps:  72%|███████▏  | 813/1125 [17:47<06:19,  1.22s/it, loss=0.402, lr=2e-6, vram=5.7/11.9GB]#015Steps:  72%|███████▏  | 814/1125 [17:48<06:19,  1.22s/it, loss=0.402, lr=2e-6, vram=5.7/11.9GB]#015Steps:  72%|███████▏  | 814/1125 [17:49<06:19,  1.22s/it, loss=0.266, lr=2e-6, vram=5.7/11.9GB]#015Steps:  72%|███████▏  | 815/1125 [17:49<06:17,  1.22s/it, loss=0.266, lr=2e-6, vram=5.7/11.9GB]#015Steps:  73%|███████▎  | 816/1125 [17:51<06:15,  1.21s/it, loss=0.266, lr=2e-6, vram=5.7/11.9GB]#015Steps:  73%|███████▎  | 816/1125 [17:52<06:15,  1.21s/it, loss=0.287, lr=2e-6, vram=5.7/11.9GB]#015Steps:  73%|███████▎  | 817/1125 [17:52<06:14,  1.22s/it, loss=0.287, lr=2e-6, vram=5.7/11.9GB]#015Steps:  73%|███████▎  | 818/1125 [17:53<06:15,  1.22s/it, loss=0.287, lr=2e-6, vram=5.7/11.9GB]#015Steps:  73%|███████▎  | 818/1125 [17:54<06:15,  1.22s/it, loss=0.305, lr=2e-6, vram=5.7/11.9GB]#015Steps:  73%|███████▎  | 819/1125 [17:54<06:12,  1.22s/it, loss=0.305, lr=2e-6, vram=5.7/11.9GB]#015Steps:  73%|███████▎  | 820/1125 [17:56<06:11,  1.22s/it, loss=0.305, lr=2e-6, vram=5.7/11.9GB]#015Steps:  73%|███████▎  | 820/1125 [17:57<06:11,  1.22s/it, loss=0.327, lr=2e-6, vram=5.7/11.9GB]#015Steps:  73%|███████▎  | 821/1125 [17:57<06:11,  1.22s/it, loss=0.327, lr=2e-6, vram=5.7/11.9GB]#015Steps:  73%|███████▎  | 822/1125 [17:58<06:11,  1.22s/it, loss=0.327, lr=2e-6, vram=5.7/11.9GB]#015Steps:  73%|███████▎  | 822/1125 [17:59<06:11,  1.22s/it, loss=0.285, lr=2e-6, vram=5.7/11.9GB]#015Steps:  73%|███████▎  | 823/1125 [17:59<06:10,  1.23s/it, loss=0.285, lr=2e-6, vram=5.7/11.9GB]#015Steps:  73%|███████▎  | 824/1125 [18:00<06:07,  1.22s/it, loss=0.285, lr=2e-6, vram=5.7/11.9GB]#015Steps:  73%|███████▎  | 824/1125 [18:02<06:07,  1.22s/it, loss=0.396, lr=2e-6, vram=5.7/11.9GB]#015Steps:  73%|███████▎  | 825/1125 [18:02<06:06,  1.22s/it, loss=0.396, lr=2e-6, vram=5.7/11.9GB]#015Steps:  73%|███████▎  | 826/1125 [18:03<06:04,  1.22s/it, loss=0.396, lr=2e-6, vram=5.7/11.9GB]#015Steps:  73%|███████▎  | 826/1125 [18:04<06:04,  1.22s/it, loss=0.389, lr=2e-6, vram=5.7/11.9GB]#015Steps:  74%|███████▎  | 827/1125 [18:04<06:03,  1.22s/it, loss=0.389, lr=2e-6, vram=5.7/11.9GB]#015Steps:  74%|███████▎  | 828/1125 [18:05<05:59,  1.21s/it, loss=0.389, lr=2e-6, vram=5.7/11.9GB]#015Steps:  74%|███████▎  | 828/1125 [18:07<05:59,  1.21s/it, loss=0.335, lr=2e-6, vram=5.7/11.9GB]#015Steps:  74%|███████▎  | 829/1125 [18:07<06:03,  1.23s/it, loss=0.335, lr=2e-6, vram=5.7/11.9GB]#015Steps:  74%|███████▍  | 830/1125 [18:08<06:01,  1.22s/it, loss=0.335, lr=2e-6, vram=5.7/11.9GB]#015Steps:  74%|███████▍  | 830/1125 [18:09<06:01,  1.22s/it, loss=0.25, lr=2e-6, vram=5.7/11.9GB] #015Steps:  74%|███████▍  | 831/1125 [18:09<06:01,  1.23s/it, loss=0.25, lr=2e-6, vram=5.7/11.9GB]#015Steps:  74%|███████▍  | 832/1125 [18:10<05:59,  1.23s/it, loss=0.25, lr=2e-6, vram=5.7/11.9GB]#015Steps:  74%|███████▍  | 832/1125 [18:11<05:59,  1.23s/it, loss=0.577, lr=2e-6, vram=5.7/11.9GB]#015Steps:  74%|███████▍  | 833/1125 [18:11<05:56,  1.22s/it, loss=0.577, lr=2e-6, vram=5.7/11.9GB]#015Steps:  74%|███████▍  | 834/1125 [18:13<05:54,  1.22s/it, loss=0.577, lr=2e-6, vram=5.7/11.9GB]#015Steps:  74%|███████▍  | 834/1125 [18:14<05:54,  1.22s/it, loss=0.378, lr=2e-6, vram=5.7/11.9GB]#015Steps:  74%|███████▍  | 835/1125 [18:14<05:52,  1.22s/it, loss=0.378, lr=2e-6, vram=5.7/11.9GB]#015Steps:  74%|███████▍  | 836/1125 [18:15<05:50,  1.21s/it, loss=0.378, lr=2e-6, vram=5.7/11.9GB]#015Steps:  74%|███████▍  | 836/1125 [18:16<05:50,  1.21s/it, loss=0.563, lr=2e-6, vram=5.7/11.9GB]#015Steps:  74%|███████▍  | 837/1125 [18:16<05:48,  1.21s/it, loss=0.563, lr=2e-6, vram=5.7/11.9GB]#015Steps:  74%|███████▍  | 838/1125 [18:18<05:48,  1.21s/it, loss=0.563, lr=2e-6, vram=5.7/11.9GB]#015Steps:  74%|███████▍  | 838/1125 [18:19<05:48,  1.21s/it, loss=0.352, lr=2e-6, vram=5.7/11.9GB]#015Steps:  75%|███████▍  | 839/1125 [18:19<05:48,  1.22s/it, loss=0.352, lr=2e-6, vram=5.7/11.9GB]#015Steps:  75%|███████▍  | 840/1125 [18:20<05:45,  1.21s/it, loss=0.352, lr=2e-6, vram=5.7/11.9GB]#015Steps:  75%|███████▍  | 840/1125 [18:21<05:45,  1.21s/it, loss=0.424, lr=2e-6, vram=5.7/11.9GB]#015Steps:  75%|███████▍  | 841/1125 [18:21<05:46,  1.22s/it, loss=0.424, lr=2e-6, vram=5.7/11.9GB]#015Steps:  75%|███████▍  | 842/1125 [18:22<05:44,  1.22s/it, loss=0.424, lr=2e-6, vram=5.7/11.9GB]#015Steps:  75%|███████▍  | 842/1125 [18:24<05:44,  1.22s/it, loss=0.428, lr=2e-6, vram=5.7/11.9GB]#015Steps:  75%|███████▍  | 843/1125 [18:24<05:45,  1.22s/it, loss=0.428, lr=2e-6, vram=5.7/11.9GB]#015Steps:  75%|███████▌  | 844/1125 [18:25<05:44,  1.23s/it, loss=0.428, lr=2e-6, vram=5.7/11.9GB]#015Steps:  75%|███████▌  | 844/1125 [18:26<05:44,  1.23s/it, loss=0.336, lr=2e-6, vram=5.7/11.9GB]#015Steps:  75%|███████▌  | 845/1125 [18:26<05:41,  1.22s/it, loss=0.336, lr=2e-6, vram=5.7/11.9GB]#015Steps:  75%|███████▌  | 846/1125 [18:27<05:38,  1.21s/it, loss=0.336, lr=2e-6, vram=5.7/11.9GB]#015Steps:  75%|███████▌  | 846/1125 [18:29<05:38,  1.21s/it, loss=0.287, lr=2e-6, vram=5.7/11.9GB]#015Steps:  75%|███████▌  | 847/1125 [18:29<05:41,  1.23s/it, loss=0.287, lr=2e-6, vram=5.7/11.9GB]#015Steps:  75%|███████▌  | 848/1125 [18:30<05:39,  1.23s/it, loss=0.287, lr=2e-6, vram=5.7/11.9GB]#015Steps:  75%|███████▌  | 848/1125 [18:31<05:39,  1.23s/it, loss=0.439, lr=2e-6, vram=5.7/11.9GB]#015Steps:  75%|███████▌  | 849/1125 [18:31<05:37,  1.22s/it, loss=0.439, lr=2e-6, vram=5.7/11.9GB]#015Steps:  76%|███████▌  | 850/1125 [18:32<05:36,  1.22s/it, loss=0.439, lr=2e-6, vram=5.7/11.9GB]#015Steps:  76%|███████▌  | 850/1125 [18:33<05:36,  1.22s/it, loss=0.537, lr=2e-6, vram=5.7/11.9GB]#015Steps:  76%|███████▌  | 851/1125 [18:33<05:34,  1.22s/it, loss=0.537, lr=2e-6, vram=5.7/11.9GB]#015Steps:  76%|███████▌  | 852/1125 [18:35<05:32,  1.22s/it, loss=0.537, lr=2e-6, vram=5.7/11.9GB]#015Steps:  76%|███████▌  | 852/1125 [18:36<05:32,  1.22s/it, loss=0.253, lr=2e-6, vram=5.7/11.9GB]#015Steps:  76%|███████▌  | 853/1125 [18:36<05:32,  1.22s/it, loss=0.253, lr=2e-6, vram=5.7/11.9GB]#015Steps:  76%|███████▌  | 854/1125 [18:37<05:29,  1.22s/it, loss=0.253, lr=2e-6, vram=5.7/11.9GB]#015Steps:  76%|███████▌  | 854/1125 [18:38<05:29,  1.22s/it, loss=0.564, lr=2e-6, vram=5.7/11.9GB]#015Steps:  76%|███████▌  | 855/1125 [18:38<05:27,  1.21s/it, loss=0.564, lr=2e-6, vram=5.7/11.9GB]#015Steps:  76%|███████▌  | 856/1125 [18:40<05:30,  1.23s/it, loss=0.564, lr=2e-6, vram=5.7/11.9GB]#015Steps:  76%|███████▌  | 856/1125 [18:41<05:30,  1.23s/it, loss=0.33, lr=2e-6, vram=5.7/11.9GB] #015Steps:  76%|███████▌  | 857/1125 [18:41<05:28,  1.22s/it, loss=0.33, lr=2e-6, vram=5.7/11.9GB]#015Steps:  76%|███████▋  | 858/1125 [18:42<05:25,  1.22s/it, loss=0.33, lr=2e-6, vram=5.7/11.9GB]#015Steps:  76%|███████▋  | 858/1125 [18:43<05:25,  1.22s/it, loss=0.259, lr=2e-6, vram=5.7/11.9GB]#015Steps:  76%|███████▋  | 859/1125 [18:43<05:25,  1.22s/it, loss=0.259, lr=2e-6, vram=5.7/11.9GB]#015Steps:  76%|███████▋  | 860/1125 [18:44<05:22,  1.22s/it, loss=0.259, lr=2e-6, vram=5.7/11.9GB]#015Steps:  76%|███████▋  | 860/1125 [18:46<05:22,  1.22s/it, loss=0.28, lr=2e-6, vram=5.7/11.9GB] #015Steps:  77%|███████▋  | 861/1125 [18:46<05:21,  1.22s/it, loss=0.28, lr=2e-6, vram=5.7/11.9GB]#015Steps:  77%|███████▋  | 862/1125 [18:47<05:21,  1.22s/it, loss=0.28, lr=2e-6, vram=5.7/11.9GB]#015Steps:  77%|███████▋  | 862/1125 [18:48<05:21,  1.22s/it, loss=0.267, lr=2e-6, vram=5.7/11.9GB]#015Steps:  77%|███████▋  | 863/1125 [18:48<05:18,  1.22s/it, loss=0.267, lr=2e-6, vram=5.7/11.9GB]#015Steps:  77%|███████▋  | 864/1125 [18:49<05:15,  1.21s/it, loss=0.267, lr=2e-6, vram=5.7/11.9GB]#015Steps:  77%|███████▋  | 864/1125 [18:50<05:15,  1.21s/it, loss=0.509, lr=2e-6, vram=5.7/11.9GB]#015Steps:  77%|███████▋  | 865/1125 [18:50<05:17,  1.22s/it, loss=0.509, lr=2e-6, vram=5.7/11.9GB]#015Steps:  77%|███████▋  | 866/1125 [18:52<05:14,  1.22s/it, loss=0.509, lr=2e-6, vram=5.7/11.9GB]#015Steps:  77%|███████▋  | 866/1125 [18:53<05:14,  1.22s/it, loss=0.356, lr=2e-6, vram=5.7/11.9GB]#015Steps:  77%|███████▋  | 867/1125 [18:53<05:14,  1.22s/it, loss=0.356, lr=2e-6, vram=5.7/11.9GB]#015Steps:  77%|███████▋  | 868/1125 [18:54<05:13,  1.22s/it, loss=0.356, lr=2e-6, vram=5.7/11.9GB]#015Steps:  77%|███████▋  | 868/1125 [18:55<05:13,  1.22s/it, loss=0.396, lr=2e-6, vram=5.7/11.9GB]#015Steps:  77%|███████▋  | 869/1125 [18:55<05:12,  1.22s/it, loss=0.396, lr=2e-6, vram=5.7/11.9GB]#015Steps:  77%|███████▋  | 870/1125 [18:57<05:12,  1.22s/it, loss=0.396, lr=2e-6, vram=5.7/11.9GB]#015Steps:  77%|███████▋  | 870/1125 [18:58<05:12,  1.22s/it, loss=0.487, lr=2e-6, vram=5.7/11.9GB]#015Steps:  77%|███████▋  | 871/1125 [18:58<05:10,  1.22s/it, loss=0.487, lr=2e-6, vram=5.7/11.9GB]#015Steps:  78%|███████▊  | 872/1125 [18:59<05:08,  1.22s/it, loss=0.487, lr=2e-6, vram=5.7/11.9GB]#015Steps:  78%|███████▊  | 872/1125 [19:00<05:08,  1.22s/it, loss=0.339, lr=2e-6, vram=5.7/11.9GB]#015Steps:  78%|███████▊  | 873/1125 [19:00<05:05,  1.21s/it, loss=0.339, lr=2e-6, vram=5.7/11.9GB]#015Steps:  78%|███████▊  | 874/1125 [19:01<05:06,  1.22s/it, loss=0.339, lr=2e-6, vram=5.7/11.9GB]#015Steps:  78%|███████▊  | 874/1125 [19:03<05:06,  1.22s/it, loss=0.418, lr=2e-6, vram=5.7/11.9GB]#015Steps:  78%|███████▊  | 875/1125 [19:03<05:06,  1.23s/it, loss=0.418, lr=2e-6, vram=5.7/11.9GB]#015Steps:  78%|███████▊  | 876/1125 [19:04<05:05,  1.23s/it, loss=0.418, lr=2e-6, vram=5.7/11.9GB]#015Steps:  78%|███████▊  | 876/1125 [19:05<05:05,  1.23s/it, loss=0.47, lr=2e-6, vram=5.7/11.9GB] #015Steps:  78%|███████▊  | 877/1125 [19:05<05:02,  1.22s/it, loss=0.47, lr=2e-6, vram=5.7/11.9GB]#015Steps:  78%|███████▊  | 878/1125 [19:06<05:00,  1.22s/it, loss=0.47, lr=2e-6, vram=5.7/11.9GB]#015Steps:  78%|███████▊  | 878/1125 [19:08<05:00,  1.22s/it, loss=0.311, lr=2e-6, vram=5.7/11.9GB]#015Steps:  78%|███████▊  | 879/1125 [19:08<05:00,  1.22s/it, loss=0.311, lr=2e-6, vram=5.7/11.9GB]#015Steps:  78%|███████▊  | 880/1125 [19:09<04:58,  1.22s/it, loss=0.311, lr=2e-6, vram=5.7/11.9GB]#015Steps:  78%|███████▊  | 880/1125 [19:10<04:58,  1.22s/it, loss=0.337, lr=2e-6, vram=5.7/11.9GB]#015Steps:  78%|███████▊  | 881/1125 [19:10<04:58,  1.22s/it, loss=0.337, lr=2e-6, vram=5.7/11.9GB]#015Steps:  78%|███████▊  | 882/1125 [19:11<04:55,  1.21s/it, loss=0.337, lr=2e-6, vram=5.7/11.9GB]#015Steps:  78%|███████▊  | 882/1125 [19:12<04:55,  1.21s/it, loss=0.326, lr=2e-6, vram=5.7/11.9GB]#015Steps:  78%|███████▊  | 883/1125 [19:12<04:54,  1.22s/it, loss=0.326, lr=2e-6, vram=5.7/11.9GB]#015Steps:  79%|███████▊  | 884/1125 [19:14<04:53,  1.22s/it, loss=0.326, lr=2e-6, vram=5.7/11.9GB]#015Steps:  79%|███████▊  | 884/1125 [19:15<04:53,  1.22s/it, loss=0.419, lr=2e-6, vram=5.7/11.9GB]#015Steps:  79%|███████▊  | 885/1125 [19:15<04:53,  1.22s/it, loss=0.419, lr=2e-6, vram=5.7/11.9GB]#015Steps:  79%|███████▉  | 886/1125 [19:16<04:51,  1.22s/it, loss=0.419, lr=2e-6, vram=5.7/11.9GB]#015Steps:  79%|███████▉  | 886/1125 [19:17<04:51,  1.22s/it, loss=0.531, lr=2e-6, vram=5.7/11.9GB]#015Steps:  79%|███████▉  | 887/1125 [19:17<04:49,  1.22s/it, loss=0.531, lr=2e-6, vram=5.7/11.9GB]#015Steps:  79%|███████▉  | 888/1125 [19:19<04:49,  1.22s/it, loss=0.531, lr=2e-6, vram=5.7/11.9GB]#015Steps:  79%|███████▉  | 888/1125 [19:20<04:49,  1.22s/it, loss=0.351, lr=2e-6, vram=5.7/11.9GB]#015Steps:  79%|███████▉  | 889/1125 [19:20<04:49,  1.23s/it, loss=0.351, lr=2e-6, vram=5.7/11.9GB]#015Steps:  79%|███████▉  | 890/1125 [19:21<04:47,  1.23s/it, loss=0.351, lr=2e-6, vram=5.7/11.9GB]#015Steps:  79%|███████▉  | 890/1125 [19:22<04:47,  1.23s/it, loss=0.344, lr=2e-6, vram=5.7/11.9GB]#015Steps:  79%|███████▉  | 891/1125 [19:22<04:45,  1.22s/it, loss=0.344, lr=2e-6, vram=5.7/11.9GB]#015Steps:  79%|███████▉  | 892/1125 [19:23<04:46,  1.23s/it, loss=0.344, lr=2e-6, vram=5.7/11.9GB]#015Steps:  79%|███████▉  | 892/1125 [19:25<04:46,  1.23s/it, loss=0.359, lr=2e-6, vram=5.7/11.9GB]#015Steps:  79%|███████▉  | 893/1125 [19:25<04:43,  1.22s/it, loss=0.359, lr=2e-6, vram=5.7/11.9GB]#015Steps:  79%|███████▉  | 894/1125 [19:26<04:42,  1.22s/it, loss=0.359, lr=2e-6, vram=5.7/11.9GB]#015Steps:  79%|███████▉  | 894/1125 [19:27<04:42,  1.22s/it, loss=0.327, lr=2e-6, vram=5.7/11.9GB]#015Steps:  80%|███████▉  | 895/1125 [19:27<04:40,  1.22s/it, loss=0.327, lr=2e-6, vram=5.7/11.9GB]#015Steps:  80%|███████▉  | 896/1125 [19:28<04:39,  1.22s/it, loss=0.327, lr=2e-6, vram=5.7/11.9GB]#015Steps:  80%|███████▉  | 896/1125 [19:30<04:39,  1.22s/it, loss=0.344, lr=2e-6, vram=5.7/11.9GB]#015Steps:  80%|███████▉  | 897/1125 [19:30<04:39,  1.22s/it, loss=0.344, lr=2e-6, vram=5.7/11.9GB]#015Steps:  80%|███████▉  | 898/1125 [19:31<04:36,  1.22s/it, loss=0.344, lr=2e-6, vram=5.7/11.9GB]#015Steps:  80%|███████▉  | 898/1125 [19:32<04:36,  1.22s/it, loss=0.332, lr=2e-6, vram=5.7/11.9GB]#015Steps:  80%|███████▉  | 899/1125 [19:32<04:36,  1.22s/it, loss=0.332, lr=2e-6, vram=5.7/11.9GB]#015Steps:  80%|████████  | 900/1125 [19:33<04:33,  1.22s/it, loss=0.332, lr=2e-6, vram=5.7/11.9GB]#015Steps:  80%|████████  | 900/1125 [19:34<04:33,  1.22s/it, loss=0.315, lr=2e-6, vram=5.7/11.9GB]#015Steps:  80%|████████  | 901/1125 [19:34<04:3\u001b[0m\n",
      "\u001b[34m5,  1.23s/it, loss=0.315, lr=2e-6, vram=5.7/11.9GB]#015Steps:  80%|████████  | 902/1125 [19:36<04:32,  1.22s/it, loss=0.315, lr=2e-6, vram=5.7/11.9GB]#015Steps:  80%|████████  | 902/1125 [19:37<04:32,  1.22s/it, loss=0.295, lr=2e-6, vram=5.7/11.9GB]#015Steps:  80%|████████  | 903/1125 [19:37<04:32,  1.23s/it, loss=0.295, lr=2e-6, vram=5.7/11.9GB]#015Steps:  80%|████████  | 904/1125 [19:38<04:29,  1.22s/it, loss=0.295, lr=2e-6, vram=5.7/11.9GB]#015Steps:  80%|████████  | 904/1125 [19:39<04:29,  1.22s/it, loss=0.257, lr=2e-6, vram=5.7/11.9GB]#015Steps:  80%|████████  | 905/1125 [19:39<04:28,  1.22s/it, loss=0.257, lr=2e-6, vram=5.7/11.9GB]#015Steps:  81%|████████  | 906/1125 [19:41<04:27,  1.22s/it, loss=0.257, lr=2e-6, vram=5.7/11.9GB]#015Steps:  81%|████████  | 906/1125 [19:42<04:27,  1.22s/it, loss=0.594, lr=2e-6, vram=5.7/11.9GB]#015Steps:  81%|████████  | 907/1125 [19:42<04:27,  1.22s/it, loss=0.594, lr=2e-6, vram=5.7/11.9GB]#015Steps:  81%|████████  | 908/1125 [19:43<04:24,  1.22s/it, loss=0.594, lr=2e-6, vram=5.7/11.9GB]#015Steps:  81%|████████  | 908/1125 [19:44<04:24,  1.22s/it, loss=0.401, lr=2e-6, vram=5.7/11.9GB]#015Steps:  81%|████████  | 909/1125 [19:44<04:22,  1.21s/it, loss=0.401, lr=2e-6, vram=5.7/11.9GB]#015Steps:  81%|████████  | 910/1125 [19:45<04:25,  1.24s/it, loss=0.401, lr=2e-6, vram=5.7/11.9GB]#015Steps:  81%|████████  | 910/1125 [19:47<04:25,  1.24s/it, loss=0.411, lr=2e-6, vram=5.7/11.9GB]#015Steps:  81%|████████  | 911/1125 [19:47<04:22,  1.23s/it, loss=0.411, lr=2e-6, vram=5.7/11.9GB]#015Steps:  81%|████████  | 912/1125 [19:48<04:21,  1.23s/it, loss=0.411, lr=2e-6, vram=5.7/11.9GB]#015Steps:  81%|████████  | 912/1125 [19:49<04:21,  1.23s/it, loss=0.387, lr=2e-6, vram=5.7/11.9GB]#015Steps:  81%|████████  | 913/1125 [19:49<04:20,  1.23s/it, loss=0.387, lr=2e-6, vram=5.7/11.9GB]#015Steps:  81%|████████  | 914/1125 [19:50<04:18,  1.23s/it, loss=0.387, lr=2e-6, vram=5.7/11.9GB]#015Steps:  81%|████████  | 914/1125 [19:52<04:18,  1.23s/it, loss=0.288, lr=2e-6, vram=5.7/11.9GB]#015Steps:  81%|████████▏ | 915/1125 [19:52<04:16,  1.22s/it, loss=0.288, lr=2e-6, vram=5.7/11.9GB]#015Steps:  81%|████████▏ | 916/1125 [19:53<04:15,  1.22s/it, loss=0.288, lr=2e-6, vram=5.7/11.9GB]#015Steps:  81%|████████▏ | 916/1125 [19:54<04:15,  1.22s/it, loss=0.278, lr=2e-6, vram=5.7/11.9GB]#015Steps:  82%|████████▏ | 917/1125 [19:54<04:13,  1.22s/it, loss=0.278, lr=2e-6, vram=5.7/11.9GB]#015Steps:  82%|████████▏ | 918/1125 [19:55<04:10,  1.21s/it, loss=0.278, lr=2e-6, vram=5.7/11.9GB]#015Steps:  82%|████████▏ | 918/1125 [19:56<04:10,  1.21s/it, loss=0.295, lr=2e-6, vram=5.7/11.9GB]#015Steps:  82%|████████▏ | 919/1125 [19:56<04:12,  1.23s/it, loss=0.295, lr=2e-6, vram=5.7/11.9GB]#015Steps:  82%|████████▏ | 920/1125 [19:58<04:10,  1.22s/it, loss=0.295, lr=2e-6, vram=5.7/11.9GB]#015Steps:  82%|████████▏ | 920/1125 [19:59<04:10,  1.22s/it, loss=0.281, lr=2e-6, vram=5.7/11.9GB]#015Steps:  82%|████████▏ | 921/1125 [19:59<04:08,  1.22s/it, loss=0.281, lr=2e-6, vram=5.7/11.9GB]#015Steps:  82%|████████▏ | 922/1125 [20:00<04:08,  1.22s/it, loss=0.281, lr=2e-6, vram=5.7/11.9GB]#015Steps:  82%|████████▏ | 922/1125 [20:01<04:08,  1.22s/it, loss=0.387, lr=2e-6, vram=5.7/11.9GB]#015Steps:  82%|████████▏ | 923/1125 [20:01<04:07,  1.23s/it, loss=0.387, lr=2e-6, vram=5.7/11.9GB]#015Steps:  82%|████████▏ | 924/1125 [20:03<04:05,  1.22s/it, loss=0.387, lr=2e-6, vram=5.7/11.9GB]#015Steps:  82%|████████▏ | 924/1125 [20:04<04:05,  1.22s/it, loss=0.271, lr=2e-6, vram=5.7/11.9GB]#015Steps:  82%|████████▏ | 925/1125 [20:04<04:04,  1.22s/it, loss=0.271, lr=2e-6, vram=5.7/11.9GB]#015Steps:  82%|████████▏ | 926/1125 [20:05<04:02,  1.22s/it, loss=0.271, lr=2e-6, vram=5.7/11.9GB]#015Steps:  82%|████████▏ | 926/1125 [20:06<04:02,  1.22s/it, loss=0.332, lr=2e-6, vram=5.7/11.9GB]#015Steps:  82%|████████▏ | 927/1125 [20:06<03:59,  1.21s/it, loss=0.332, lr=2e-6, vram=5.7/11.9GB]#015Steps:  82%|████████▏ | 928/1125 [20:07<04:00,  1.22s/it, loss=0.332, lr=2e-6, vram=5.7/11.9GB]#015Steps:  82%|████████▏ | 928/1125 [20:09<04:00,  1.22s/it, loss=0.303, lr=2e-6, vram=5.7/11.9GB]#015Steps:  83%|████████▎ | 929/1125 [20:09<04:00,  1.23s/it, loss=0.303, lr=2e-6, vram=5.7/11.9GB]#015Steps:  83%|████████▎ | 930/1125 [20:10<03:58,  1.22s/it, loss=0.303, lr=2e-6, vram=5.7/11.9GB]#015Steps:  83%|████████▎ | 930/1125 [20:11<03:58,  1.22s/it, loss=0.435, lr=2e-6, vram=5.7/11.9GB]#015Steps:  83%|████████▎ | 931/1125 [20:11<03:57,  1.22s/it, loss=0.435, lr=2e-6, vram=5.7/11.9GB]#015Steps:  83%|████████▎ | 932/1125 [20:12<03:55,  1.22s/it, loss=0.435, lr=2e-6, vram=5.7/11.9GB]#015Steps:  83%|████████▎ | 932/1125 [20:14<03:55,  1.22s/it, loss=0.347, lr=2e-6, vram=5.7/11.9GB]#015Steps:  83%|████████▎ | 933/1125 [20:14<03:55,  1.23s/it, loss=0.347, lr=2e-6, vram=5.7/11.9GB]#015Steps:  83%|████████▎ | 934/1125 [20:15<03:53,  1.22s/it, loss=0.347, lr=2e-6, vram=5.7/11.9GB]#015Steps:  83%|████████▎ | 934/1125 [20:16<03:53,  1.22s/it, loss=0.607, lr=2e-6, vram=5.7/11.9GB]#015Steps:  83%|████████▎ | 935/1125 [20:16<03:51,  1.22s/it, loss=0.607, lr=2e-6, vram=5.7/11.9GB]#015Steps:  83%|████████▎ | 936/1125 [20:17<03:48,  1.21s/it, loss=0.607, lr=2e-6, vram=5.7/11.9GB]#015Steps:  83%|████████▎ | 936/1125 [20:18<03:48,  1.21s/it, loss=0.407, lr=2e-6, vram=5.7/11.9GB]#015Steps:  83%|████████▎ | 937/1125 [20:18<03:51,  1.23s/it, loss=0.407, lr=2e-6, vram=5.7/11.9GB]#015Steps:  83%|████████▎ | 938/1125 [20:20<03:48,  1.22s/it, loss=0.407, lr=2e-6, vram=5.7/11.9GB]#015Steps:  83%|████████▎ | 938/1125 [20:21<03:48,  1.22s/it, loss=0.365, lr=2e-6, vram=5.7/11.9GB]#015Steps:  83%|████████▎ | 939/1125 [20:21<03:47,  1.22s/it, loss=0.365, lr=2e-6, vram=5.7/11.9GB]#015Steps:  84%|████████▎ | 940/1125 [20:22<03:46,  1.22s/it, loss=0.365, lr=2e-6, vram=5.7/11.9GB]#015Steps:  84%|████████▎ | 940/1125 [20:23<03:46,  1.22s/it, loss=0.403, lr=2e-6, vram=5.7/11.9GB]#015Steps:  84%|████████▎ | 941/1125 [20:23<03:45,  1.23s/it, loss=0.403, lr=2e-6, vram=5.7/11.9GB]#015Steps:  84%|████████▎ | 942/1125 [20:25<03:43,  1.22s/it, loss=0.403, lr=2e-6, vram=5.7/11.9GB]#015Steps:  84%|████████▎ | 942/1125 [20:26<03:43,  1.22s/it, loss=0.349, lr=2e-6, vram=5.7/11.9GB]#015Steps:  84%|████████▍ | 943/1125 [20:26<03:41,  1.22s/it, loss=0.349, lr=2e-6, vram=5.7/11.9GB]#015Steps:  84%|████████▍ | 944/1125 [20:27<03:39,  1.21s/it, loss=0.349, lr=2e-6, vram=5.7/11.9GB]#015Steps:  84%|████████▍ | 944/1125 [20:28<03:39,  1.21s/it, loss=0.359, lr=2e-6, vram=5.7/11.9GB]#015Steps:  84%|████████▍ | 945/1125 [20:28<03:37,  1.21s/it, loss=0.359, lr=2e-6, vram=5.7/11.9GB]#015Steps:  84%|████████▍ | 946/1125 [20:29<03:38,  1.22s/it, loss=0.359, lr=2e-6, vram=5.7/11.9GB]#015Steps:  84%|████████▍ | 946/1125 [20:31<03:38,  1.22s/it, loss=0.324, lr=2e-6, vram=5.7/11.9GB]#015Steps:  84%|████████▍ | 947/1125 [20:31<03:36,  1.22s/it, loss=0.324, lr=2e-6, vram=5.7/11.9GB]#015Steps:  84%|████████▍ | 948/1125 [20:32<03:36,  1.22s/it, loss=0.324, lr=2e-6, vram=5.7/11.9GB]#015Steps:  84%|████████▍ | 948/1125 [20:33<03:36,  1.22s/it, loss=0.345, lr=2e-6, vram=5.7/11.9GB]#015Steps:  84%|████████▍ | 949/1125 [20:33<03:36,  1.23s/it, loss=0.345, lr=2e-6, vram=5.7/11.9GB]#015Steps:  84%|████████▍ | 950/1125 [20:34<03:33,  1.22s/it, loss=0.345, lr=2e-6, vram=5.7/11.9GB]#015Steps:  84%|████████▍ | 950/1125 [20:36<03:33,  1.22s/it, loss=0.454, lr=2e-6, vram=5.7/11.9GB]#015Steps:  85%|████████▍ | 951/1125 [20:36<03:32,  1.22s/it, loss=0.454, lr=2e-6, vram=5.7/11.9GB]#015Steps:  85%|████████▍ | 952/1125 [20:37<03:31,  1.22s/it, loss=0.454, lr=2e-6, vram=5.7/11.9GB]#015Steps:  85%|████████▍ | 952/1125 [20:38<03:31,  1.22s/it, loss=0.373, lr=2e-6, vram=5.7/11.9GB]#015Steps:  85%|████████▍ | 953/1125 [20:38<03:29,  1.22s/it, loss=0.373, lr=2e-6, vram=5.7/11.9GB]#015Steps:  85%|████████▍ | 954/1125 [20:39<03:27,  1.21s/it, loss=0.373, lr=2e-6, vram=5.7/11.9GB]#015Steps:  85%|████████▍ | 954/1125 [20:40<03:27,  1.21s/it, loss=0.269, lr=2e-6, vram=5.7/11.9GB]#015Steps:  85%|████████▍ | 955/1125 [20:40<03:26,  1.22s/it, loss=0.269, lr=2e-6, vram=5.7/11.9GB]#015Steps:  85%|████████▍ | 956/1125 [20:42<03:25,  1.22s/it, loss=0.269, lr=2e-6, vram=5.7/11.9GB]#015Steps:  85%|████████▍ | 956/1125 [20:43<03:25,  1.22s/it, loss=0.273, lr=2e-6, vram=5.7/11.9GB]#015Steps:  85%|████████▌ | 957/1125 [20:43<03:25,  1.22s/it, loss=0.273, lr=2e-6, vram=5.7/11.9GB]#015Steps:  85%|████████▌ | 958/1125 [20:44<03:24,  1.23s/it, loss=0.273, lr=2e-6, vram=5.7/11.9GB]#015Steps:  85%|████████▌ | 958/1125 [20:45<03:24,  1.23s/it, loss=0.406, lr=2e-6, vram=5.7/11.9GB]#015Steps:  85%|████████▌ | 959/1125 [20:45<03:22,  1.22s/it, loss=0.406, lr=2e-6, vram=5.7/11.9GB]#015Steps:  85%|████████▌ | 960/1125 [20:46<03:21,  1.22s/it, loss=0.406, lr=2e-6, vram=5.7/11.9GB]#015Steps:  85%|████████▌ | 960/1125 [20:48<03:21,  1.22s/it, loss=0.326, lr=2e-6, vram=5.7/11.9GB]#015Steps:  85%|████████▌ | 961/1125 [20:48<03:20,  1.22s/it, loss=0.326, lr=2e-6, vram=5.7/11.9GB]#015Steps:  86%|████████▌ | 962/1125 [20:49<03:19,  1.22s/it, loss=0.326, lr=2e-6, vram=5.7/11.9GB]#015Steps:  86%|████████▌ | 962/1125 [20:50<03:19,  1.22s/it, loss=0.432, lr=2e-6, vram=5.7/11.9GB]#015Steps:  86%|████████▌ | 963/1125 [20:50<03:16,  1.21s/it, loss=0.432, lr=2e-6, vram=5.7/11.9GB]#015Steps:  86%|████████▌ | 964/1125 [20:51<03:17,  1.23s/it, loss=0.432, lr=2e-6, vram=5.7/11.9GB]#015Steps:  86%|████████▌ | 964/1125 [20:53<03:17,  1.23s/it, loss=0.638, lr=2e-6, vram=5.7/11.9GB]#015Steps:  86%|████████▌ | 965/1125 [20:53<03:15,  1.22s/it, loss=0.638, lr=2e-6, vram=5.7/11.9GB]#015Steps:  86%|████████▌ | 966/1125 [20:54<03:14,  1.22s/it, loss=0.638, lr=2e-6, vram=5.7/11.9GB]#015Steps:  86%|████████▌ | 966/1125 [20:55<03:14,  1.22s/it, loss=0.206, lr=2e-6, vram=5.7/11.9GB]#015Steps:  86%|████████▌ | 967/1125 [20:55<03:13,  1.22s/it, loss=0.206, lr=2e-6, vram=5.7/11.9GB]#015Steps:  86%|████████▌ | 968/1125 [20:56<03:11,  1.22s/it, loss=0.206, lr=2e-6, vram=5.7/11.9GB]#015Steps:  86%|████████▌ | 968/1125 [20:57<03:11,  1.22s/it, loss=0.32, lr=2e-6, vram=5.7/11.9GB] #015Steps:  86%|████████▌ | 969/1125 [20:57<03:09,  1.22s/it, loss=0.32, lr=2e-6, vram=5.7/11.9GB]#015Steps:  86%|████████▌ | 970/1125 [20:59<03:09,  1.22s/it, loss=0.32, lr=2e-6, vram=5.7/11.9GB]#015Steps:  86%|████████▌ | 970/1125 [21:00<03:09,  1.22s/it, loss=0.414, lr=2e-6, vram=5.7/11.9GB]#015Steps:  86%|████████▋ | 971/1125 [21:00<03:08,  1.22s/it, loss=0.414, lr=2e-6, vram=5.7/11.9GB]#015Steps:  86%|████████▋ | 972/1125 [21:01<03:05,  1.22s/it, loss=0.414, lr=2e-6, vram=5.7/11.9GB]#015Steps:  86%|████████▋ | 972/1125 [21:02<03:05,  1.22s/it, loss=0.306, lr=2e-6, vram=5.7/11.9GB]#015Steps:  86%|████████▋ | 973/1125 [21:02<03:06,  1.23s/it, loss=0.306, lr=2e-6, vram=5.7/11.9GB]#015Steps:  87%|████████▋ | 974/1125 [21:04<03:04,  1.22s/it, loss=0.306, lr=2e-6, vram=5.7/11.9GB]#015Steps:  87%|████████▋ | 974/1125 [21:05<03:04,  1.22s/it, loss=0.362, lr=2e-6, vram=5.7/11.9GB]#015Steps:  87%|████████▋ | 975/1125 [21:05<03:03,  1.22s/it, loss=0.362, lr=2e-6, vram=5.7/11.9GB]#015Steps:  87%|████████▋ | 976/1125 [21:06<03:01,  1.22s/it, loss=0.362, lr=2e-6, vram=5.7/11.9GB]#015Steps:  87%|████████▋ | 976/1125 [21:07<03:01,  1.22s/it, loss=0.407, lr=2e-6, vram=5.7/11.9GB]#015Steps:  87%|████████▋ | 977/1125 [21:07<03:00,  1.22s/it, loss=0.407, lr=2e-6, vram=5.7/11.9GB]#015Steps:  87%|████████▋ | 978/1125 [21:08<02:59,  1.22s/it, loss=0.407, lr=2e-6, vram=5.7/11.9GB]#015Steps:  87%|████████▋ | 978/1125 [21:10<02:59,  1.22s/it, loss=0.39, lr=2e-6, vram=5.7/11.9GB] #015Steps:  87%|████████▋ | 979/1125 [21:10<02:58,  1.22s/it, loss=0.39, lr=2e-6, vram=5.7/11.9GB]#015Steps:  87%|████████▋ | 980/1125 [21:11<02:56,  1.22s/it, loss=0.39, lr=2e-6, vram=5.7/11.9GB]#015Steps:  87%|████████▋ | 980/1125 [21:12<02:56,  1.22s/it, loss=0.28, lr=2e-6, vram=5.7/11.9GB]#015Steps:  87%|████████▋ | 981/1125 [21:12<02:54,  1.21s/it, loss=0.28, lr=2e-6, vram=5.7/11.9GB]#015Steps:  87%|████████▋ | 982/1125 [21:13<02:56,  1.23s/it, loss=0.28, lr=2e-6, vram=5.7/11.9GB]#015Steps:  87%|████████▋ | 982/1125 [21:15<02:56,  1.23s/it, loss=0.425, lr=2e-6, vram=5.7/11.9GB]#015Steps:  87%|████████▋ | 983/1125 [21:15<02:55,  1.23s/it, loss=0.425, lr=2e-6, vram=5.7/11.9GB]#015Steps:  87%|████████▋ | 984/1125 [21:16<02:53,  1.23s/it, loss=0.425, lr=2e-6, vram=5.7/11.9GB]#015Steps:  87%|████████▋ | 984/1125 [21:17<02:53,  1.23s/it, loss=0.369, lr=2e-6, vram=5.7/11.9GB]#015Steps:  88%|████████▊ | 985/1125 [21:17<02:51,  1.22s/it, loss=0.369, lr=2e-6, vram=5.7/11.9GB]#015Steps:  88%|████████▊ | 986/1125 [21:18<02:49,  1.22s/it, loss=0.369, lr=2e-6, vram=5.7/11.9GB]#015Steps:  88%|████████▊ | 986/1125 [21:19<02:49,  1.22s/it, loss=0.317, lr=2e-6, vram=5.7/11.9GB]#015Steps:  88%|████████▊ | 987/1125 [21:19<02:47,  1.22s/it, loss=0.317, lr=2e-6, vram=5.7/11.9GB]#015Steps:  88%|████████▊ | 988/1125 [21:21<02:47,  1.22s/it, loss=0.317, lr=2e-6, vram=5.7/11.9GB]#015Steps:  88%|████████▊ | 988/1125 [21:22<02:47,  1.22s/it, loss=0.345, lr=2e-6, vram=5.7/11.9GB]#015Steps:  88%|████████▊ | 989/1125 [21:22<02:45,  1.22s/it, loss=0.345, lr=2e-6, vram=5.7/11.9GB]#015Steps:  88%|████████▊ | 990/1125 [21:23<02:43,  1.21s/it, loss=0.345, lr=2e-6, vram=5.7/11.9GB]#015Steps:  88%|████████▊ | 990/1125 [21:24<02:43,  1.21s/it, loss=0.252, lr=2e-6, vram=5.7/11.9GB]#015Steps:  88%|████████▊ | 991/1125 [21:24<02:43,  1.22s/it, loss=0.252, lr=2e-6, vram=5.7/11.9GB]#015Steps:  88%|████████▊ | 992/1125 [21:26<02:42,  1.22s/it, loss=0.252, lr=2e-6, vram=5.7/11.9GB]#015Steps:  88%|████████▊ | 992/1125 [21:27<02:42,  1.22s/it, loss=0.43, lr=2e-6, vram=5.7/11.9GB] #015Steps:  88%|████████▊ | 993/1125 [21:27<02:41,  1.22s/it, loss=0.43, lr=2e-6, vram=5.7/11.9GB]#015Steps:  88%|████████▊ | 994/1125 [21:28<02:39,  1.22s/it, loss=0.43, lr=2e-6, vram=5.7/11.9GB]#015Steps:  88%|████████▊ | 994/1125 [21:29<02:39,  1.22s/it, loss=0.218, lr=2e-6, vram=5.7/11.9GB]#015Steps:  88%|████████▊ | 995/1125 [21:29<02:39,  1.22s/it, loss=0.218, lr=2e-6, vram=5.7/11.9GB]#015Steps:  89%|████████▊ | 996/1125 [21:30<02:37,  1.22s/it, loss=0.218, lr=2e-6, vram=5.7/11.9GB]#015Steps:  89%|████████▊ | 996/1125 [21:32<02:37,  1.22s/it, loss=0.291, lr=2e-6, vram=5.7/11.9GB]#015Steps:  89%|████████▊ | 997/1125 [21:32<02:35,  1.22s/it, los\u001b[0m\n",
      "\u001b[34m Allocated 7.0/10.8GB \n",
      " Reserved: 7.9/11.9GB \u001b[0m\n",
      "\u001b[34mCompiling checkpoint for aws-db-new-model...\u001b[0m\n",
      "\u001b[34mSaving checkpoint to /opt/ml/input/data/models/aws-db-new-model_1000.ckpt...\u001b[0m\n",
      "\u001b[34ms=0.291, lr=2e-6, vram=5.7/11.9GB]#015Steps:  89%|████████▊ | 998/1125 [21:33<02:34,  1.22s/it, loss=0.291, lr=2e-6, vram=5.7/11.9GB]#015Steps:  89%|████████▊ | 998/1125 [21:34<02:34,  1.22s/it, loss=0.6, lr=2e-6, vram=5.7/11.9GB]  #015Steps:  89%|████████▉ | 999/1125 [21:34<02:32,  1.21s/it, loss=0.6, lr=2e-6, vram=5.7/11.9GB]#015Steps:  89%|████████▉ | 1000/1125 [21:35<02:32,  1.22s/it, loss=0.6, lr=2e-6, vram=5.7/11.9GB]#015Steps:  89%|████████▉ | 1000/1125 [21:37<02:32,  1.22s/it, loss=0.479, lr=2e-6, vram=5.7/11.9GB]\u001b[0m\n",
      "\u001b[34m#015Generating samples:   0%|          | 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Generating samples: 100%|██████████| 1/1 [00:14<00:00, 14.42s/it]#033[A#015Generating samples: 100%|██████████| 1/1 [00:14<00:00, 14.42s/it]\u001b[0m\n",
      "\u001b[34m#015Steps:  89%|████████▉ | 1001/1125 [22:58<53:17, 25.78s/it, loss=0.479, lr=2e-6, vram=5.7/11.9GB]#015Steps:  89%|████████▉ | 1002/1125 [23:00<37:44, 18.41s/it, loss=0.479, lr=2e-6, vram=5.7/11.9GB]#015Steps:  89%|████████▉ | 1002/1125 [23:01<37:44, 18.41s/it, loss=0.294, lr=2e-6, vram=5.7/11.9GB]#015Steps:  89%|████████▉ | 1003/1125 [23:01<26:55, 13.24s/it, loss=0.294, lr=2e-6, vram=5.7/11.9GB]#015Steps:  89%|████████▉ | 1004/1125 [23:02<19:25,  9.63s/it, loss=0.294, lr=2e-6, vram=5.7/11.9GB]#015Steps:  89%|████████▉ | 1004/1125 [23:03<19:25,  9.63s/it, loss=0.285, lr=2e-6, vram=5.7/11.9GB]#015Steps:  89%|████████▉ | 1005/1125 [23:03<14:12,  7.10s/it, loss=0.285, lr=2e-6, vram=5.7/11.9GB]#015Steps:  89%|████████▉ | 1006/1125 [23:04<10:33,  5.33s/it, loss=0.285, lr=2e-6, vram=5.7/11.9GB]#015Steps:  89%|████████▉ | 1006/1125 [23:06<10:33,  5.33s/it, loss=0.425, lr=2e-6, vram=5.7/11.9GB]#015Steps:  90%|████████▉ | 1007/1125 [23:06<08:01,  4.08s/it, loss=0.425, lr=2e-6, vram=5.7/11.9GB]#015Steps:  90%|████████▉ | 1008/1125 [23:07<06:15,  3.21s/it, loss=0.425, lr=2e-6, vram=5.7/11.9GB]#015Steps:  90%|████████▉ | 1008/1125 [23:08<06:15,  3.21s/it, loss=0.302, lr=2e-6, vram=5.7/11.9GB]#015Steps:  90%|████████▉ | 1009/1125 [23:08<05:01,  2.60s/it, loss=0.302, lr=2e-6, vram=5.7/11.9GB]#015Steps:  90%|████████▉ | 1010/1125 [23:09<04:10,  2.18s/it, loss=0.302, lr=2e-6, vram=5.7/11.9GB]#015Steps:  90%|████████▉ | 1010/1125 [23:10<04:10,  2.18s/it, loss=0.508, lr=2e-6, vram=5.7/11.9GB]#015Steps:  90%|████████▉ | 1011/1125 [23:10<03:34,  1.88s/it, loss=0.508, lr=2e-6, vram=5.7/11.9GB]#015Steps:  90%|████████▉ | 1012/1125 [23:12<03:09,  1.68s/it, loss=0.508, lr=2e-6, vram=5.7/11.9GB]#015Steps:  90%|████████▉ | 1012/1125 [23:13<03:09,  1.68s/it, loss=0.531, lr=2e-6, vram=5.7/11.9GB]#015Steps:  90%|█████████ | 1013/1125 [23:13<02:51,  1.53s/it, loss=0.531, lr=2e-6, vram=5.7/11.9GB]#015Steps:  90%|█████████ | 1014/1125 [23:14<02:38,  1.43s/it, loss=0.531, lr=2e-6, vram=5.7/11.9GB]#015Steps:  90%|█████████ | 1014/1125 [23:15<02:38,  1.43s/it, loss=0.28, lr=2e-6, vram=5.7/11.9GB] #015Steps:  90%|█████████ | 1015/1125 [23:15<02:29,  1.36s/it, loss=0.28, lr=2e-6, vram=5.7/11.9GB]#015Steps:  90%|█████████ | 1016/1125 [23:16<02:22,  1.31s/it, loss=0.28, lr=2e-6, vram=5.7/11.9GB]#015Steps:  90%|█████████ | 1016/1125 [23:17<02:22,  1.31s/it, loss=0.263, lr=2e-6, vram=5.7/11.9GB]#015Steps:  90%|█████████ | 1017/1125 [23:17<02:16,  1.27s/it, loss=0.263, lr=2e-6, vram=5.7/11.9GB]#015Steps:  90%|█████████ | 1018/1125 [23:19<02:13,  1.25s/it, loss=0.263, lr=2e-6, vram=5.7/11.9GB]#015Steps:  90%|█████████ | 1018/1125 [23:20<02:13,  1.25s/it, loss=0.374, lr=2e-6, vram=5.7/11.9GB]#015Steps:  91%|█████████ | 1019/1125 [23:20<02:10,  1.23s/it, loss=0.374, lr=2e-6, vram=5.7/11.9GB]#015Steps:  91%|█████████ | 1020/1125 [23:21<02:08,  1.22s/it, loss=0.374, lr=2e-6, vram=5.7/11.9GB]#015Steps:  91%|█████████ | 1020/1125 [23:22<02:08,  1.22s/it, loss=0.373, lr=2e-6, vram=5.7/11.9GB]#015Steps:  91%|█████████ | 1021/1125 [23:22<02:06,  1.21s/it, loss=0.373, lr=2e-6, vram=5.7/11.9GB]#015Steps:  91%|█████████ | 1022/1125 [23:23<02:04,  1.21s/it, loss=0.373, lr=2e-6, vram=5.7/11.9GB]#015Steps:  91%|█████████ | 1022/1125 [23:25<02:04,  1.21s/it, loss=0.492, lr=2e-6, vram=5.7/11.9GB]#015Steps:  91%|█████████ | 1023/1125 [23:25<02:03,  1.21s/it, loss=0.492, lr=2e-6, vram=5.7/11.9GB]#015Steps:  91%|█████████ | 1024/1125 [23:26<02:01,  1.20s/it, loss=0.492, lr=2e-6, vram=5.7/11.9GB]#015Steps:  91%|█████████ | 1024/1125 [23:27<02:01,  1.20s/it, loss=0.269, lr=2e-6, vram=5.7/11.9GB]#015Steps:  91%|█████████ | 1025/1125 [23:27<01:59,  1.20s/it, loss=0.269, lr=2e-6, vram=5.7/11.9GB]#015Steps:  91%|█████████ | 1026/1125 [23:28<01:57,  1.19s/it, loss=0.269, lr=2e-6, vram=5.7/11.9GB]#015Steps:  91%|█████████ | 1026/1125 [23:29<01:57,  1.19s/it, loss=0.223, lr=2e-6, vram=5.7/11.9GB]#015Steps:  91%|█████████▏| 1027/1125 [23:29<01:57,  1.20s/it, loss=0.223, lr=2e-6, vram=5.7/11.9GB]#015Steps:  91%|█████████▏| 1028/1125 [23:31<01:56,  1.20s/it, loss=0.223, lr=2e-6, vram=5.7/11.9GB]#015Steps:  91%|█████████▏| 1028/1125 [23:32<01:56,  1.20s/it, loss=0.341, lr=2e-6, vram=5.7/11.9GB]#015Steps:  91%|█████████▏| 1029/1125 [23:32<01:54,  1.19s/it, loss=0.341, lr=2e-6, vram=5.7/11.9GB]#015Steps:  92%|█████████▏| 1030/1125 [23:33<01:53,  1.19s/it, loss=0.341, lr=2e-6, vram=5.7/11.9GB]#015Steps:  92%|█████████▏| 1030/1125 [23:34<01:53,  1.19s/it, loss=0.329, lr=2e-6, vram=5.7/11.9GB]#015Steps:  92%|█████████▏| 1031/1125 [23:34<01:52,  1.20s/it, loss=0.329, lr=2e-6, vram=5.7/11.9GB]#015Steps:  92%|█████████▏| 1032/1125 [23:35<01:51,  1.20s/it, loss=0.329, lr=2e-6, vram=5.7/11.9GB]#015Steps:  92%|█████████▏| 1032/1125 [23:37<01:51,  1.20s/it, loss=0.371, lr=2e-6, vram=5.7/11.9GB]#015Steps:  92%|█████████▏| 1033/1125 [23:37<01:50,  1.20s/it, loss=0.371, lr=2e-6, vram=5.7/11.9GB]#015Steps:  92%|█████████▏| 1034/1125 [23:38<01:49,  1.20s/it, loss=0.371, lr=2e-6, vram=5.7/11.9GB]#015Steps:  92%|█████████▏| 1034/1125 [23:39<01:49,  1.20s/it, loss=0.438, lr=2e-6, vram=5.7/11.9GB]#015Steps:  92%|█████████▏| 1035/1125 [23:39<01:47,  1.19s/it, loss=0.438, lr=2e-6, vram=5.7/11.9GB]#015Steps:  92%|█████████▏| 1036/1125 [23:40<01:46,  1.20s/it, loss=0.438, lr=2e-6, vram=5.7/11.9GB]#015Steps:  92%|█████████▏| 1036/1125 [23:41<01:46,  1.20s/it, loss=0.336, lr=2e-6, vram=5.7/11.9GB]#015Steps:  92%|█████████▏| 1037/1125 [23:41<01:45,  1.20s/it, loss=0.336, lr=2e-6, vram=5.7/11.9GB]#015Steps:  92%|█████████▏| 1038/1125 [23:43<01:44,  1.20s/it, loss=0.336, lr=2e-6, vram=5.7/11.9GB]#015Steps:  92%|█████████▏| 1038/1125 [23:44<01:44,  1.20s/it, loss=0.28, lr=2e-6, vram=5.7/11.9GB] #015Steps:  92%|█████████▏| 1039/1125 [23:44<01:43,  1.20s/it, loss=0.28, lr=2e-6, vram=5.7/11.9GB]#015Steps:  92%|█████████▏| 1040/1125 [23:45<01:42,  1.20s/it, loss=0.28, lr=2e-6, vram=5.7/11.9GB]#015Steps:  92%|█████████▏| 1040/1125 [23:46<01:42,  1.20s/it, loss=0.434, lr=2e-6, vram=5.7/11.9GB]#015Steps:  93%|█████████▎| 1041/1125 [23:46<01:40,  1.20s/it, loss=0.434, lr=2e-6, vram=5.7/11.9GB]#015Steps:  93%|█████████▎| 1042/1125 [23:47<01:39,  1.19s/it, loss=0.434, lr=2e-6, vram=5.7/11.9GB]#015Steps:  93%|█████████▎| 1042/1125 [23:49<01:39,  1.19s/it, loss=0.289, lr=2e-6, vram=5.7/11.9GB]#015Steps:  93%|█████████▎| 1043/1125 [23:49<01:38,  1.20s/it, loss=0.289, lr=2e-6, vram=5.7/11.9GB]#015Steps:  93%|█████████▎| 1044/1125 [23:50<01:36,  1.19s/it, loss=0.289, lr=2e-6, vram=5.7/11.9GB]#015Steps:  93%|█████████▎| 1044/1125 [23:51<01:36,  1.19s/it, loss=0.289, lr=2e-6, vram=5.7/11.9GB]#015Steps:  93%|█████████▎| 1045/1125 [23:51<01:36,  1.20s/it, loss=0.289, lr=2e-6, vram=5.7/11.9GB]#015Steps:  93%|█████████▎| 1046/1125 [23:52<01:34,  1.20s/it, loss=0.289, lr=2e-6, vram=5.7/11.9GB]#015Steps:  93%|█████████▎| 1046/1125 [23:53<01:34,  1.20s/it, loss=0.501, lr=2e-6, vram=5.7/11.9GB]#015Steps:  93%|█████████▎| 1047/1125 [23:53<01:33,  1.20s/it, loss=0.501, lr=2e-6, vram=5.7/11.9GB]#015Steps:  93%|█████████▎| 1048/1125 [23:55<01:32,  1.20s/it, loss=0.501, lr=2e-6, vram=5.7/11.9GB]#015Steps:  93%|█████████▎| 1048/1125 [23:56<01:32,  1.20s/it, loss=0.225, lr=2e-6, vram=5.7/11.9GB]#015Steps:  93%|█████████▎| 1049/1125 [23:56<01:31,  1.20s/it, loss=0.225, lr=2e-6, vram=5.7/11.9GB]#015Steps:  93%|█████████▎| 1050/1125 [23:57<01:29,  1.20s/it, loss=0.225, lr=2e-6, vram=5.7/11.9GB]#015Steps:  93%|█████████▎| 1050/1125 [23:58<01:29,  1.20s/it, loss=0.366, lr=2e-6, vram=5.7/11.9GB]#015Steps:  93%|█████████▎| 1051/1125 [23:58<01:28,  1.20s/it, loss=0.366, lr=2e-6, vram=5.7/11.9GB]#015Steps:  94%|█████████▎| 1052/1125 [23:59<01:27,  1.20s/it, loss=0.366, lr=2e-6, vram=5.7/11.9GB]#015Steps:  94%|█████████▎| 1052/1125 [24:01<01:27,  1.20s/it, loss=0.292, lr=2e-6, vram=5.7/11.9GB]#015Steps:  94%|█████████▎| 1053/1125 [24:01<01:26,  1.20s/it, loss=0.292, lr=2e-6, vram=5.7/11.9GB]#015Steps:  94%|█████████▎| 1054/1125 [24:02<01:25,  1.21s/it, loss=0.292, lr=2e-6, vram=5.7/11.9GB]#015Steps:  94%|█████████▎| 1054/1125 [24:03<01:25,  1.21s/it, loss=0.308, lr=2e-6, vram=5.7/11.9GB]#015Steps:  94%|█████████▍| 1055/1125 [24:03<01:24,  1.20s/it, loss=0.308, lr=2e-6, vram=5.7/11.9GB]#015Steps:  94%|█████████▍| 1056/1125 [24:04<01:23,  1.20s/it, loss=0.308, lr=2e-6, vram=5.7/11.9GB]#015Steps:  94%|█████████▍| 1056/1125 [24:05<01:23,  1.20s/it, loss=0.22, lr=2e-6, vram=5.7/11.9GB] #015Steps:  94%|█████████▍| 1057/1125 [24:05<01:21,  1.21s/it, loss=0.22, lr=2e-6, vram=5.7/11.9GB]#015Steps:  94%|█████████▍| 1058/1125 [24:07<01:20,  1.20s/it, loss=0.22, lr=2e-6, vram=5.7/11.9GB]#015Steps:  94%|█████████▍| 1058/1125 [24:08<01:20,  1.20s/it, loss=0.342, lr=2e-6, vram=5.7/11.9GB]#015Steps:  94%|█████████▍| 1059/1125 [24:08<01:19,  1.20s/it, loss=0.342, lr=2e-6, vram=5.7/11.9GB]#015Steps:  94%|█████████▍| 1060/1125 [24:09<01:18,  1.20s/it, loss=0.342, lr=2e-6, vram=5.7/11.9GB]#015Steps:  94%|█████████▍| 1060/1125 [24:10<01:18,  1.20s/it, loss=0.431, lr=2e-6, vram=5.7/11.9GB]#015Steps:  94%|█████████▍| 1061/1125 [24:10<01:17,  1.20s/it, loss=0.431, lr=2e-6, vram=5.7/11.9GB]#015Steps:  94%|█████████▍| 1062/1125 [24:11<01:15,  1.20s/it, loss=0.431, lr=2e-6, vram=5.7/11.9GB]#015Steps:  94%|█████████▍| 1062/1125 [24:13<01:15,  1.20s/it, loss=0.282, lr=2e-6, vram=5.7/11.9GB]#015Steps:  94%|█████████▍| 1063/1125 [24:13<01:14,  1.21s/it, loss=0.282, lr=2e-6, vram=5.7/11.9GB]#015Steps:  95%|█████████▍| 1064/1125 [24:14<01:13,  1.21s/it, loss=0.282, lr=2e-6, vram=5.7/11.9GB]#015Steps:  95%|█████████▍| 1064/1125 [24:15<01:13,  1.21s/it, loss=0.351, lr=2e-6, vram=5.7/11.9GB]#015Steps:  95%|█████████▍| 1065/1125 [24:15<01:12,  1.21s/it, loss=0.351, lr=2e-6, vram=5.7/11.9GB]#015Steps:  95%|█████████▍| 1066/1125 [24:16<01:11,  1.21s/it, loss=0.351, lr=2e-6, vram=5.7/11.9GB]#015Steps:  95%|█████████▍| 1066/1125 [24:17<01:11,  1.21s/it, loss=0.331, lr=2e-6, vram=5.7/11.9GB]#015Steps:  95%|█████████▍| 1067/1125 [24:17<01:09,  1.21s/it, loss=0.331, lr=2e-6, vram=5.7/11.9GB]#015Steps:  95%|█████████▍| 1068/1125 [24:19<01:08,  1.21s/it, loss=0.331, lr=2e-6, vram=5.7/11.9GB]#015Steps:  95%|█████████▍| 1068/1125 [24:20<01:08,  1.21s/it, loss=0.377, lr=2e-6, vram=5.7/11.9GB]#015Steps:  95%|█████████▌| 1069/1125 [24:20<01:07,  1.20s/it, loss=0.377, lr=2e-6, vram=5.7/11.9GB]#015Steps:  95%|█████████▌| 1070/1125 [24:21<01:05,  1.20s/it, loss=0.377, lr=2e-6, vram=5.7/11.9GB]#015Steps:  95%|█████████▌| 1070/1125 [24:22<01:05,  1.20s/it, loss=0.28, lr=2e-6, vram=5.7/11.9GB] #015Steps:  95%|█████████▌| 1071/1125 [24:22<01:04,  1.19s/it, loss=0.28, lr=2e-6, vram=5.7/11.9GB]#015Steps:  95%|█████████▌| 1072/1125 [24:23<01:03,  1.20s/it, loss=0.28, lr=2e-6, vram=5.7/11.9GB]#015Steps:  95%|█████████▌| 1072/1125 [24:25<01:03,  1.20s/it, loss=0.464, lr=2e-6, vram=5.7/11.9GB]#015Steps:  95%|█████████▌| 1073/1125 [24:25<01:02,  1.20s/it, loss=0.464, lr=2e-6, vram=5.7/11.9GB]#015Steps:  95%|█████████▌| 1074/1125 [24:26<01:01,  1.20s/it, loss=0.464, lr=2e-6, vram=5.7/11.9GB]#015Steps:  95%|█████████▌| 1074/1125 [24:27<01:01,  1.20s/it, loss=0.227, lr=2e-6, vram=5.7/11.9GB]#015Steps:  96%|█████████▌| 1075/1125 [24:27<00:59,  1.20s/it, loss=0.227, lr=2e-6, vram=5.7/11.9GB]#015Steps:  96%|█████████▌| 1076/1125 [24:28<00:58,  1.20s/it, loss=0.227, lr=2e-6, vram=5.7/11.9GB]#015Steps:  96%|█████████▌| 1076/1125 [24:29<00:58,  1.20s/it, loss=0.271, lr=2e-6, vram=5.7/11.9GB]#015Steps:  96%|█████████▌| 1077/1125 [24:29<00:57,  1.21s/it, loss=0.271, lr=2e-6, vram=5.7/11.9GB]#015Steps:  96%|█████████▌| 1078/1125 [24:31<00:56,  1.21s/it, loss=0.271, lr=2e-6, vram=5.7/11.9GB]#015Steps:  96%|█████████▌| 1078/1125 [24:32<00:56,  1.21s/it, loss=0.341, lr=2e-6, vram=5.7/11.9GB]#015Steps:  96%|█████████▌| 1079/1125 [24:32<00:55,  1.21s/it, loss=0.341, lr=2e-6, vram=5.7/11.9GB]#015Steps:  96%|█████████▌| 1080/1125 [24:33<00:54,  1.20s/it, loss=0.341, lr=2e-6, vram=5.7/11.9GB]#015Steps:  96%|█████████▌| 1080/1125 [24:34<00:54,  1.20s/it, loss=0.281, lr=2e-6, vram=5.7/11.9GB]#015Steps:  96%|█████████▌| 1081/1125 [24:34<00:53,  1.22s/it, loss=0.281, lr=2e-6, vram=5.7/11.9GB]#015Steps:  96%|█████████▌| 1082/1125 [24:36<00:52,  1.22s/it, loss=0.281, lr=2e-6, vram=5.7/11.9GB]#015Steps:  96%|█████████▌| 1082/1125 [24:37<00:52,  1.22s/it, loss=0.391, lr=2e-6, vram=5.7/11.9GB]#015Steps:  96%|█████████▋| 1083/1125 [24:37<00:50,  1.21s/it, loss=0.391, lr=2e-6, vram=5.7/11.9GB]#015Steps:  96%|█████████▋| 1084/1125 [24:38<00:49,  1.22s/it, loss=0.391, lr=2e-6, vram=5.7/11.9GB]#015Steps:  96%|█████████▋| 1084/1125 [24:39<00:49,  1.22s/it, loss=0.322, lr=2e-6, vram=5.7/11.9GB]#015Steps:  96%|█████████▋| 1085/1125 [24:39<00:48,  1.21s/it, loss=0.322, lr=2e-6, vram=5.7/11.9GB]#015Steps:  97%|█████████▋| 1086/1125 [24:40<00:47,  1.21s/it, loss=0.322, lr=2e-6, vram=5.7/11.9GB]#015Steps:  97%|█████████▋| 1086/1125 [24:42<00:47,  1.21s/it, loss=0.402, lr=2e-6, vram=5.7/11.9GB]#015Steps:  97%|█████████▋| 1087/1125 [24:42<00:45,  1.20s/it, loss=0.402, lr=2e-6, vram=5.7/11.9GB]#015Steps:  97%|█████████▋| 1088/1125 [24:43<00:44,  1.21s/it, loss=0.402, lr=2e-6, vram=5.7/11.9GB]#015Steps:  97%|█████████▋| 1088/1125 [24:44<00:44,  1.21s/it, loss=0.228, lr=2e-6, vram=5.7/11.9GB]#015Steps:  97%|█████████▋| 1089/1125 [24:44<00:43,  1.20s/it, loss=0.228, lr=2e-6, vram=5.7/11.9GB]#015Steps:  97%|█████████▋| 1090/1125 [24:45<00:42,  1.21s/it, loss=0.228, lr=2e-6, vram=5.7/11.9GB]#015Steps:  97%|█████████▋| 1090/1125 [24:46<00:42,  1.21s/it, loss=0.271, lr=2e-6, vram=5.7/11.9GB]#015Steps:  97%|█████████▋| 1091/1125 [24:46<00:41,  1.21s/it, loss=0.271, lr=2e-6, vram=5.7/11.9GB]#015Steps:  97%|█████████▋| 1092/1125 [24:48<00:39,  1.21s/it, loss=0.271, lr=2e-6, vram=5.7/11.9GB]#015Steps:  97%|█████████▋| 1092/1125 [24:49<00:39,  1.21s/it, loss=0.326, lr=2e-6, vram=5.7/11.9GB]#015Steps:  97%|█████████▋| 1093/1125 [24:49<00:38,  1.21s/it, loss=0.326, lr=2e-6, vram=5.7/11.9GB]#015Steps:  97%|█████████▋| 1094/1125 [24:50<00:37,  1.21s/it, loss=0.326, lr=2e-6, vram=5.7/11.9GB]#015Steps:  97%|█████████▋| 1094/1125 [24:51<00:37,  1.21s/it, loss=0.318\u001b[0m\n",
      "\u001b[34m Allocated 7.0/10.8GB \n",
      " Reserved: 8.1/11.9GB \u001b[0m\n",
      "\u001b[34mCompiling checkpoint for aws-db-new-model...\u001b[0m\n",
      "\u001b[34mSaving checkpoint to /opt/ml/input/data/models/aws-db-new-model_1125.ckpt...\n",
      " CLEANUP:  \n",
      " Allocated: 5.7GB \n",
      " Reserved: 8.1GB \n",
      " Cleanup completed. \n",
      " Allocated: 5.7GB \n",
      " Reserved: 7.1GB \n",
      " Cleanup Complete. \n",
      " Allocated: 5.7GB \n",
      " Reserved: 7.1GB \n",
      " Training completed, reloading SD Model. \n",
      " Allocated: 0.0GB \n",
      " Reserved: 3.4GB \u001b[0m\n",
      "\u001b[34mMemory output: {}\n",
      " Restored system models. \n",
      " Allocated: 2.5GB \n",
      " Reserved: 3.5GB \u001b[0m\n",
      "\u001b[34mReturning result: Training finished. Total lifetime steps: 1125 \u001b[0m\n",
      "\u001b[34mUploading SD Models...\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/models/aws-db-new-model_500.yaml stable-diffusion/models/aws-db-new-model_500.yaml\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/models/aws-db-new-model_1000.yaml stable-diffusion/models/aws-db-new-model_1000.yaml\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/models/aws-db-new-model_1125.yaml stable-diffusion/models/aws-db-new-model_1125.yaml\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/models/aws-db-new-model_1125.ckpt stable-diffusion/models/aws-db-new-model_1125.ckpt\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/models/aws-db-new-model_1000.ckpt stable-diffusion/models/aws-db-new-model_1000.ckpt\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/models/aws-db-new-model_500.ckpt stable-diffusion/models/aws-db-new-model_500.ckpt\u001b[0m\n",
      "\u001b[34mUploading DB Models...\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/dreambooth/aws-db-new-model/db_config.json stable-diffusion/dreambooth/aws-db-new-model/db_config.json\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/dreambooth/aws-db-new-model/samples/sample_500-00.png stable-diffusion/dreambooth/aws-db-new-model/samples/sample_500-00.png\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/dreambooth/aws-db-new-model/samples/sample_1000-00.png stable-diffusion/dreambooth/aws-db-new-model/samples/sample_1000-00.png\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/dreambooth/aws-db-new-model/logging/dreambooth/events.out.tfevents.1674825350.ip-10-0-179-75.ap-southeast-1.compute.internal.34.0 stable-diffusion/dreambooth/aws-db-new-model/logging/dreambooth/events.out.tfevents.1674825350.ip-10-0-179-75.ap-southeast-1.compute.internal.34.0\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/dreambooth/aws-db-new-model/working/model_index.json stable-diffusion/dreambooth/aws-db-new-model/working/model_index.json\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/dreambooth/aws-db-new-model/working/tokenizer/vocab.json stable-diffusion/dreambooth/aws-db-new-model/working/tokenizer/vocab.json\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/dreambooth/aws-db-new-model/working/tokenizer/tokenizer_config.json stable-diffusion/dreambooth/aws-db-new-model/working/tokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/dreambooth/aws-db-new-model/working/tokenizer/merges.txt stable-diffusion/dreambooth/aws-db-new-model/working/tokenizer/merges.txt\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/dreambooth/aws-db-new-model/working/tokenizer/special_tokens_map.json stable-diffusion/dreambooth/aws-db-new-model/working/tokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/dreambooth/aws-db-new-model/working/scheduler/scheduler_config.json stable-diffusion/dreambooth/aws-db-new-model/working/scheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/dreambooth/aws-db-new-model/working/vae/diffusion_pytorch_model.bin stable-diffusion/dreambooth/aws-db-new-model/working/vae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/dreambooth/aws-db-new-model/working/vae/config.json stable-diffusion/dreambooth/aws-db-new-model/working/vae/config.json\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/dreambooth/aws-db-new-model/working/text_encoder/pytorch_model.bin stable-diffusion/dreambooth/aws-db-new-model/working/text_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/dreambooth/aws-db-new-model/working/text_encoder/config.json stable-diffusion/dreambooth/aws-db-new-model/working/text_encoder/config.json\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/dreambooth/aws-db-new-model/working/unet/diffusion_pytorch_model.bin stable-diffusion/dreambooth/aws-db-new-model/working/unet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/dreambooth/aws-db-new-model/working/unet/config.json stable-diffusion/dreambooth/aws-db-new-model/working/unet/config.json\u001b[0m\n",
      "\u001b[34m2023-01-27 13:44:18,908 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-01-27 13:44:35 Uploading - Uploading generated training model\n",
      "2023-01-27 13:44:35 Completed - Training job completed\n",
      "Training seconds: 2331\n",
      "Billable seconds: 2331\n"
     ]
    }
   ],
   "source": [
    "#!aws s3 cp ./768-v-ema.ckpt   $models_s3uri\n",
    "#!aws s3 cp ./768-v-ema.yaml   $models_s3uri\n",
    "image_uri = '687912291502.dkr.ecr.ap-southeast-1.amazonaws.com/dreambooth-finetuning-v3-with-webui:latest'\n",
    "#image_uri = '687912291502.dkr.ecr.ap-southeast-1.amazonaws.com/dreambooth-finetuning-v3:latest'\n",
    "#image_uri = '687912291502.dkr.ecr.ap-southeast-1.amazonaws.com/dreambooth-finetuning-v3-withw-webui:latest'\n",
    "instance_type = 'ml.g4dn.2xlarge'\n",
    "#image_uri = '687912291502.dkr.ecr.ap-southeast-1.amazonaws.com/dreambooth-finetuning-v3:latest'\n",
    "from sagemaker.estimator import Estimator\n",
    "inputs = {\n",
    "    'images': images_s3uri,\n",
    "    'models': models_s3uri,\n",
    "    'config': dreambooth_config_s3uri\n",
    "}\n",
    "# Please exectute tools/prepare.py with the path to your model files directory.\n",
    "# Make sure the 768-v-ema.ckpt and 768-v-ema.yaml have been uploaded to sd_models_s3uri\n",
    "estimator = Estimator(\n",
    "    role = role,\n",
    "    instance_count=1,\n",
    "    instance_type = instance_type,\n",
    "    image_uri = image_uri,\n",
    "    hyperparameters = hyperparameters\n",
    ")\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2669338-ea5b-45e9-ab78-a90b8f9b37f9",
   "metadata": {},
   "source": [
    "## 不与webui绑定的training BYOC#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "681d420b-8ed7-46c6-9e1b-b561c8d0acc4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Cloning into 'sd_dreambooth_extension'...\n",
      "remote: Enumerating objects: 1957, done.\u001b[K\n",
      "remote: Counting objects: 100% (195/195), done.\u001b[K\n",
      "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
      "remote: Total 1957 (delta 125), reused 172 (delta 111), pack-reused 1762\u001b[K\n",
      "Receiving objects: 100% (1957/1957), 10.25 MiB | 11.78 MiB/s, done.\n",
      "Resolving deltas: 100% (1239/1239), done.\n",
      "The push refers to repository [687912291502.dkr.ecr.us-west-2.amazonaws.com/dreambooth-finetuning-v3]\n",
      "\n",
      "\u001b[1Bbcdfac54: Preparing \n",
      "\u001b[1B06d6940b: Preparing \n",
      "\u001b[1B543eb7dd: Preparing \n",
      "\u001b[1B3de32538: Preparing \n",
      "\u001b[1Bd5f5d706: Preparing \n",
      "\u001b[1B9524610e: Preparing \n",
      "\u001b[1B7129bac2: Preparing \n",
      "\u001b[1B6f1a4e2e: Preparing \n",
      "\u001b[1B2ac5fcbf: Preparing \n",
      "\u001b[1B928ff7fc: Preparing \n",
      "\u001b[1B62f5b997: Preparing \n",
      "\u001b[1B2f7b90a9: Preparing \n",
      "\u001b[1B07ec79a1: Preparing \n",
      "\u001b[1Be4d8282b: Preparing \n",
      "\u001b[1Bbfa15408: Preparing \n",
      "\u001b[1B0648b8c6: Preparing \n",
      "\u001b[1Ba50e7b38: Preparing \n",
      "\u001b[7BEOFb90a9: Waiting  in 1 second   [18A\u001b[2K\u001b[17A\u001b[2K\u001b[14A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[16A\u001b[2K\u001b[18A\u001b[2K\u001b[16A\u001b[2K\u001b[14A\u001b[2K\u001b[17A\u001b[2K\u001b[15A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[17A\u001b[2K\u001b[16A\u001b[2K\u001b[17A\u001b[2K\u001b[18A\u001b[2K\u001b[17A\u001b[2K\u001b[14A\u001b[2K\u001b[16A\u001b[2K\u001b[15A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[14A\u001b[2K\u001b[17A\u001b[2K\u001b[15A\u001b[2K\u001b[17A\u001b[2K\u001b[15A\u001b[2K\u001b[17A\u001b[2K\u001b[15A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[16A\u001b[2K\u001b[17A\u001b[2K\u001b[15A\u001b[2K\u001b[17A\u001b[2K\u001b[15A\u001b[2K\u001b[17A\u001b[2K\u001b[15A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[17A\u001b[2K\u001b[16A\u001b[2K\u001b[15A\u001b[2K\u001b[16A\u001b[2K\u001b[15A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[14A\u001b[2K\u001b[16A\u001b[2K\u001b[18A\u001b[2K\u001b[16A\u001b[2K\u001b[15A\u001b[2K\u001b[16A\u001b[2K\u001b[15A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[18A\u001b[2K\u001b[16A\u001b[2K\u001b[15A\u001b[2K\u001b[16A\u001b[2K\u001b[15A\u001b[2K\u001b[16A\u001b[2K\u001b[15A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[16A\u001b[2K\u001b[14A\u001b[2K\u001b[16A\u001b[2K\u001b[18A\u001b[2K\u001b[6A\u001b[2K\n"
     ]
    }
   ],
   "source": [
    "!./build_push.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce96e94-c472-42ad-a0a8-5a5c1a8e5d87",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name aws-trained-dreambooth-model\n",
      "mixed_precision fp16\n",
      "pretrained_model_name_or_path runwayml/stable-diffusion-v1-5\n",
      "instance_data_dir /opt/ml/input/data/images/\n",
      "class_data_dir /opt/ml/input/data/images/\n",
      "with_prior_preservation True\n",
      "models_path /opt/ml/model/\n",
      "manul_upload_model_path s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\n",
      "instance_prompt Erwin\\ Rommel\n",
      "class_prompt a\\ photo\\ of\\ Erwin\\ Rommel\n",
      "resolution 512\n",
      "train_batch_size 1\n",
      "sample_batch_size 1\n",
      "gradient_accumulation_steps 1\n",
      "learning_rate 2e-06\n",
      "lr_scheduler constant\n",
      "lr_warmup_steps 1000\n",
      "num_class_images 0\n",
      "max_train_steps 1000\n",
      "save_steps 1000\n",
      "attention xformers\n",
      "prior_loss_weight 0.5\n",
      "use_ema True\n",
      "train_text_encoder False\n",
      "not_cache_latents True\n",
      "gradient_checkpointing True\n",
      "save_use_epochs False\n",
      "use_8bit_adam False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: dreambooth-finetuning-v3-2023-04-25-09-29-43-398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-25 09:29:44 Starting - Starting the training job...\n",
      "2023-04-25 09:29:59 Starting - Preparing the instances for training...\n",
      "2023-04-25 09:30:45 Downloading - Downloading input data...\n",
      "2023-04-25 09:31:00 Training - Downloading the training image..............................\n",
      "2023-04-25 09:36:17 Training - Training image download completed. Training in progress......\u001b[34m2023-04-25 09:37:07,291 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-04-25 09:37:07,323 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-04-25 09:37:07,351 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-04-25 09:37:07,362 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"images\": \"/opt/ml/input/data/images\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g4dn.4xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"attention\": \"xformers\",\n",
      "        \"class_data_dir\": \"/opt/ml/input/data/images/\",\n",
      "        \"class_prompt\": \"a\\\\ photo\\\\ of\\\\ Erwin\\\\ Rommel\",\n",
      "        \"gradient_accumulation_steps\": 1,\n",
      "        \"gradient_checkpointing\": true,\n",
      "        \"instance_data_dir\": \"/opt/ml/input/data/images/\",\n",
      "        \"instance_prompt\": \"Erwin\\\\ Rommel\",\n",
      "        \"learning_rate\": 2e-06,\n",
      "        \"lr_scheduler\": \"constant\",\n",
      "        \"lr_warmup_steps\": 1000,\n",
      "        \"manul_upload_model_path\": \"s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\",\n",
      "        \"max_train_steps\": 1000,\n",
      "        \"mixed_precision\": \"fp16\",\n",
      "        \"model_name\": \"aws-trained-dreambooth-model\",\n",
      "        \"models_path\": \"/opt/ml/model/\",\n",
      "        \"not_cache_latents\": true,\n",
      "        \"num_class_images\": 0,\n",
      "        \"pretrained_model_name_or_path\": \"runwayml/stable-diffusion-v1-5\",\n",
      "        \"prior_loss_weight\": 0.5,\n",
      "        \"resolution\": 512,\n",
      "        \"sample_batch_size\": 1,\n",
      "        \"save_steps\": 1000,\n",
      "        \"save_use_epochs\": false,\n",
      "        \"train_batch_size\": 1,\n",
      "        \"train_text_encoder\": false,\n",
      "        \"use_8bit_adam\": false,\n",
      "        \"use_ema\": true,\n",
      "        \"with_prior_preservation\": true\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"images\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g4dn.4xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"job_name\": \"dreambooth-finetuning-v3-2023-04-25-09-29-43-398\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"/opt/ml/code/extensions/sd_dreambooth_extension/dreambooth/train_dreambooth\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.4xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.4xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"/opt/ml/code/extensions/sd_dreambooth_extension/dreambooth/train_dreambooth.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"attention\":\"xformers\",\"class_data_dir\":\"/opt/ml/input/data/images/\",\"class_prompt\":\"a\\\\ photo\\\\ of\\\\ Erwin\\\\ Rommel\",\"gradient_accumulation_steps\":1,\"gradient_checkpointing\":true,\"instance_data_dir\":\"/opt/ml/input/data/images/\",\"instance_prompt\":\"Erwin\\\\ Rommel\",\"learning_rate\":2e-06,\"lr_scheduler\":\"constant\",\"lr_warmup_steps\":1000,\"manul_upload_model_path\":\"s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\",\"max_train_steps\":1000,\"mixed_precision\":\"fp16\",\"model_name\":\"aws-trained-dreambooth-model\",\"models_path\":\"/opt/ml/model/\",\"not_cache_latents\":true,\"num_class_images\":0,\"pretrained_model_name_or_path\":\"runwayml/stable-diffusion-v1-5\",\"prior_loss_weight\":0.5,\"resolution\":512,\"sample_batch_size\":1,\"save_steps\":1000,\"save_use_epochs\":false,\"train_batch_size\":1,\"train_text_encoder\":false,\"use_8bit_adam\":false,\"use_ema\":true,\"with_prior_preservation\":true}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=/opt/ml/code/extensions/sd_dreambooth_extension/dreambooth/train_dreambooth.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.4xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"images\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"images\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g4dn.4xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.4xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=/opt/ml/code/extensions/sd_dreambooth_extension/dreambooth/train_dreambooth\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"images\":\"/opt/ml/input/data/images\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g4dn.4xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"attention\":\"xformers\",\"class_data_dir\":\"/opt/ml/input/data/images/\",\"class_prompt\":\"a\\\\ photo\\\\ of\\\\ Erwin\\\\ Rommel\",\"gradient_accumulation_steps\":1,\"gradient_checkpointing\":true,\"instance_data_dir\":\"/opt/ml/input/data/images/\",\"instance_prompt\":\"Erwin\\\\ Rommel\",\"learning_rate\":2e-06,\"lr_scheduler\":\"constant\",\"lr_warmup_steps\":1000,\"manul_upload_model_path\":\"s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\",\"max_train_steps\":1000,\"mixed_precision\":\"fp16\",\"model_name\":\"aws-trained-dreambooth-model\",\"models_path\":\"/opt/ml/model/\",\"not_cache_latents\":true,\"num_class_images\":0,\"pretrained_model_name_or_path\":\"runwayml/stable-diffusion-v1-5\",\"prior_loss_weight\":0.5,\"resolution\":512,\"sample_batch_size\":1,\"save_steps\":1000,\"save_use_epochs\":false,\"train_batch_size\":1,\"train_text_encoder\":false,\"use_8bit_adam\":false,\"use_ema\":true,\"with_prior_preservation\":true},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"images\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.4xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"dreambooth-finetuning-v3-2023-04-25-09-29-43-398\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"/opt/ml/code/extensions/sd_dreambooth_extension/dreambooth/train_dreambooth\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.4xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"/opt/ml/code/extensions/sd_dreambooth_extension/dreambooth/train_dreambooth.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--attention\",\"xformers\",\"--class_data_dir\",\"/opt/ml/input/data/images/\",\"--class_prompt\",\"a\\\\ photo\\\\ of\\\\ Erwin\\\\ Rommel\",\"--gradient_accumulation_steps\",\"1\",\"--gradient_checkpointing\",\"True\",\"--instance_data_dir\",\"/opt/ml/input/data/images/\",\"--instance_prompt\",\"Erwin\\\\ Rommel\",\"--learning_rate\",\"2e-06\",\"--lr_scheduler\",\"constant\",\"--lr_warmup_steps\",\"1000\",\"--manul_upload_model_path\",\"s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\",\"--max_train_steps\",\"1000\",\"--mixed_precision\",\"fp16\",\"--model_name\",\"aws-trained-dreambooth-model\",\"--models_path\",\"/opt/ml/model/\",\"--not_cache_latents\",\"True\",\"--num_class_images\",\"0\",\"--pretrained_model_name_or_path\",\"runwayml/stable-diffusion-v1-5\",\"--prior_loss_weight\",\"0.5\",\"--resolution\",\"512\",\"--sample_batch_size\",\"1\",\"--save_steps\",\"1000\",\"--save_use_epochs\",\"False\",\"--train_batch_size\",\"1\",\"--train_text_encoder\",\"False\",\"--use_8bit_adam\",\"False\",\"--use_ema\",\"True\",\"--with_prior_preservation\",\"True\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_IMAGES=/opt/ml/input/data/images\u001b[0m\n",
      "\u001b[34mSM_HP_ATTENTION=xformers\u001b[0m\n",
      "\u001b[34mSM_HP_CLASS_DATA_DIR=/opt/ml/input/data/images/\u001b[0m\n",
      "\u001b[34mSM_HP_CLASS_PROMPT=a\\ photo\\ of\\ Erwin\\ Rommel\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=1\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_CHECKPOINTING=true\u001b[0m\n",
      "\u001b[34mSM_HP_INSTANCE_DATA_DIR=/opt/ml/input/data/images/\u001b[0m\n",
      "\u001b[34mSM_HP_INSTANCE_PROMPT=Erwin\\ Rommel\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=2e-06\u001b[0m\n",
      "\u001b[34mSM_HP_LR_SCHEDULER=constant\u001b[0m\n",
      "\u001b[34mSM_HP_LR_WARMUP_STEPS=1000\u001b[0m\n",
      "\u001b[34mSM_HP_MANUL_UPLOAD_MODEL_PATH=s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_TRAIN_STEPS=1000\u001b[0m\n",
      "\u001b[34mSM_HP_MIXED_PRECISION=fp16\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=aws-trained-dreambooth-model\u001b[0m\n",
      "\u001b[34mSM_HP_MODELS_PATH=/opt/ml/model/\u001b[0m\n",
      "\u001b[34mSM_HP_NOT_CACHE_LATENTS=true\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_CLASS_IMAGES=0\u001b[0m\n",
      "\u001b[34mSM_HP_PRETRAINED_MODEL_NAME_OR_PATH=runwayml/stable-diffusion-v1-5\u001b[0m\n",
      "\u001b[34mSM_HP_PRIOR_LOSS_WEIGHT=0.5\u001b[0m\n",
      "\u001b[34mSM_HP_RESOLUTION=512\u001b[0m\n",
      "\u001b[34mSM_HP_SAMPLE_BATCH_SIZE=1\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STEPS=1000\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_USE_EPOCHS=false\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=1\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_TEXT_ENCODER=false\u001b[0m\n",
      "\u001b[34mSM_HP_USE_8BIT_ADAM=false\u001b[0m\n",
      "\u001b[34mSM_HP_USE_EMA=true\u001b[0m\n",
      "\u001b[34mSM_HP_WITH_PRIOR_PRESERVATION=true\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages:/opt/ml/code/repositories/xformers\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python /opt/ml/code/extensions/sd_dreambooth_extension/dreambooth/train_dreambooth.py --attention xformers --class_data_dir /opt/ml/input/data/images/ --class_prompt a\\ photo\\ of\\ Erwin\\ Rommel --gradient_accumulation_steps 1 --gradient_checkpointing True --instance_data_dir /opt/ml/input/data/images/ --instance_prompt Erwin\\ Rommel --learning_rate 2e-06 --lr_scheduler constant --lr_warmup_steps 1000 --manul_upload_model_path s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models --max_train_steps 1000 --mixed_precision fp16 --model_name aws-trained-dreambooth-model --models_path /opt/ml/model/ --not_cache_latents True --num_class_images 0 --pretrained_model_name_or_path runwayml/stable-diffusion-v1-5 --prior_loss_weight 0.5 --resolution 512 --sample_batch_size 1 --save_steps 1000 --save_use_epochs False --train_batch_size 1 --train_text_encoder False --use_8bit_adam False --use_ema True --with_prior_preservation True\u001b[0m\n",
      "\u001b[34m2023-04-25 09:37:07,363 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2023-04-25 09:37:07,363 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mPatching transformers to fix kwargs errors.\u001b[0m\n",
      "\u001b[34m{'manul_upload_model_path': 's3://sagemaker-us-west-2-687912291502/dreambooth/trained_models', 'model_name': 'aws-trained-dreambooth-model', 'models_path': '/opt/ml/model/', 'use_lora': False, 'use_cpu': False, 'lora_models_path': None, 'pretrained_model_name_or_path': 'runwayml/stable-diffusion-v1-5', 'pretrained_vae_name_or_path': None, 'revision': None, 'tokenizer_name': None, 'instance_data_dir': '/opt/ml/input/data/images/', 'class_data_dir': '/opt/ml/input/data/images/', 'instance_prompt': 'Erwin\\\\ Rommel', 'class_prompt': 'a\\\\ photo\\\\ of\\\\ Erwin\\\\ Rommel', 'pad_tokens': False, 'with_prior_preservation': True, 'save_use_global_counts': False, 'save_use_epochs': True, 'prior_loss_weight': 0.5, 'num_class_images': 0, 'output_dir': 'text-inversion-model', 'seed': -1, 'resolution': 512, 'center_crop': False, 'train_text_encoder': 'False', 'train_batch_size': 1, 'sample_batch_size': 1, 'num_train_epochs': 1, 'max_train_steps': 1000, 'epoch': 0, 'save_steps': 1000, 'gradient_accumulation_steps': 1, 'gradient_checkpointing': True, 'learning_rate': 2e-06, 'scale_lr': False, 'lr_scheduler': 'constant', 'lr_warmup_steps': 1000, 'use_8bit_adam': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'logging_dir': 'logs', 'mixed_precision': 'fp16', 'not_cache_latents': 'True', 'hflip': False, 'local_rank': -1, 'concepts_list': [{'instance_prompt': 'Erwin\\\\ Rommel', 'class_prompt': 'a\\\\ photo\\\\ of\\\\ Erwin\\\\ Rommel', 'instance_data_dir': '/opt/ml/input/data/images/', 'class_data_dir': '/opt/ml/input/data/images/', 'num_class_images': 0, 'instance_token': '', 'class_token': '', 'class_negative_prompt': '', 'class_guidance_scale': 7.5, 'class_infer_steps': 60}], 'use_ema': True, 'max_token_length': 75, 'half_model': False, 'attention': 'xformers', 'shuffle_tags': False}\u001b[0m\n",
      "\u001b[34mReplace CrossAttention.forward to use xformers\u001b[0m\n",
      "\u001b[34mChecking concept: {'instance_prompt': 'Erwin\\\\ Rommel', 'class_prompt': 'a\\\\ photo\\\\ of\\\\ Erwin\\\\ Rommel', 'instance_data_dir': '/opt/ml/input/data/images/', 'class_data_dir': '/opt/ml/input/data/images/', 'num_class_images': 0, 'instance_token': '', 'class_token': '', 'class_negative_prompt': '', 'class_guidance_scale': 7.5, 'class_infer_steps': 60}\u001b[0m\n",
      "\u001b[34mConcept requires 0 images.\u001b[0m\n",
      "\u001b[34m#015Downloading (…)okenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]#015Downloading (…)okenizer_config.json: 100%|██████████| 806/806 [00:00<00:00, 109kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]#015Downloading (…)tokenizer/vocab.json: 100%|██████████| 1.06M/1.06M [00:00<00:00, 13.3MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]#015Downloading (…)tokenizer/merges.txt: 100%|██████████| 525k/525k [00:00<00:00, 11.5MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)cial_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]#015Downloading (…)cial_tokens_map.json: 100%|██████████| 472/472 [00:00<00:00, 190kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)_encoder/config.json:   0%|          | 0.00/617 [00:00<?, ?B/s]#015Downloading (…)_encoder/config.json: 100%|██████████| 617/617 [00:00<00:00, 96.3kB/s]\u001b[0m\n",
      "\u001b[34mYou are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]#015Downloading model.safetensors:   2%|▏         | 10.5M/492M [00:00<00:09, 51.0MB/s]#015Downloading model.safetensors:   6%|▋         | 31.5M/492M [00:00<00:04, 103MB/s] #015Downloading model.safetensors:  13%|█▎        | 62.9M/492M [00:00<00:02, 174MB/s]#015Downloading model.safetensors:  21%|██▏       | 105M/492M [00:00<00:01, 248MB/s] #015Downloading model.safetensors:  30%|██▉       | 147M/492M [00:00<00:01, 292MB/s]#015Downloading model.safetensors:  38%|███▊      | 189M/492M [00:00<00:00, 319MB/s]#015Downloading model.safetensors:  47%|████▋     | 231M/492M [00:00<00:00, 336MB/s]#015Downloading model.safetensors:  55%|█████▌    | 273M/492M [00:00<00:00, 352MB/s]#015Downloading model.safetensors:  64%|██████▍   | 315M/492M [00:01<00:00, 359MB/s]#015Downloading model.safetensors:  72%|███████▏  | 357M/492M [00:01<00:00, 367MB/s]#015Downloading model.safetensors:  81%|████████  | 398M/492M [00:01<00:00, 371MB/s]#015Downloading model.safetensors:  89%|████████▉ | 440M/492M [00:01<00:00, 376MB/s]#015Downloading model.safetensors:  98%|█████████▊| 482M/492M [00:01<00:00, 376MB/s]#015Downloading model.safetensors: 100%|██████████| 492M/492M [00:01<00:00, 313MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)ch_model.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]#015Downloading (…)ch_model.safetensors:   0%|          | 10.5M/3.44G [00:00<01:01, 55.4MB/s]#015Downloading (…)ch_model.safetensors:   1%|          | 31.5M/3.44G [00:00<00:31, 109MB/s] #015Downloading (…)ch_model.safetensors:   2%|▏         | 62.9M/3.44G [00:00<00:18, 181MB/s]#015Downloading (…)ch_model.safetensors:   3%|▎         | 105M/3.44G [00:00<00:13, 256MB/s] #015Downloading (…)ch_model.safetensors:   4%|▍         | 147M/3.44G [00:00<00:10, 299MB/s]#015Downloading (…)ch_model.safetensors:   5%|▌         | 189M/3.44G [00:00<00:09, 326MB/s]#015Downloading (…)ch_model.safetensors:   7%|▋         | 231M/3.44G [00:00<00:09, 343MB/s]#015Downloading (…)ch_model.safetensors:   8%|▊         | 273M/3.44G [00:00<00:09, 346MB/s]#015Downloading (…)ch_model.safetensors:   9%|▉         | 315M/3.44G [00:01<00:09, 336MB/s]#015Downloading (…)ch_model.safetensors:  10%|█         | 357M/3.44G [00:01<00:09, 333MB/s]#015Downloading (…)ch_model.safetensors:  12%|█▏        | 398M/3.44G [00:01<00:09, 331MB/s]#015Downloading (…)ch_model.safetensors:  13%|█▎        | 440M/3.44G [00:01<00:09, 331MB/s]#015Downloading (…)ch_model.safetensors:  14%|█▍        | 482M/3.44G [00:01<00:08, 331MB/s]#015Downloading (…)ch_model.safetensors:  15%|█▌        | 524M/3.44G [00:01<00:08, 333MB/s]#015Downloading (…)ch_model.safetensors:  16%|█▋        | 566M/3.44G [00:01<00:08, 334MB/s]#015Downloading (…)ch_model.safetensors:  18%|█▊        | 608M/3.44G [00:01<00:08, 335MB/s]#015Downloading (…)ch_model.safetensors:  19%|█▉        | 650M/3.44G [00:02<00:08, 336MB/s]#015Downloading (…)ch_model.safetensors:  20%|██        | 692M/3.44G [00:02<00:08, 337MB/s]#015Downloading (…)ch_model.safetensors:  21%|██▏       | 734M/3.44G [00:02<00:07, 341MB/s]#015Downloading (…)ch_model.safetensors:  23%|██▎       | 776M/3.44G [00:02<00:07, 344MB/s]#015Downloading (…)ch_model.safetensors:  24%|██▍       | 818M/3.44G [00:02<00:07, 347MB/s]#015Downloading (…)ch_model.safetensors:  25%|██▌       | 860M/3.44G [00:02<00:07, 344MB/s]#015Downloading (…)ch_model.safetensors:  26%|██▌       | 902M/3.44G [00:02<00:07, 342MB/s]#015Downloading (…)ch_model.safetensors:  27%|██▋       | 944M/3.44G [00:02<00:07, 348MB/s]#015Downloading (…)ch_model.safetensors:  29%|██▊       | 986M/3.44G [00:03<00:06, 351MB/s]#015Downloading (…)ch_model.safetensors:  30%|██▉       | 1.03G/3.44G [00:03<00:06, 355MB/s]#015Downloading (…)ch_model.safetensors:  31%|███       | 1.07G/3.44G [00:03<00:06, 357MB/s]#015Downloading (…)ch_model.safetensors:  32%|███▏      | 1.11G/3.44G [00:03<00:06, 358MB/s]#015Downloading (…)ch_model.safetensors:  34%|███▎      | 1.15G/3.44G [00:03<00:06, 360MB/s]#015Downloading (…)ch_model.safetensors:  35%|███▍      | 1.20G/3.44G [00:03<00:06, 365MB/s]#015Downloading (…)ch_model.safetensors:  36%|███▌      | 1.24G/3.44G [00:03<00:05, 368MB/s]#015Downloading (…)ch_model.safetensors:  37%|███▋      | 1.28G/3.44G [00:03<00:05, 367MB/s]#015Downloading (…)ch_model.safetensors:  38%|███▊      | 1.32G/3.44G [00:03<00:05, 368MB/s]#015Downloading (…)ch_model.safetensors:  40%|███▉      | 1.36G/3.44G [00:04<00:05, 366MB/s]#015Downloading (…)ch_model.safetensors:  41%|████      | 1.41G/3.44G [00:04<00:05, 363MB/s]#015Downloading (…)ch_model.safetensors:  42%|████▏     | 1.45G/3.44G [00:04<00:05, 364MB/s]#015Downloading (…)ch_model.safetensors:  43%|████▎     | 1.49G/3.44G [00:04<00:05, 365MB/s]#015Downloading (…)ch_model.safetensors:  45%|████▍     | 1.53G/3.44G [00:04<00:05, 366MB/s]#015Downloading (…)ch_model.safetensors:  46%|████▌     | 1.57G/3.44G [00:04<00:05, 368MB/s]#015Downloading (…)ch_model.safetensors:  47%|████▋     | 1.61G/3.44G [00:04<00:04, 371MB/s]#015Downloading (…)ch_model.safetensors:  48%|████▊     | 1.66G/3.44G [00:04<00:04, 373MB/s]#015Downloading (…)ch_model.safetensors:  49%|████▉     | 1.70G/3.44G [00:05<00:04, 378MB/s]#015Downloading (…)ch_model.safetensors:  51%|█████     | 1.74G/3.44G [00:05<00:04, 381MB/s]#015Downloading (…)ch_model.safetensors:  52%|█████▏    | 1.78G/3.44G [00:05<00:04, 382MB/s]#015Downloading (…)ch_model.safetensors:  53%|█████▎    | 1.82G/3.44G [00:05<00:04, 379MB/s]#015Downloading (…)ch_model.safetensors:  54%|█████▍    | 1.87G/3.44G [00:05<00:04, 384MB/s]#015Downloading (…)ch_model.safetensors:  56%|█████▌    | 1.91G/3.44G [00:05<00:04, 381MB/s]#015Downloading (…)ch_model.safetensors:  57%|█████▋    | 1.95G/3.44G [00:05<00:03, 383MB/s]#015Downloading (…)ch_model.safetensors:  58%|█████▊    | 1.99G/3.44G [00:05<00:03, 386MB/s]#015Downloading (…)ch_model.safetensors:  59%|█████▉    | 2.03G/3.44G [00:05<00:03, 384MB/s]#015Downloading (…)ch_model.safetensors:  60%|██████    | 2.08G/3.44G [00:06<00:03, 362MB/s]#015Downloading (…)ch_model.safetensors:  62%|██████▏   | 2.12G/3.44G [00:06<00:03, 338MB/s]#015Downloading (…)ch_model.safetensors:  63%|██████▎   | 2.16G/3.44G [00:06<00:03, 325MB/s]#015Downloading (…)ch_model.safetensors:  64%|██████▍   | 2.20G/3.44G [00:06<00:03, 316MB/s]#015Downloading (…)ch_model.safetensors:  65%|██████▌   | 2.24G/3.44G [00:06<00:03, 314MB/s]#015Downloading (…)ch_model.safetensors:  66%|██████▋   | 2.29G/3.44G [00:06<00:03, 314MB/s]#015Downloading (…)ch_model.safetensors:  68%|██████▊   | 2.33G/3.44G [00:06<00:03, 310MB/s]#015Downloading (…)ch_model.safetensors:  69%|██████▊   | 2.36G/3.44G [00:06<00:03, 307MB/s]#015Downloading (…)ch_model.safetensors:  70%|██████▉   | 2.39G/3.44G [00:07<00:03, 307MB/s]#015Downloading (…)ch_model.safetensors:  71%|███████   | 2.43G/3.44G [00:07<00:03, 310MB/s]#015Downloading (…)ch_model.safetensors:  72%|███████▏  | 2.47G/3.44G [00:07<00:03, 311MB/s]#015Downloading (…)ch_model.safetensors:  73%|███████▎  | 2.52G/3.44G [00:07<00:02, 315MB/s]#015Downloading (…)ch_model.safetensors:  74%|███████▍  | 2.56G/3.44G [00:07<00:02, 317MB/s]#015Downloading (…)ch_model.safetensors:  76%|███████▌  | 2.60G/3.44G [00:07<00:02, 321MB/s]#015Downloading (…)ch_model.safetensors:  77%|███████▋  | 2.64G/3.44G [00:07<00:02, 323MB/s]#015Downloading (…)ch_model.safetensors:  78%|███████▊  | 2.68G/3.44G [00:07<00:02, 326MB/s]#015Downloading (…)ch_model.safetensors:  79%|███████▉  | 2.73G/3.44G [00:08<00:02, 329MB/s]#015Downloading (…)ch_model.safetensors:  81%|████████  | 2.77G/3.44G [00:08<00:02, 319MB/s]#015Downloading (…)ch_model.safetensors:  82%|████████▏ | 2.81G/3.44G [00:08<00:01, 323MB/s]#015Downloading (…)ch_model.safetensors:  83%|████████▎ | 2.85G/3.44G [00:08<00:01, 328MB/s]#015Downloading (…)ch_model.safetensors:  84%|████████▍ | 2.89G/3.44G [00:08<00:01, 331MB/s]#015Downloading (…)ch_model.safetensors:  85%|████████▌ | 2.94G/3.44G [00:08<00:01, 333MB/s]#015Downloading (…)ch_model.safetensors:  87%|████████▋ | 2.98G/3.44G [00:08<00:01, 337MB/s]#015Downloading (…)ch_model.safetensors:  88%|████████▊ | 3.02G/3.44G [00:08<00:01, 336MB/s]#015Downloading (…)ch_model.safetensors:  89%|████████▉ | 3.06G/3.44G [00:09<00:01, 337MB/s]#015Downloading (…)ch_model.safetensors:  90%|█████████ | 3.10G/3.44G [00:09<00:00, 335MB/s]#015Downloading (…)ch_model.safetensors:  91%|█████████▏| 3.15G/3.44G [00:09<00:00, 331MB/s]#015Downloading (…)ch_model.safetensors:  93%|█████████▎| 3.19G/3.44G [00:09<00:00, 326MB/s]#015Downloading (…)ch_model.safetensors:  94%|█████████▍| 3.23G/3.44G [00:09<00:00, 332MB/s]#015Downloading (…)ch_model.safetensors:  95%|█████████▌| 3.27G/3.44G [00:09<00:00, 336MB/s]#015Downloading (…)ch_model.safetensors:  96%|█████████▋| 3.31G/3.44G [00:09<00:00, 330MB/s]#015Downloading (…)ch_model.safetensors:  98%|█████████▊| 3.36G/3.44G [00:10<00:00, 307MB/s]#015Downloading (…)ch_model.safetensors:  99%|█████████▊| 3.39G/3.44G [00:10<00:00, 297MB/s]#015Downloading (…)ch_model.safetensors:  99%|█████████▉| 3.42G/3.44G [00:10<00:00, 289MB/s]#015Downloading (…)ch_model.safetensors: 100%|██████████| 3.44G/3.44G [00:10<00:00, 333MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)ain/unet/config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]#015Downloading (…)ain/unet/config.json: 100%|██████████| 743/743 [00:00<00:00, 126kB/s]\u001b[0m\n",
      "\u001b[34m Loaded model. \n",
      " Allocated: 0.0GB \n",
      " Reserved: 0.0GB \u001b[0m\n",
      "\u001b[34m#015Downloading (…)ch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]#015Downloading (…)ch_model.safetensors:   3%|▎         | 10.5M/335M [00:00<00:06, 51.7MB/s]#015Downloading (…)ch_model.safetensors:   9%|▉         | 31.5M/335M [00:00<00:02, 103MB/s] #015Downloading (…)ch_model.safetensors:  19%|█▉        | 62.9M/335M [00:00<00:01, 166MB/s]#015Downloading (…)ch_model.safetensors:  28%|██▊       | 94.4M/335M [00:00<00:01, 206MB/s]#015Downloading (…)ch_model.safetensors:  38%|███▊      | 126M/335M [00:00<00:00, 232MB/s] #015Downloading (…)ch_model.safetensors:  47%|████▋     | 157M/335M [00:00<00:00, 252MB/s]#015Downloading (…)ch_model.safetensors:  56%|█████▋    | 189M/335M [00:00<00:00, 267MB/s]#015Downloading (…)ch_model.safetensors:  66%|██████▌   | 220M/335M [00:00<00:00, 273MB/s]#015Downloading (…)ch_model.safetensors:  75%|███████▌  | 252M/335M [00:01<00:00, 276MB/s]#015Downloading (…)ch_model.safetensors:  85%|████████▍ | 283M/335M [00:01<00:00, 280MB/s]#015Downloading (…)ch_model.safetensors:  94%|█████████▍| 315M/335M [00:01<00:00, 281MB/s]#015Downloading (…)ch_model.safetensors: 100%|██████████| 335M/335M [00:01<00:00, 239MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)main/vae/config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]#015Downloading (…)main/vae/config.json: 100%|██████████| 547/547 [00:00<00:00, 348kB/s]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('${LD_LIBRARY_PATH}')}\n",
      "  warn(\u001b[0m\n",
      "\u001b[34m===================================BUG REPORT===================================\u001b[0m\n",
      "\u001b[34mWelcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\u001b[0m\n",
      "\u001b[34mFor effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\u001b[0m\n",
      "\u001b[34m================================================================================\u001b[0m\n",
      "\u001b[34mCUDA SETUP: CUDA runtime path found: /opt/conda/lib/libcudart.so\u001b[0m\n",
      "\u001b[34mCUDA SETUP: Highest compute capability among GPUs detected: 7.5\u001b[0m\n",
      "\u001b[34mCUDA SETUP: Detected CUDA version 113\u001b[0m\n",
      "\u001b[34mCUDA SETUP: Loading binary /opt/conda/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...\u001b[0m\n",
      "\u001b[34m#015Downloading (…)cheduler_config.json:   0%|          | 0.00/308 [00:00<?, ?B/s]#015Downloading (…)cheduler_config.json: 100%|██████████| 308/308 [00:00<00:00, 48.0kB/s]\u001b[0m\n",
      "\u001b[34m Scheduler, EMA Loaded. \n",
      " Allocated: 5.5GB \n",
      " Reserved: 5.6GB \u001b[0m\n",
      "\u001b[34m***** Running training *****\n",
      "  Num examples = 9\n",
      "  Num batches each epoch = 9\n",
      "  Num Epochs = 112\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1000\n",
      "  Actual steps: 1000\n",
      "   Training settings: CPU: False Adam: True, Prec: fp16, Grad: True, TextTr: False EM: True, LR: 2e-06 LORA:False \n",
      " Allocated: 5.5GB \n",
      " Reserved: 5.6GB \u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1000 [00:00<?, ?it/s]#015Steps:   0%|          | 0/1000 [00:00<?, ?it/s]You're using a CLIPTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m Step 0 completed. \u001b[0m\n",
      "\u001b[34m#015Steps:   0%|          | 0/1000 [00:02<?, ?it/s, loss=0.932, lr=2e-6, vram=7.4/7.7GB]#015Steps:   0%|          | 1/1000 [00:02<39:10,  2.35s/it, loss=0.932, lr=2e-6, vram=7.4/7.7GB]#015Steps:   0%|          | 2/1000 [00:03<25:18,  1.52s/it, loss=0.932, lr=2e-6, vram=7.4/7.7GB]#015Steps:   0%|          | 2/1000 [00:04<25:18,  1.52s/it, loss=0.29, lr=2e-6, vram=7.4/7.7GB] #015Steps:   0%|          | 3/1000 [00:04<20:46,  1.25s/it, loss=0.29, lr=2e-6, vram=7.4/7.7GB]#015Steps:   0%|          | 4/1000 [00:05<18:44,  1.13s/it, loss=0.29, lr=2e-6, vram=7.4/7.7GB]#015Steps:   0%|          | 4/1000 [00:06<18:44,  1.13s/it, loss=0.274, lr=2e-6, vram=7.4/7.7GB]#015Steps:   0%|          | 5/1000 [00:06<17:32,  1.06s/it, loss=0.274, lr=2e-6, vram=7.4/7.7GB]#015Steps:   1%|          | 6/1000 [00:07<16:55,  1.02s/it, loss=0.274, lr=2e-6, vram=7.4/7.7GB]#015Steps:   1%|          | 6/1000 [00:07<16:55,  1.02s/it, loss=0.249, lr=2e-6, vram=7.4/7.7GB]#015Steps:   1%|          | 7/1000 [00:07<16:25,  1.01it/s, loss=0.249, lr=2e-6, vram=7.4/7.7GB]#015Steps:   1%|          | 8/1000 [00:08<16:07,  1.03it/s, loss=0.249, lr=2e-6, vram=7.4/7.7GB]#015Steps:   1%|          | 8/1000 [00:09<16:07,  1.03it/s, loss=0.117, lr=2e-6, vram=7.4/7.7GB]#015Steps:   1%|          | 9/1000 [00:09<15:50,  1.04it/s, loss=0.117, lr=2e-6, vram=7.4/7.7GB]\n",
      " Allocated: 7.4GB \n",
      " Reserved: 7.7GB \n",
      " Step 5 completed. \n",
      " Allocated: 7.4GB \n",
      " Reserved: 7.7GB \u001b[0m\n",
      "\u001b[34m#015Downloading (…)ain/model_index.json:   0%|          | 0.00/543 [00:00<?, ?B/s]#033[A#015Downloading (…)ain/model_index.json: 100%|██████████| 543/543 [00:00<00:00, 261kB/s]\u001b[0m\n",
      "\u001b[34m#015Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading (…)rocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading (…)_encoder/config.json:   0%|          | 0.00/617 [00:00<?, ?B/s]#033[A#033[A#033[A#033[A#033[A#015Downloading (…)rocessor_config.json: 100%|██████████| 342/342 [00:00<00:00, 22.9kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)_encoder/config.json: 100%|██████████| 617/617 [00:00<00:00, 77.1kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)cial_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading (…)okenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]#033[A#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:   1%|          | 10.5M/1.22G [00:00<00:14, 84.1MB/s]#033[A#033[A#033[A#015Downloading (…)cial_tokens_map.json: 100%|██████████| 472/472 [00:00<00:00, 29.8kB/s]\u001b[0m\n",
      "\u001b[34m#015Fetching 15 files:   7%|▋         | 1/15 [00:00<00:04,  3.41it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading (…)_checker/config.json:   0%|          | 0.00/4.72k [00:00<?, ?B/s]#033[A#033[A#033[A#033[A#015Downloading (…)okenizer_config.json: 100%|██████████| 806/806 [00:00<00:00, 44.7kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)_checker/config.json: 100%|██████████| 4.72k/4.72k [00:00<00:00, 514kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:   2%|▏         | 10.5M/492M [00:00<00:07, 62.0MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading (…)tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]#033[A#033[A#033[A#033[A#015Downloading (…)tokenizer/merges.txt: 100%|██████████| 525k/525k [00:00<00:00, 16.5MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:   3%|▎         | 31.5M/1.22G [00:00<00:08, 134MB/s] #033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:   6%|▋         | 31.5M/492M [00:00<00:03, 121MB/s] #033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:   5%|▌         | 62.9M/1.22G [00:00<00:05, 206MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  15%|█▍        | 73.4M/492M [00:00<00:01, 220MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:   9%|▊         | 105M/1.22G [00:00<00:04, 262MB/s] #033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading (…)tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]#033[A#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  23%|██▎       | 115M/492M [00:00<00:01, 275MB/s] #033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  12%|█▏        | 147M/1.22G [00:00<00:03, 290MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading (…)tokenizer/vocab.json: 100%|██████████| 1.06M/1.06M [00:00<00:00, 10.1MB/s]#033[A#033[A#033[A#033[A#015Downloading (…)tokenizer/vocab.json: 100%|██████████| 1.06M/1.06M [00:00<00:00, 9.99MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  32%|███▏      | 157M/492M [00:00<00:01, 314MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  16%|█▌        | 189M/1.22G [00:00<00:03, 310MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  40%|████      | 199M/492M [00:00<00:00, 339MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  49%|████▉     | 241M/492M [00:00<00:00, 354MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  19%|█▉        | 231M/1.22G [00:00<00:03, 317MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  58%|█████▊    | 283M/492M [00:00<00:00, 363MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  22%|██▏       | 273M/1.22G [00:00<00:02, 326MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  66%|██████▌   | 325M/492M [00:01<00:00, 367MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  26%|██▌       | 315M/1.22G [00:01<00:02, 328MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  75%|███████▍  | 367M/492M [00:01<00:00, 375MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  29%|██▉       | 357M/1.22G [00:01<00:02, 333MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  83%|████████▎ | 409M/492M [00:01<00:00, 373MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  33%|███▎      | 398M/1.22G [00:01<00:02, 334MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  92%|█████████▏| 451M/492M [00:01<00:00, 379MB/s]#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  36%|███▌      | 440M/1.22G [00:01<00:02, 339MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors: 100%|██████████| 492M/492M [00:01<00:00, 378MB/s]#033[A#033[A#015Downloading model.safetensors: 100%|██████████| 492M/492M [00:01<00:00, 328MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  40%|███▉      | 482M/1.22G [00:01<00:02, 342MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  43%|████▎     | 524M/1.22G [00:01<00:01, 352MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  47%|████▋     | 566M/1.22G [00:01<00:01, 359MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  50%|█████     | 608M/1.22G [00:01<00:01, 359MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  53%|█████▎    | 650M/1.22G [00:02<00:01, 360MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  57%|█████▋    | 692M/1.22G [00:02<00:01, 362MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  60%|██████    | 734M/1.22G [00:02<00:01, 365MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  64%|██████▍   | 776M/1.22G [00:02<00:01, 365MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  67%|██████▋   | 818M/1.22G [00:02<00:01, 364MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  71%|███████   | 860M/1.22G [00:02<00:00, 370MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  74%|███████▍  | 902M/1.22G [00:02<00:00, 372MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  78%|███████▊  | 944M/1.22G [00:02<00:00, 367MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  81%|████████  | 986M/1.22G [00:02<00:00, 367MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  85%|████████▍ | 1.03G/1.22G [00:03<00:00, 366MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  88%|████████▊ | 1.07G/1.22G [00:03<00:00, 364MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  91%|█████████▏| 1.11G/1.22G [00:03<00:00, 363MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  95%|█████████▍| 1.15G/1.22G [00:03<00:00, 364MB/s]#033[A#033[A#033[A\u001b[0m\n",
      "\u001b[34m#015Downloading model.safetensors:  98%|█████████▊| 1.20G/1.22G [00:03<00:00, 361MB/s]#033[A#033[A#033[A#015Downloading model.safetensors: 100%|██████████| 1.22G/1.22G [00:03<00:00, 339MB/s]\u001b[0m\n",
      "\u001b[34m#015Fetching 15 files:  27%|██▋       | 4/15 [00:03<00:10,  1.01it/s]#033[A#015Fetching 15 files: 100%|██████████| 15/15 [00:03<00:00,  4.01it/s]\u001b[0m\n",
      "\u001b[34mmanul_upload_model_path is s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/model_index.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/model_index.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsfeature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsscheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsloggingdreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelslogging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/merges.txt\u001b[0m\n",
      "\u001b[34m#015Steps:   1%|          | 10/1000 [01:05<4:52:45, 17.74s/it, loss=0.117, lr=2e-6, vram=7.4/7.7GB]#015Steps:   1%|          | 10/1000 [01:06<4:52:45, 17.74s/it, loss=0.123, lr=2e-6, vram=7.4/7.7GB]#015Steps:   1%|          | 11/1000 [01:06<3:27:39, 12.60s/it, loss=0.123, lr=2e-6, vram=7.4/7.7GB]#015Steps:   1%|          | 12/1000 [01:07<2:29:07,  9.06s/it, loss=0.123, lr=2e-6, vram=7.4/7.7GB]#015Steps:   1%|          | 12/1000 [01:07<2:29:07,  9.06s/it, loss=0.628, lr=2e-6, vram=7.4/7.7GB]#015Steps:   1%|▏         | 13/1000 [01:07<1:48:30,  6.60s/it, loss=0.628, lr=2e-6, vram=7.4/7.7GB]#015Steps:   1%|▏         | 14/1000 [01:08<1:20:17,  4.89s/it, loss=0.628, lr=2e-6, vram=7.4/7.7GB]#015Steps:   1%|▏         | 14/1000 [01:09<1:20:17,  4.89s/it, loss=0.357, lr=2e-6, vram=7.4/7.7GB]#015Steps:   2%|▏         | 15/1000 [01:09<1:00:40,  3.70s/it, loss=0.357, lr=2e-6, vram=7.4/7.7GB]#015Steps:   2%|▏         | 16/1000 [01:10<47:02,  2.87s/it, loss=0.357, lr=2e-6, vram=7.4/7.7GB]  #015Steps:   2%|▏         | 16/1000 [01:11<47:02,  2.87s/it, loss=0.241, lr=2e-6, vram=7.4/7.7GB]#015Steps:   2%|▏         | 17/1000 [01:11<37:29,  2.29s/it, loss=0.241, lr=2e-6, vram=7.4/7.7GB]#015Steps:   2%|▏         | 18/1000 [01:12<30:46,  1.88s/it, loss=0.241, lr=2e-6, vram=7.4/7.7GB]\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/feature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/scheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/config.json\u001b[0m\n",
      "\u001b[34m#015Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]#033[A#015Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 202950.19it/s]\u001b[0m\n",
      "\u001b[34mmanul_upload_model_path is s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/model_index.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/model_index.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsfeature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsscheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsloggingdreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelslogging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/vocab.json\u001b[0m\n",
      "\u001b[34m#015Steps:   2%|▏         | 18/1000 [02:01<30:46,  1.88s/it, loss=0.325, lr=2e-6, vram=7.4/7.7GB]#015Steps:   2%|▏         | 19/1000 [02:01<4:19:31, 15.87s/it, loss=0.325, lr=2e-6, vram=7.4/7.7GB]#015Steps:   2%|▏         | 20/1000 [02:02<3:06:04, 11.39s/it, loss=0.325, lr=2e-6, vram=7.4/7.7GB]#015Steps:   2%|▏         | 20/1000 [02:03<3:06:04, 11.39s/it, loss=0.188, lr=2e-6, vram=7.4/7.7GB]#015Steps:   2%|▏         | 21/1000 [02:03<2:14:42,  8.26s/it, loss=0.188, lr=2e-6, vram=7.4/7.7GB]#015Steps:   2%|▏         | 22/1000 [02:03<1:38:49,  6.06s/it, loss=0.188, lr=2e-6, vram=7.4/7.7GB]#015Steps:   2%|▏         | 22/1000 [02:04<1:38:49,  6.06s/it, loss=0.0706, lr=2e-6, vram=7.4/7.7GB]#015Steps:   2%|▏         | 23/1000 [02:04<1:13:41,  4.53s/it, loss=0.0706, lr=2e-6, vram=7.4/7.7GB]#015Steps:   2%|▏         | 24/1000 [02:05<56:13,  3.46s/it, loss=0.0706, lr=2e-6, vram=7.4/7.7GB]  #015Steps:   2%|▏         | 24/1000 [02:06<56:13,  3.46s/it, loss=0.197, lr=2e-6, vram=7.4/7.7GB] #015Steps:   2%|▎         | 25/1000 [02:06<43:54,  2.70s/it, loss=0.197, lr=2e-6, vram=7.4/7.7GB]#015Steps:   3%|▎         | 26/1000 [02:07<35:18,  2.17s/it, loss=0.197, lr=2e-6, vram=7.4/7.7GB]#015Steps:   3%|▎         | 26/1000 [02:08<35:18,  2.17s/it, loss=0.256, lr=2e-6, vram=7.4/7.7GB]#015Steps:   3%|▎         | 27/1000 [02:08<29:14,  1.80s/it, loss=0.256, lr=2e-6, vram=7.4/7.7GB]\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/feature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/scheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34m#015Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]#033[A#015Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 174762.67it/s]\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/config.json\u001b[0m\n",
      "\u001b[34mmanul_upload_model_path is s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/model_index.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/model_index.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsfeature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsscheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsloggingdreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelslogging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/feature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/scheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34m#015Steps:   3%|▎         | 28/1000 [02:56<4:13:58, 15.68s/it, loss=0.256, lr=2e-6, vram=7.4/7.7GB]#015Steps:   3%|▎         | 28/1000 [02:57<4:13:58, 15.68s/it, loss=0.102, lr=2e-6, vram=7.4/7.7GB]#015Steps:   3%|▎         | 29/1000 [02:57<3:02:11, 11.26s/it, loss=0.102, lr=2e-6, vram=7.4/7.7GB]#015Steps:   3%|▎         | 30/1000 [02:58<2:12:02,  8.17s/it, loss=0.102, lr=2e-6, vram=7.4/7.7GB]#015Steps:   3%|▎         | 30/1000 [02:59<2:12:02,  8.17s/it, loss=0.182, lr=2e-6, vram=7.4/7.7GB]#015Steps:   3%|▎         | 31/1000 [02:59<1:36:57,  6.00s/it, loss=0.182, lr=2e-6, vram=7.4/7.7GB]#015Steps:   3%|▎         | 32/1000 [03:00<1:12:28,  4.49s/it, loss=0.182, lr=2e-6, vram=7.4/7.7GB]#015Steps:   3%|▎         | 32/1000 [03:01<1:12:28,  4.49s/it, loss=0.103, lr=2e-6, vram=7.4/7.7GB]#015Steps:   3%|▎         | 33/1000 [03:01<55:13,  3.43s/it, loss=0.103, lr=2e-6, vram=7.4/7.7GB]  #015Steps:   3%|▎         | 34/1000 [03:02<43:12,  2.68s/it, loss=0.103, lr=2e-6, vram=7.4/7.7GB]#015Steps:   3%|▎         | 34/1000 [03:03<43:12,  2.68s/it, loss=0.178, lr=2e-6, vram=7.4/7.7GB]#015Steps:   4%|▎         | 35/1000 [03:03<34:47,  2.16s/it, loss=0.178, lr=2e-6, vram=7.4/7.7GB]#015Steps:   4%|▎         | 36/1000 [03:04<28:50,  1.79s/it, loss=0.178, lr=2e-6, vram=7.4/7.7GB]\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/config.json\u001b[0m\n",
      "\u001b[34m#015Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]#033[A#015Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 118706.72it/s]\u001b[0m\n",
      "\u001b[34mmanul_upload_model_path is s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/model_index.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/model_index.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsfeature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsscheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsloggingdreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelslogging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/feature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/scheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/config.json\u001b[0m\n",
      "\u001b[34m#015Steps:   4%|▎         | 36/1000 [03:51<28:50,  1.79s/it, loss=0.153, lr=2e-6, vram=7.4/7.7GB]#015Steps:   4%|▎         | 37/1000 [03:51<4:07:39, 15.43s/it, loss=0.153, lr=2e-6, vram=7.4/7.7GB]#015Steps:   4%|▍         | 38/1000 [03:52<2:57:45, 11.09s/it, loss=0.153, lr=2e-6, vram=7.4/7.7GB]#015Steps:   4%|▍         | 38/1000 [03:53<2:57:45, 11.09s/it, loss=0.0763, lr=2e-6, vram=7.4/7.7GB]#015Steps:   4%|▍         | 39/1000 [03:53<2:08:50,  8.04s/it, loss=0.0763, lr=2e-6, vram=7.4/7.7GB]#015Steps:   4%|▍         | 40/1000 [03:54<1:34:38,  5.92s/it, loss=0.0763, lr=2e-6, vram=7.4/7.7GB]#015Steps:   4%|▍         | 40/1000 [03:55<1:34:38,  5.92s/it, loss=0.223, lr=2e-6, vram=7.4/7.7GB] #015Steps:   4%|▍         | 41/1000 [03:55<1:10:43,  4.43s/it, loss=0.223, lr=2e-6, vram=7.4/7.7GB]#015Steps:   4%|▍         | 42/1000 [03:56<54:05,  3.39s/it, loss=0.223, lr=2e-6, vram=7.4/7.7GB]  #015Steps:   4%|▍         | 42/1000 [03:57<54:05,  3.39s/it, loss=0.155, lr=2e-6, vram=7.4/7.7GB]#015Steps:   4%|▍         | 43/1000 [03:57<42:20,  2.65s/it, loss=0.155, lr=2e-6, vram=7.4/7.7GB]#015Steps:   4%|▍         | 44/1000 [03:58<34:13,  2.15s/it, loss=0.155, lr=2e-6, vram=7.4/7.7GB]#015Steps:   4%|▍         | 44/1000 [03:59<34:13,  2.15s/it, loss=0.474, lr=2e-6, vram=7.4/7.7GB]#015Steps:   4%|▍         | 45/1000 [03:59<28:23,  1.78s/it, loss=0.474, lr=2e-6, vram=7.4/7.7GB]\u001b[0m\n",
      "\u001b[34m#015Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]#033[A#015Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 173318.35it/s]\u001b[0m\n",
      "\u001b[34mmanul_upload_model_path is s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/model_index.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/model_index.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsfeature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsscheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsloggingdreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelslogging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/feature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/scheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/config.json\u001b[0m\n",
      "\u001b[34m#015Steps:  89%|████████▉ | 892/1000 [1:35:45<31:44, 17.63s/it, loss=0.0165, lr=2e-6, vram=7.4/7.7GB]#015Steps:  89%|████████▉ | 892/1000 [1:35:46<31:44, 17.63s/it, loss=0.183, lr=2e-6, vram=7.4/7.7GB] #015Steps:  89%|████████▉ | 893/1000 [1:35:46<22:31, 12.63s/it, loss=0.183, lr=2e-6, vram=7.4/7.7GB]#015Steps:  89%|████████▉ | 894/1000 [1:35:47<16:08,  9.13s/it, loss=0.183, lr=2e-6, vram=7.4/7.7GB]#015Steps:  89%|████████▉ | 894/1000 [1:35:48<16:08,  9.13s/it, loss=0.0275, lr=2e-6, vram=7.4/7.7GB]#015Steps:  90%|████████▉ | 895/1000 [1:35:48<11:41,  6.68s/it, loss=0.0275, lr=2e-6, vram=7.4/7.7GB]#015Steps:  90%|████████▉ | 896/1000 [1:35:49<08:35,  4.96s/it, loss=0.0275, lr=2e-6, vram=7.4/7.7GB]#015Steps:  90%|████████▉ | 896/1000 [1:35:50<08:35,  4.96s/it, loss=0.179, lr=2e-6, vram=7.4/7.7GB] #015Steps:  90%|████████▉ | 897/1000 [1:35:50<06:27,  3.76s/it, loss=0.179, lr=2e-6, vram=7.4/7.7GB]#015Steps:  90%|████████▉ | 898/1000 [1:35:51<04:57,  2.92s/it, loss=0.179, lr=2e-6, vram=7.4/7.7GB]#015Steps:  90%|████████▉ | 898/1000 [1:35:52<04:57,  2.92s/it, loss=0.122, lr=2e-6, vram=7.4/7.7GB]#015Steps:  90%|████████▉ | 899/1000 [1:35:52<03:55,  2.33s/it, loss=0.122, lr=2e-6, vram=7.4/7.7GB]#015Steps:  90%|█████████ | 900/1000 [1:35:53<03:11,  1.91s/it, loss=0.122, lr=2e-6, vram=7.4/7.7GB]\u001b[0m\n",
      "\u001b[34m#015Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]#033[A#015Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 172368.66it/s]\u001b[0m\n",
      "\u001b[34mmanul_upload_model_path is s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/model_index.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/model_index.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsfeature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsscheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsloggingdreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelslogging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34m#015Steps:  90%|█████████ | 900/1000 [1:36:45<03:11,  1.91s/it, loss=0.0257, lr=2e-6, vram=7.4/7.7GB]#015Steps:  90%|█████████ | 901/1000 [1:36:45<28:04, 17.02s/it, loss=0.0257, lr=2e-6, vram=7.4/7.7GB]#015Steps:  90%|█████████ | 902/1000 [1:36:46<19:55, 12.20s/it, loss=0.0257, lr=2e-6, vram=7.4/7.7GB]#015Steps:  90%|█████████ | 902/1000 [1:36:47<19:55, 12.20s/it, loss=0.0468, lr=2e-6, vram=7.4/7.7GB]#015Steps:  90%|█████████ | 903/1000 [1:36:47<14:16,  8.83s/it, loss=0.0468, lr=2e-6, vram=7.4/7.7GB]#015Steps:  90%|█████████ | 904/1000 [1:36:48<10:20,  6.46s/it, loss=0.0468, lr=2e-6, vram=7.4/7.7GB]#015Steps:  90%|█████████ | 904/1000 [1:36:49<10:20,  6.46s/it, loss=0.0459, lr=2e-6, vram=7.4/7.7GB]#015Steps:  90%|█████████ | 905/1000 [1:36:49<07:36,  4.81s/it, loss=0.0459, lr=2e-6, vram=7.4/7.7GB]#015Steps:  91%|█████████ | 906/1000 [1:36:50<05:43,  3.66s/it, loss=0.0459, lr=2e-6, vram=7.4/7.7GB]#015Steps:  91%|█████████ | 906/1000 [1:36:51<05:43,  3.66s/it, loss=0.4, lr=2e-6, vram=7.4/7.7GB]   #015Steps:  91%|█████████ | 907/1000 [1:36:51<04:25,  2.85s/it, loss=0.4, lr=2e-6, vram=7.4/7.7GB]#015Steps:  91%|█████████ | 908/1000 [1:36:52<03:30,  2.28s/it, loss=0.4, lr=2e-6, vram=7.4/7.7GB]#015Steps:  91%|█████████ | 908/1000 [1:36:53<03:30,  2.28s/it, loss=0.0851, lr=2e-6, vram=7.4/7.7GB]#015Steps:  91%|█████████ | 909/1000 [1:36:53<02:51,  1.88s/it, loss=0.0851, lr=2e-6, vram=7.4/7.7GB]\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/feature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/scheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/config.json\u001b[0m\n",
      "\u001b[34m#015Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]#033[A#015Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 188366.95it/s]\u001b[0m\n",
      "\u001b[34mmanul_upload_model_path is s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/model_index.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/model_index.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsfeature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsscheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsloggingdreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelslogging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/feature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/scheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/config.json\u001b[0m\n",
      "\u001b[34m#015Steps:  91%|█████████ | 910/1000 [1:37:43<24:47, 16.53s/it, loss=0.0851, lr=2e-6, vram=7.4/7.7GB]#015Steps:  91%|█████████ | 910/1000 [1:37:44<24:47, 16.53s/it, loss=0.0886, lr=2e-6, vram=7.4/7.7GB]#015Steps:  91%|█████████ | 911/1000 [1:37:44<17:35, 11.86s/it, loss=0.0886, lr=2e-6, vram=7.4/7.7GB]#015Steps:  91%|█████████ | 912/1000 [1:37:45<12:35,  8.59s/it, loss=0.0886, lr=2e-6, vram=7.4/7.7GB]#015Steps:  91%|█████████ | 912/1000 [1:37:46<12:35,  8.59s/it, loss=0.0217, lr=2e-6, vram=7.4/7.7GB]#015Steps:  91%|█████████▏| 913/1000 [1:37:46<09:08,  6.30s/it, loss=0.0217, lr=2e-6, vram=7.4/7.7GB]#015Steps:  91%|█████████▏| 914/1000 [1:37:47<06:43,  4.69s/it, loss=0.0217, lr=2e-6, vram=7.4/7.7GB]#015Steps:  91%|█████████▏| 914/1000 [1:37:48<06:43,  4.69s/it, loss=0.0301, lr=2e-6, vram=7.4/7.7GB]#015Steps:  92%|█████████▏| 915/1000 [1:37:48<05:03,  3.57s/it, loss=0.0301, lr=2e-6, vram=7.4/7.7GB]#015Steps:  92%|█████████▏| 916/1000 [1:37:49<03:54,  2.79s/it, loss=0.0301, lr=2e-6, vram=7.4/7.7GB]#015Steps:  92%|█████████▏| 916/1000 [1:37:50<03:54,  2.79s/it, loss=0.177, lr=2e-6, vram=7.4/7.7GB] #015Steps:  92%|█████████▏| 917/1000 [1:37:50<03:06,  2.25s/it, loss=0.177, lr=2e-6, vram=7.4/7.7GB]#015Steps:  92%|█████████▏| 918/1000 [1:37:51<02:32,  1.85s/it, loss=0.177, lr=2e-6, vram=7.4/7.7GB]\u001b[0m\n",
      "\u001b[34m#015Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]#033[A#015Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 157286.40it/s]\u001b[0m\n",
      "\u001b[34mmanul_upload_model_path is s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\u001b[0m\n",
      "\u001b[34m#015Steps:  92%|█████████▏| 918/1000 [1:38:41<02:32,  1.85s/it, loss=0.0461, lr=2e-6, vram=7.4/7.7GB]#015Steps:  92%|█████████▏| 919/1000 [1:38:41<21:48, 16.16s/it, loss=0.0461, lr=2e-6, vram=7.4/7.7GB]#015Steps:  92%|█████████▏| 920/1000 [1:38:41<15:27, 11.59s/it, loss=0.0461, lr=2e-6, vram=7.4/7.7GB]#015Steps:  92%|█████████▏| 920/1000 [1:38:42<15:27, 11.59s/it, loss=0.236, lr=2e-6, vram=7.4/7.7GB] #015Steps:  92%|█████████▏| 921/1000 [1:38:42<11:04,  8.41s/it, loss=0.236, lr=2e-6, vram=7.4/7.7GB]#015Steps:  92%|█████████▏| 922/1000 [1:38:43<08:01,  6.17s/it, loss=0.236, lr=2e-6, vram=7.4/7.7GB]#015Steps:  92%|█████████▏| 922/1000 [1:38:44<08:01,  6.17s/it, loss=0.18, lr=2e-6, vram=7.4/7.7GB] #015Steps:  92%|█████████▏| 923/1000 [1:38:44<05:54,  4.61s/it, loss=0.18, lr=2e-6, vram=7.4/7.7GB]#015Steps:  92%|█████████▏| 924/1000 [1:38:45<04:26,  3.51s/it, loss=0.18, lr=2e-6, vram=7.4/7.7GB]#015Steps:  92%|█████████▏| 924/1000 [1:38:46<04:26,  3.51s/it, loss=0.108, lr=2e-6, vram=7.4/7.7GB]#015Steps:  92%|█████████▎| 925/1000 [1:38:46<03:25,  2.74s/it, loss=0.108, lr=2e-6, vram=7.4/7.7GB]#015Steps:  93%|█████████▎| 926/1000 [1:38:47<02:43,  2.21s/it, loss=0.108, lr=2e-6, vram=7.4/7.7GB]#015Steps:  93%|█████████▎| 926/1000 [1:38:48<02:43,  2.21s/it, loss=0.0398, lr=2e-6, vram=7.4/7.7GB]#015Steps:  93%|█████████▎| 927/1000 [1:38:48<02:13,  1.83s/it, loss=0.0398, lr=2e-6, vram=7.4/7.7GB]\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/model_index.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/model_index.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsfeature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsscheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsloggingdreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelslogging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/feature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/scheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/config.json\u001b[0m\n",
      "\u001b[34m#015Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]#033[A#015Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 172368.66it/s]\u001b[0m\n",
      "\u001b[34mmanul_upload_model_path is s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/model_index.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/model_index.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsfeature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsscheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsloggingdreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelslogging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/feature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/scheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/config.json\u001b[0m\n",
      "\u001b[34m#015Steps:  93%|█████████▎| 928/1000 [1:39:39<19:46, 16.48s/it, loss=0.0398, lr=2e-6, vram=7.4/7.7GB]#015Steps:  93%|█████████▎| 928/1000 [1:39:40<19:46, 16.48s/it, loss=0.0333, lr=2e-6, vram=7.4/7.7GB]#015Steps:  93%|█████████▎| 929/1000 [1:39:40<13:59, 11.82s/it, loss=0.0333, lr=2e-6, vram=7.4/7.7GB]#015Steps:  93%|█████████▎| 930/1000 [1:39:41<09:59,  8.56s/it, loss=0.0333, lr=2e-6, vram=7.4/7.7GB]#015Steps:  93%|█████████▎| 930/1000 [1:39:42<09:59,  8.56s/it, loss=0.101, lr=2e-6, vram=7.4/7.7GB] #015Steps:  93%|█████████▎| 931/1000 [1:39:42<07:13,  6.28s/it, loss=0.101, lr=2e-6, vram=7.4/7.7GB]#015Steps:  93%|█████████▎| 932/1000 [1:39:43<05:18,  4.69s/it, loss=0.101, lr=2e-6, vram=7.4/7.7GB]#015Steps:  93%|█████████▎| 932/1000 [1:39:44<05:18,  4.69s/it, loss=0.121, lr=2e-6, vram=7.4/7.7GB]#015Steps:  93%|█████████▎| 933/1000 [1:39:44<03:58,  3.56s/it, loss=0.121, lr=2e-6, vram=7.4/7.7GB]#015Steps:  93%|█████████▎| 934/1000 [1:39:45<03:03,  2.78s/it, loss=0.121, lr=2e-6, vram=7.4/7.7GB]#015Steps:  93%|█████████▎| 934/1000 [1:39:46<03:03,  2.78s/it, loss=0.18, lr=2e-6, vram=7.4/7.7GB] #015Steps:  94%|█████████▎| 935/1000 [1:39:46<02:25,  2.23s/it, loss=0.18, lr=2e-6, vram=7.4/7.7GB]#015Steps:  94%|█████████▎| 936/1000 [1:39:46<01:58,  1.85s/it, loss=0.18, lr=2e-6, vram=7.4/7.7GB]\u001b[0m\n",
      "\u001b[34m#015Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]#033[A#015Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 168220.75it/s]\u001b[0m\n",
      "\u001b[34mmanul_upload_model_path is s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/model_index.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/model_index.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsfeature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsscheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsloggingdreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelslogging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m#015Steps:  94%|█████████▎| 936/1000 [1:40:37<01:58,  1.85s/it, loss=0.0649, lr=2e-6, vram=7.4/7.7GB]#015Steps:  94%|█████████▎| 937/1000 [1:40:37<17:16, 16.45s/it, loss=0.0649, lr=2e-6, vram=7.4/7.7GB]#015Steps:  94%|█████████▍| 938/1000 [1:40:38<12:11, 11.81s/it, loss=0.0649, lr=2e-6, vram=7.4/7.7GB]#015Steps:  94%|█████████▍| 938/1000 [1:40:39<12:11, 11.81s/it, loss=0.13, lr=2e-6, vram=7.4/7.7GB]  #015Steps:  94%|█████████▍| 939/1000 [1:40:39<08:41,  8.55s/it, loss=0.13, lr=2e-6, vram=7.4/7.7GB]#015Steps:  94%|█████████▍| 940/1000 [1:40:40<06:16,  6.27s/it, loss=0.13, lr=2e-6, vram=7.4/7.7GB]#015Steps:  94%|█████████▍| 940/1000 [1:40:41<06:16,  6.27s/it, loss=0.158, lr=2e-6, vram=7.4/7.7GB]#015Steps:  94%|█████████▍| 941/1000 [1:40:41<04:36,  4.68s/it, loss=0.158, lr=2e-6, vram=7.4/7.7GB]#015Steps:  94%|█████████▍| 942/1000 [1:40:42<03:26,  3.56s/it, loss=0.158, lr=2e-6, vram=7.4/7.7GB]#015Steps:  94%|█████████▍| 942/1000 [1:40:43<03:26,  3.56s/it, loss=0.145, lr=2e-6, vram=7.4/7.7GB]#015Steps:  94%|█████████▍| 943/1000 [1:40:43<02:38,  2.78s/it, loss=0.145, lr=2e-6, vram=7.4/7.7GB]#015Steps:  94%|█████████▍| 944/1000 [1:40:44<02:04,  2.23s/it, loss=0.145, lr=2e-6, vram=7.4/7.7GB]#015Steps:  94%|█████████▍| 944/1000 [1:40:45<02:04,  2.23s/it, loss=0.225, lr=2e-6, vram=7.4/7.7GB]#015Steps:  94%|█████████▍| 945/1000 [1:40:45<01:41,  1.84s/it, loss=0.225, lr=2e-6, vram=7.4/7.7GB]\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/feature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/scheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/config.json\u001b[0m\n",
      "\u001b[34m#015Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]#033[A#015Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 180788.97it/s]\u001b[0m\n",
      "\u001b[34mmanul_upload_model_path is s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/model_index.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/model_index.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsfeature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsscheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsloggingdreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelslogging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/feature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/scheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/config.json\u001b[0m\n",
      "\u001b[34m#015Steps:  95%|█████████▍| 946/1000 [1:41:39<15:49, 17.58s/it, loss=0.225, lr=2e-6, vram=7.4/7.7GB]#015Steps:  95%|█████████▍| 946/1000 [1:41:40<15:49, 17.58s/it, loss=0.1, lr=2e-6, vram=7.4/7.7GB]  #015Steps:  95%|█████████▍| 947/1000 [1:41:40<11:07, 12.59s/it, loss=0.1, lr=2e-6, vram=7.4/7.7GB]#015Steps:  95%|█████████▍| 948/1000 [1:41:41<07:53,  9.10s/it, loss=0.1, lr=2e-6, vram=7.4/7.7GB]#015Steps:  95%|█████████▍| 948/1000 [1:41:42<07:53,  9.10s/it, loss=0.0512, lr=2e-6, vram=7.4/7.7GB]#015Steps:  95%|█████████▍| 949/1000 [1:41:42<05:39,  6.66s/it, loss=0.0512, lr=2e-6, vram=7.4/7.7GB]#015Steps:  95%|█████████▌| 950/1000 [1:41:43<04:07,  4.94s/it, loss=0.0512, lr=2e-6, vram=7.4/7.7GB]#015Steps:  95%|█████████▌| 950/1000 [1:41:44<04:07,  4.94s/it, loss=0.379, lr=2e-6, vram=7.4/7.7GB] #015Steps:  95%|█████████▌| 951/1000 [1:41:44<03:03,  3.75s/it, loss=0.379, lr=2e-6, vram=7.4/7.7GB]#015Steps:  95%|█████████▌| 952/1000 [1:41:45<02:19,  2.91s/it, loss=0.379, lr=2e-6, vram=7.4/7.7GB]#015Steps:  95%|█████████▌| 952/1000 [1:41:46<02:19,  2.91s/it, loss=0.105, lr=2e-6, vram=7.4/7.7GB]#015Steps:  95%|█████████▌| 953/1000 [1:41:46<01:49,  2.33s/it, loss=0.105, lr=2e-6, vram=7.4/7.7GB]#015Steps:  95%|█████████▌| 954/1000 [1:41:47<01:27,  1.91s/it, loss=0.105, lr=2e-6, vram=7.4/7.7GB]\u001b[0m\n",
      "\u001b[34m#015Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]#033[A#015Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 116724.60it/s]\u001b[0m\n",
      "\u001b[34mmanul_upload_model_path is s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\u001b[0m\n",
      "\u001b[34m#015Steps:  95%|█████████▌| 954/1000 [1:42:38<01:27,  1.91s/it, loss=0.0859, lr=2e-6, vram=7.4/7.7GB]#015Steps:  96%|█████████▌| 955/1000 [1:42:38<12:35, 16.79s/it, loss=0.0859, lr=2e-6, vram=7.4/7.7GB]#015Steps:  96%|█████████▌| 956/1000 [1:42:39<08:49, 12.04s/it, loss=0.0859, lr=2e-6, vram=7.4/7.7GB]#015Steps:  96%|█████████▌| 956/1000 [1:42:40<08:49, 12.04s/it, loss=0.143, lr=2e-6, vram=7.4/7.7GB] #015Steps:  96%|█████████▌| 957/1000 [1:42:40<06:14,  8.71s/it, loss=0.143, lr=2e-6, vram=7.4/7.7GB]#015Steps:  96%|█████████▌| 958/1000 [1:42:41<04:28,  6.39s/it, loss=0.143, lr=2e-6, vram=7.4/7.7GB]#015Steps:  96%|█████████▌| 958/1000 [1:42:42<04:28,  6.39s/it, loss=0.0624, lr=2e-6, vram=7.4/7.7GB]#015Steps:  96%|█████████▌| 959/1000 [1:42:42<03:15,  4.76s/it, loss=0.0624, lr=2e-6, vram=7.4/7.7GB]#015Steps:  96%|█████████▌| 960/1000 [1:42:43<02:24,  3.62s/it, loss=0.0624, lr=2e-6, vram=7.4/7.7GB]#015Steps:  96%|█████████▌| 960/1000 [1:42:44<02:24,  3.62s/it, loss=0.158, lr=2e-6, vram=7.4/7.7GB] #015Steps:  96%|█████████▌| 961/1000 [1:42:44<01:49,  2.82s/it, loss=0.158, lr=2e-6, vram=7.4/7.7GB]#015Steps:  96%|█████████▌| 962/1000 [1:42:45<01:25,  2.26s/it, loss=0.158, lr=2e-6, vram=7.4/7.7GB]#015Steps:  96%|█████████▌| 962/1000 [1:42:46<01:25,  2.26s/it, loss=0.0236, lr=2e-6, vram=7.4/7.7GB]#015Steps:  96%|█████████▋| 963/1000 [1:42:46<01:09,  1.87s/it, loss=0.0236, lr=2e-6, vram=7.4/7.7GB]\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/model_index.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/model_index.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsfeature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsscheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsloggingdreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelslogging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/feature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/scheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/config.json\u001b[0m\n",
      "\u001b[34m#015Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]#033[A#015Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 94608.36it/s]\u001b[0m\n",
      "\u001b[34mmanul_upload_model_path is s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\u001b[0m\n",
      "\u001b[34m#015Steps:  96%|█████████▋| 964/1000 [1:43:39<10:22, 17.30s/it, loss=0.0236, lr=2e-6, vram=7.4/7.7GB]#015Steps:  96%|█████████▋| 964/1000 [1:43:40<10:22, 17.30s/it, loss=0.334, lr=2e-6, vram=7.4/7.7GB] #015Steps:  96%|█████████▋| 965/1000 [1:43:40<07:13, 12.40s/it, loss=0.334, lr=2e-6, vram=7.4/7.7GB]#015Steps:  97%|█████████▋| 966/1000 [1:43:41<05:04,  8.96s/it, loss=0.334, lr=2e-6, vram=7.4/7.7GB]#015Steps:  97%|█████████▋| 966/1000 [1:43:42<05:04,  8.96s/it, loss=0.0693, lr=2e-6, vram=7.4/7.7GB]#015Steps:  97%|█████████▋| 967/1000 [1:43:42<03:36,  6.56s/it, loss=0.0693, lr=2e-6, vram=7.4/7.7GB]#015Steps:  97%|█████████▋| 968/1000 [1:43:43<02:36,  4.88s/it, loss=0.0693, lr=2e-6, vram=7.4/7.7GB]#015Steps:  97%|█████████▋| 968/1000 [1:43:44<02:36,  4.88s/it, loss=0.094, lr=2e-6, vram=7.4/7.7GB] #015Steps:  97%|█████████▋| 969/1000 [1:43:44<01:54,  3.70s/it, loss=0.094, lr=2e-6, vram=7.4/7.7GB]#015Steps:  97%|█████████▋| 970/1000 [1:43:45<01:26,  2.88s/it, loss=0.094, lr=2e-6, vram=7.4/7.7GB]#015Steps:  97%|█████████▋| 970/1000 [1:43:46<01:26,  2.88s/it, loss=0.0804, lr=2e-6, vram=7.4/7.7GB]#015Steps:  97%|█████████▋| 971/1000 [1:43:46<01:06,  2.30s/it, loss=0.0804, lr=2e-6, vram=7.4/7.7GB]#015Steps:  97%|█████████▋| 972/1000 [1:43:47<00:53,  1.89s/it, loss=0.0804, lr=2e-6, vram=7.4/7.7GB]\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/model_index.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/model_index.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsfeature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsscheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsloggingdreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelslogging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/feature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/scheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/config.json\u001b[0m\n",
      "\u001b[34m#015Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]#033[A#015Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 46637.92it/s]\u001b[0m\n",
      "\u001b[34mmanul_upload_model_path is s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/model_index.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/model_index.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsfeature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsscheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsloggingdreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelslogging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34m#015Steps:  97%|█████████▋| 972/1000 [1:44:43<00:53,  1.89s/it, loss=0.0703, lr=2e-6, vram=7.4/7.7GB]#015Steps:  97%|█████████▋| 973/1000 [1:44:43<08:09, 18.11s/it, loss=0.0703, lr=2e-6, vram=7.4/7.7GB]#015Steps:  97%|█████████▋| 974/1000 [1:44:44<05:37, 12.96s/it, loss=0.0703, lr=2e-6, vram=7.4/7.7GB]#015Steps:  97%|█████████▋| 974/1000 [1:44:45<05:37, 12.96s/it, loss=0.101, lr=2e-6, vram=7.4/7.7GB] #015Steps:  98%|█████████▊| 975/1000 [1:44:45<03:54,  9.36s/it, loss=0.101, lr=2e-6, vram=7.4/7.7GB]#015Steps:  98%|█████████▊| 976/1000 [1:44:45<02:44,  6.84s/it, loss=0.101, lr=2e-6, vram=7.4/7.7GB]#015Steps:  98%|█████████▊| 976/1000 [1:44:46<02:44,  6.84s/it, loss=0.108, lr=2e-6, vram=7.4/7.7GB]#015Steps:  98%|█████████▊| 977/1000 [1:44:46<01:56,  5.08s/it, loss=0.108, lr=2e-6, vram=7.4/7.7GB]#015Steps:  98%|█████████▊| 978/1000 [1:44:47<01:24,  3.84s/it, loss=0.108, lr=2e-6, vram=7.4/7.7GB]#015Steps:  98%|█████████▊| 978/1000 [1:44:48<01:24,  3.84s/it, loss=0.274, lr=2e-6, vram=7.4/7.7GB]#015Steps:  98%|█████████▊| 979/1000 [1:44:48<01:02,  2.98s/it, loss=0.274, lr=2e-6, vram=7.4/7.7GB]#015Steps:  98%|█████████▊| 980/1000 [1:44:49<00:47,  2.37s/it, loss=0.274, lr=2e-6, vram=7.4/7.7GB]#015Steps:  98%|█████████▊| 980/1000 [1:44:50<00:47,  2.37s/it, loss=0.113, lr=2e-6, vram=7.4/7.7GB]#015Steps:  98%|█████████▊| 981/1000 [1:44:50<00:36,  1.94s/it, loss=0.113, lr=2e-6, vram=7.4/7.7GB]\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/feature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/scheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/config.json\u001b[0m\n",
      "\u001b[34m#015Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]#033[A#015Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 116508.44it/s]\u001b[0m\n",
      "\u001b[34mmanul_upload_model_path is s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/model_index.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/model_index.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsfeature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsscheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsloggingdreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelslogging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34m#015Steps:  98%|█████████▊| 982/1000 [1:45:45<05:17, 17.65s/it, loss=0.113, lr=2e-6, vram=7.4/7.7GB]#015Steps:  98%|█████████▊| 982/1000 [1:45:46<05:17, 17.65s/it, loss=0.305, lr=2e-6, vram=7.4/7.7GB]#015Steps:  98%|█████████▊| 983/1000 [1:45:46<03:34, 12.64s/it, loss=0.305, lr=2e-6, vram=7.4/7.7GB]#015Steps:  98%|█████████▊| 984/1000 [1:45:46<02:26,  9.14s/it, loss=0.305, lr=2e-6, vram=7.4/7.7GB]#015Steps:  98%|█████████▊| 984/1000 [1:45:47<02:26,  9.14s/it, loss=0.0108, lr=2e-6, vram=7.4/7.7GB]#015Steps:  98%|█████████▊| 985/1000 [1:45:47<01:40,  6.68s/it, loss=0.0108, lr=2e-6, vram=7.4/7.7GB]#015Steps:  99%|█████████▊| 986/1000 [1:45:48<01:09,  4.96s/it, loss=0.0108, lr=2e-6, vram=7.4/7.7GB]#015Steps:  99%|█████████▊| 986/1000 [1:45:49<01:09,  4.96s/it, loss=0.0568, lr=2e-6, vram=7.4/7.7GB]#015Steps:  99%|█████████▊| 987/1000 [1:45:49<00:48,  3.76s/it, loss=0.0568, lr=2e-6, vram=7.4/7.7GB]#015Steps:  99%|█████████▉| 988/1000 [1:45:50<00:35,  2.92s/it, loss=0.0568, lr=2e-6, vram=7.4/7.7GB]#015Steps:  99%|█████████▉| 988/1000 [1:45:51<00:35,  2.92s/it, loss=0.405, lr=2e-6, vram=7.4/7.7GB] #015Steps:  99%|█████████▉| 989/1000 [1:45:51<00:25,  2.34s/it, loss=0.405, lr=2e-6, vram=7.4/7.7GB]#015Steps:  99%|█████████▉| 990/1000 [1:45:52<00:19,  1.92s/it, loss=0.405, lr=2e-6, vram=7.4/7.7GB]\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/feature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/scheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/config.json\u001b[0m\n",
      "\u001b[34m#015Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]#033[A#015Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 110376.42it/s]\u001b[0m\n",
      "\u001b[34mmanul_upload_model_path is s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/model_index.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/model_index.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsfeature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsscheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsloggingdreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelslogging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/config.json\u001b[0m\n",
      "\u001b[34m#015Steps:  99%|█████████▉| 990/1000 [1:46:44<00:19,  1.92s/it, loss=0.0361, lr=2e-6, vram=7.4/7.7GB]#015Steps:  99%|█████████▉| 991/1000 [1:46:44<02:32, 16.89s/it, loss=0.0361, lr=2e-6, vram=7.4/7.7GB]#015Steps:  99%|█████████▉| 992/1000 [1:46:45<01:36, 12.11s/it, loss=0.0361, lr=2e-6, vram=7.4/7.7GB]#015Steps:  99%|█████████▉| 992/1000 [1:46:46<01:36, 12.11s/it, loss=0.015, lr=2e-6, vram=7.4/7.7GB] #015Steps:  99%|█████████▉| 993/1000 [1:46:46<01:01,  8.76s/it, loss=0.015, lr=2e-6, vram=7.4/7.7GB]#015Steps:  99%|█████████▉| 994/1000 [1:46:47<00:38,  6.42s/it, loss=0.015, lr=2e-6, vram=7.4/7.7GB]#015Steps:  99%|█████████▉| 994/1000 [1:46:48<00:38,  6.42s/it, loss=0.242, lr=2e-6, vram=7.4/7.7GB]#015Steps: 100%|█████████▉| 995/1000 [1:46:48<00:23,  4.78s/it, loss=0.242, lr=2e-6, vram=7.4/7.7GB]#015Steps: 100%|█████████▉| 996/1000 [1:46:49<00:14,  3.64s/it, loss=0.242, lr=2e-6, vram=7.4/7.7GB]#015Steps: 100%|█████████▉| 996/1000 [1:46:50<00:14,  3.64s/it, loss=0.114, lr=2e-6, vram=7.4/7.7GB]#015Steps: 100%|█████████▉| 997/1000 [1:46:50<00:08,  2.83s/it, loss=0.114, lr=2e-6, vram=7.4/7.7GB]#015Steps: 100%|█████████▉| 998/1000 [1:46:51<00:04,  2.27s/it, loss=0.114, lr=2e-6, vram=7.4/7.7GB]#015Steps: 100%|█████████▉| 998/1000 [1:46:52<00:04,  2.27s/it, loss=0.141, lr=2e-6, vram=7.4/7.7GB]#015Steps: 100%|█████████▉| 999/1000 [1:46:52<00:01,  1.87s/it, loss=0.141, lr=2e-6, vram=7.4/7.7GB]\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/feature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/scheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/config.json\u001b[0m\n",
      "\u001b[34m#015Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]#033[A#015Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 170963.48it/s]\u001b[0m\n",
      "\u001b[34mmanul_upload_model_path is s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/model_index.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/model_index.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsfeature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsscheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsloggingdreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelslogging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/feature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/scheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/config.json\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\u001b[34m#015Steps: 100%|██████████| 1000/1000 [1:47:44<00:00, 16.89s/it, loss=0.141, lr=2e-6, vram=7.4/7.7GB]#015Steps: 100%|██████████| 1000/1000 [1:47:45<00:00, 16.89s/it, loss=0.303, lr=2e-6, vram=7.4/7.7GB]\u001b[0m\n",
      "\u001b[34m#015Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]#033[A#015Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 173318.35it/s]\u001b[0m\n",
      "\u001b[34m#015Steps: 100%|██████████| 1000/1000 [1:48:36<00:00,  6.52s/it, loss=0.303, lr=2e-6, vram=7.4/7.7GB]\u001b[0m\n",
      "\u001b[34mmanul_upload_model_path is s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/model_index.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/model_index.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsfeature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsscheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsunet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsloggingdreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelslogging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelsvae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model//text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_modelstext_encoder/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/feature_extractor/preprocessor_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/feature_extractor/preprocessor_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/scheduler/scheduler_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/scheduler/scheduler_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/unet/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/unet/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0 uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/logging/dreambooth/events.out.tfevents.1682415452.ip-10-0-221-0.us-west-2.compute.internal.20.0\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/merges.txt uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/merges.txt\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/vocab.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/vocab.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/tokenizer_config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/tokenizer/special_tokens_map.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/tokenizer/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/diffusion_pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/diffusion_pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/vae/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/vae/config.json\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/pytorch_model.bin uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mFile /opt/ml/model/text_encoder/config.json uploaded to s3://sagemaker-us-west-2-687912291502/dreambooth/trained_models/text_encoder/config.json\n",
      " CLEANUP:  \n",
      " Allocated: 7.4GB \n",
      " Reserved: 10.8GB \n",
      " Cleanup completed. \n",
      " Allocated: 7.4GB \n",
      " Reserved: 7.7GB \n",
      " Cleanup Complete. \n",
      " Allocated: 7.4GB \n",
      " Reserved: 7.7GB \n",
      " Training completed, total steps: 1000 \n",
      " Allocated: 7.4GB \n",
      " Reserved: 7.7GB \u001b[0m\n",
      "\u001b[34m2023-04-25 11:26:09,786 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-04-25 11:26:14 Uploading - Uploading generated training model\n",
      "2023-04-25 11:55:27 Completed - Training job completed\n",
      "Training seconds: 8683\n",
      "Billable seconds: 8683\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def json_encode_hyperparameters(hyperparameters):\n",
    "    for (k, v) in hyperparameters.items():\n",
    "        print(k, v)\n",
    "    \n",
    "    return {k: json.dumps(v) for (k, v) in hyperparameters.items()}\n",
    "\n",
    "\n",
    "\n",
    "image_uri = '{}.dkr.ecr.{}.amazonaws.com/dreambooth-finetuning-v3:latest'.format(account_id,region_name)\n",
    "instance_type = 'ml.g4dn.4xlarge'\n",
    "\n",
    "instance_prompt=\"Erwin\\ Rommel\"\n",
    "prior_preservation_class_prompt=\"a\\ photo\\ of\\ Erwin\\ Rommel\"\n",
    "s3_model_output_location='s3://{}/{}/{}'.format(bucket, 'dreambooth', 'trained_models')\n",
    "#model_name=\"CompVis/stable-diffusion-v1-4\"\n",
    "model_name=\"runwayml/stable-diffusion-v1-5\"\n",
    "#model_name=\"stabilityai/stable-diffusion-2\"\n",
    "instance_dir=\"/opt/ml/input/data/images/\"\n",
    "class_dir=\"/opt/ml/input/data/images/\"\n",
    "\n",
    "\n",
    "\n",
    "environment = {\n",
    "    'PYTORCH_CUDA_ALLOC_CONF':'max_split_size_mb:32',\n",
    "    'LD_LIBRARY_PATH':\"${LD_LIBRARY_PATH}:/opt/conda/lib/\"\n",
    "}\n",
    "\n",
    "hyperparameters = {\n",
    "                    'model_name':'aws-trained-dreambooth-model',\n",
    "                    'mixed_precision':'fp16',\n",
    "                    'pretrained_model_name_or_path': model_name, \n",
    "                    'instance_data_dir':instance_dir,\n",
    "                    'class_data_dir':class_dir,\n",
    "                    'with_prior_preservation':True,\n",
    "                    'models_path': '/tmp/',\n",
    "                    #'models_path': '/opt/ml/output/',\n",
    "                    'manul_upload_model_path':s3_model_output_location,\n",
    "                    'instance_prompt': instance_prompt, \n",
    "                    'class_prompt':prior_preservation_class_prompt,\n",
    "                    'resolution':512,\n",
    "                    'train_batch_size':1,\n",
    "                    'sample_batch_size': 1,\n",
    "                    'gradient_accumulation_steps':1,\n",
    "                    'learning_rate':2e-06,\n",
    "                    'lr_scheduler':'constant',\n",
    "                    'lr_warmup_steps':1000,\n",
    "                    'num_class_images':0,\n",
    "                    'max_train_steps':1000,\n",
    "                    'save_steps':1000,\n",
    "                    #'attention':'flash_attention',\n",
    "                    'attention':'xformers',\n",
    "                    'prior_loss_weight': 0.5,\n",
    "                    'use_ema':True,\n",
    "                    'train_text_encoder':False,\n",
    "                    'not_cache_latents':True,\n",
    "                    'gradient_checkpointing':True,\n",
    "                    'save_use_epochs': False,\n",
    "                    'use_8bit_adam': False\n",
    "}\n",
    "\n",
    "hyperparameters = json_encode_hyperparameters(hyperparameters)\n",
    "\n",
    "from sagemaker.estimator import Estimator\n",
    "inputs = {\n",
    "    'images': images_s3uri\n",
    "}\n",
    "\n",
    "estimator = Estimator(\n",
    "    role = role,\n",
    "    instance_count=1,\n",
    "    instance_type = instance_type,\n",
    "    image_uri = image_uri,\n",
    "    hyperparameters = hyperparameters,\n",
    "    environment = environment\n",
    ")\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd181b4e-f435-4dca-842a-444d083fdf3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model artifact saved at:\n",
      " s3://sagemaker-us-west-2-687912291502/dreambooth-finetuning-v3-2023-04-25-09-29-43-398/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "dreambooth_model_data = estimator.model_data\n",
    "print(\"Model artifact saved at:\\n\", dreambooth_model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b90beb-3b46-479d-a933-9540b0723331",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 ls s3://sagemaker-ap-southeast-1-687912291502/stable-diffusion/dreambooth/aws-db-new-model/working/unet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7279d922-766c-4a71-8ed4-363467c9c817",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
