{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0e92bd0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### controlnet 模型微调\n",
    "controlnet模型使得用户可以通过施加额外条件，细粒度地控制扩散模型的生成过程。这一技术最初由 Adding Conditional Control to Text-to-Image Diffusion Models 这篇论文提出，并很快地风靡了扩散模型的开源社区。作者开源了 8 个不同的模型，使得用户可以用 8 种条件去控制 Stable Diffusion 模型（包括版本 1 到 5 ）。这 8 种条件包括姿态估计、深度图、边缘图、素描图。\n",
    "\n",
    "接下来我们将使用 controlnet 来微调我们的 stable diffusion xl模型.\n",
    "\n",
    "#### Notebook 步骤\n",
    "1. 导入 boto3, sagemaker python SDK\n",
    "2. 构建 controlnet fine-tuning 镜像\n",
    "3. 实现模型微调\n",
    "   * 配置超参\n",
    "   * 创建训练任务\n",
    "4. 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9eb077",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1. 导入 boto3, sagemaker python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8314fc9b-c468-497b-abcc-259ec792154c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.pytorch import PyTorch\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region_name = boto3.session.Session().region_name\n",
    "\n",
    "images_s3uri = 's3://{0}/controlnet-xl/images/'.format(bucket)\n",
    "models_s3uri = 's3://{0}/stable-diffusion/models/'.format(bucket)\n",
    "controlnet_s3uri = 's3://{0}/stable-diffusion/controlnet/'.format(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a3178",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 2. 构建 controlnet xl fine-tuning 镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15c49cae-3336-4e34-aefd-c53e396f7b04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'diffusers'...\n",
      "remote: Enumerating objects: 48706, done.\u001b[K\n",
      "remote: Counting objects: 100% (2239/2239), done.\u001b[K\n",
      "remote: Compressing objects: 100% (834/834), done.\u001b[K\n",
      "remote: Total 48706 (delta 1586), reused 1790 (delta 1257), pack-reused 46467\u001b[K\n",
      "Receiving objects: 100% (48706/48706), 31.37 MiB | 34.57 MiB/s, done.\n",
      "Resolving deltas: 100% (35863/35863), done.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf sd_controlnet\n",
    "!mkdir -p sd_controlnet\n",
    "!cd sd_controlnet && git clone https://github.com/huggingface/diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adce074-4777-4847-8977-902645e3fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L https://github.com/peak/s5cmd/releases/download/v2.2.2/s5cmd_2.2.2_Linux-64bit.tar.gz | tar -xz && mv s5cmd sd_controlnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7612e5a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile_controlnet\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile_controlnet\n",
    "## You should change below region code to the region you used, here sample is use us-west-2\n",
    "#From 763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-training:1.13.1-transformers4.26.0-gpu-py39-cu117-ubuntu20.04\n",
    "From 763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04\n",
    "\n",
    "RUN pip install wandb\n",
    "#RUN pip install xformers==0.0.19 --no-deps\n",
    "RUN pip install xformers\n",
    "RUN pip install bitsandbytes\n",
    "#RUN export TORCH_CUDA_ARCH_LIST=\"7.5 8.0 8.6\" && export FORCE_CUDA=\"1\" && pip install ninja triton==2.0.0.dev20221120 && git clone https://github.com/xieyongliang/xformers.git /tmp/xformers && cd /tmp/xformers && git submodule update --init --recursive && pip install -r requirements.txt && pip install -e . \n",
    "\n",
    "\n",
    "ENV LANG=C.UTF-8\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "ENV PYTHONDONTWRITEBYTECODE=TRUE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d70d510-caf7-4b48-95d4-f9bc2eaa0648",
   "metadata": {},
   "source": [
    "* build & push docker镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f573e3c1-5e49-43cd-b71b-c858547192c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "## You should change below region code to the region you used, here sample is use us-west-2\n",
    "!aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-west-2.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a69253dd-850f-41b7-b57a-437273648a46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## define repo name, should contain *sagemaker* in the name\n",
    "repo_name = \"sd_controlnet_finetuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20a370fa-bdf7-47a6-892d-f05adcf5904c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon    132MB\n",
      "Step 1/7 : From 763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-training:2.0.0-transformers4.28.1-gpu-py310-cu118-ubuntu20.04\n",
      " ---> 1f37d018af76\n",
      "Step 2/7 : RUN pip install wandb\n",
      " ---> Using cache\n",
      " ---> 38494bb19d4b\n",
      "Step 3/7 : RUN pip install xformers\n",
      " ---> Running in 415570f7d7f0\n",
      "Collecting xformers\n",
      "  Downloading xformers-0.0.22.post7-cp310-cp310-manylinux2014_x86_64.whl (211.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.8/211.8 MB 15.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xformers) (1.23.5)\n",
      "Collecting torch==2.1.0 (from xformers)\n",
      "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 670.2/670.2 MB 2.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.1.0->xformers) (2023.5.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.0->xformers)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.7/23.7 MB 73.0 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.0->xformers)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.6/823.6 kB 81.0 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.0->xformers)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.1/14.1 MB 111.2 MB/s eta 0:00:00\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.0->xformers)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 731.7/731.7 MB 3.4 MB/s eta 0:00:00\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.0->xformers)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 410.6/410.6 MB 8.0 MB/s eta 0:00:00\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.0->xformers)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.6/121.6 MB 25.1 MB/s eta 0:00:00\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.0->xformers)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.5/56.5 MB 47.3 MB/s eta 0:00:00\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.0->xformers)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.2/124.2 MB 25.4 MB/s eta 0:00:00\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.0->xformers)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 196.0/196.0 MB 16.4 MB/s eta 0:00:00\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0->xformers)\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.8/209.8 MB 14.9 MB/s eta 0:00:00\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.0->xformers)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 99.1/99.1 kB 21.5 MB/s eta 0:00:00\n",
      "Collecting triton==2.1.0 (from torch==2.1.0->xformers)\n",
      "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 89.2/89.2 MB 32.0 MB/s eta 0:00:00\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->xformers)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 20.5/20.5 MB 101.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.1.0->xformers) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.0->xformers) (1.3.0)\n",
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, xformers\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.0.0.dev20221202\n",
      "    Uninstalling triton-2.0.0.dev20221202:\n",
      "      Successfully uninstalled triton-2.0.0.dev20221202\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.0\n",
      "    Uninstalling torch-2.0.0:\n",
      "      Successfully uninstalled torch-2.0.0\n",
      "\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 2.7.12 requires torch<2.1,>=1.7, but you have torch 2.1.0 which is incompatible.\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 torch-2.1.0 triton-2.1.0 xformers-0.0.22.post7\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91m\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0mRemoving intermediate container 415570f7d7f0\n",
      " ---> 24a292294e4f\n",
      "Step 4/7 : RUN pip install bitsandbytes\n",
      " ---> Running in fc8d15232ab4\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.41.2.post2-py3-none-any.whl (92.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.6/92.6 MB 31.5 MB/s eta 0:00:00\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.41.2.post2\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91m\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0mRemoving intermediate container fc8d15232ab4\n",
      " ---> 7b434696c6fb\n",
      "Step 5/7 : ENV LANG=C.UTF-8\n",
      " ---> Running in 7817896f9968\n",
      "Removing intermediate container 7817896f9968\n",
      " ---> c880b262058b\n",
      "Step 6/7 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Running in fa48fa4d592e\n",
      "Removing intermediate container fa48fa4d592e\n",
      " ---> 2111f8ac8bb0\n",
      "Step 7/7 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Running in fe3d910021ce\n",
      "Removing intermediate container fe3d910021ce\n",
      " ---> ab66d9c83478\n",
      "Successfully built ab66d9c83478\n",
      "Successfully tagged sd_controlnet_finetuning:latest\n",
      "The push refers to repository [687912291502.dkr.ecr.us-west-2.amazonaws.com/sd_controlnet_finetuning]\n",
      "9ea5f675bf66: Preparing\n",
      "2821820dfbad: Preparing\n",
      "fe978fad9954: Preparing\n",
      "ff37c276152d: Preparing\n",
      "a5ad883d9d7f: Preparing\n",
      "8403b2741d40: Preparing\n",
      "b8b2f58f17fe: Preparing\n",
      "0a86d2f63da9: Preparing\n",
      "e9149126e47f: Preparing\n",
      "81bcaebf20b7: Preparing\n",
      "b89ba47ef264: Preparing\n",
      "5e365e6e2026: Preparing\n",
      "30f10d0e1e2a: Preparing\n",
      "de6ad3f5baf9: Preparing\n",
      "8995be0bc275: Preparing\n",
      "7649740a6938: Preparing\n",
      "138718a88769: Preparing\n",
      "4c8ddbfabe2c: Preparing\n",
      "e11d715889d8: Preparing\n",
      "b8b2f58f17fe: Waiting\n",
      "d2516bd9d454: Preparing\n",
      "0a86d2f63da9: Waiting\n",
      "e9149126e47f: Waiting\n",
      "ab91cb17a698: Preparing\n",
      "81bcaebf20b7: Waiting\n",
      "375dafba5be7: Preparing\n",
      "b89ba47ef264: Waiting\n",
      "eb2d5581a4b3: Preparing\n",
      "6e5ea4d3b078: Preparing\n",
      "a83e3f8647a8: Preparing\n",
      "8403b2741d40: Waiting\n",
      "de6ad3f5baf9: Waiting\n",
      "5e365e6e2026: Waiting\n",
      "30f10d0e1e2a: Waiting\n",
      "7649740a6938: Waiting\n",
      "629205717bfa: Preparing\n",
      "91962ccfdb56: Preparing\n",
      "8995be0bc275: Waiting\n",
      "138718a88769: Waiting\n",
      "e42093c82aca: Preparing\n",
      "88f627f04385: Preparing\n",
      "4c8ddbfabe2c: Waiting\n",
      "53d4ef0348b1: Preparing\n",
      "7dec9be1e6de: Preparing\n",
      "e11d715889d8: Waiting\n",
      "1c442bf32dda: Preparing\n",
      "d2516bd9d454: Waiting\n",
      "7a4317d0452c: Preparing\n",
      "569b5fc6f9ba: Preparing\n",
      "ab91cb17a698: Waiting\n",
      "375dafba5be7: Waiting\n",
      "16acfff66e41: Preparing\n",
      "eb2d5581a4b3: Waiting\n",
      "a83e3f8647a8: Waiting\n",
      "c2440becfb6e: Preparing\n",
      "6e5ea4d3b078: Waiting\n",
      "93dc2ad27ff8: Preparing\n",
      "91962ccfdb56: Waiting\n",
      "3b6112f80af1: Preparing\n",
      "e42093c82aca: Waiting\n",
      "88f627f04385: Waiting\n",
      "629205717bfa: Waiting\n",
      "1be54c625d9b: Preparing\n",
      "53d4ef0348b1: Waiting\n",
      "5d4d8e450a3a: Preparing\n",
      "aed2d71a436d: Preparing\n",
      "7af37e3e56a9: Preparing\n",
      "e5167e76bf1b: Preparing\n",
      "c2440becfb6e: Waiting\n",
      "1c442bf32dda: Waiting\n",
      "a490a70ab1cd: Preparing\n",
      "93dc2ad27ff8: Waiting\n",
      "b3c248c52364: Preparing\n",
      "7a4317d0452c: Waiting\n",
      "d543b8cad89e: Preparing\n",
      "569b5fc6f9ba: Waiting\n",
      "3b6112f80af1: Waiting\n",
      "16acfff66e41: Waiting\n",
      "e5167e76bf1b: Waiting\n",
      "a490a70ab1cd: Waiting\n",
      "b3c248c52364: Waiting\n",
      "aed2d71a436d: Waiting\n",
      "1be54c625d9b: Waiting\n",
      "d543b8cad89e: Waiting\n",
      "5d4d8e450a3a: Waiting\n",
      "fe978fad9954: Layer already exists\n",
      "ff37c276152d: Layer already exists\n",
      "a5ad883d9d7f: Layer already exists\n",
      "8403b2741d40: Layer already exists\n",
      "0a86d2f63da9: Layer already exists\n",
      "b8b2f58f17fe: Layer already exists\n",
      "e9149126e47f: Layer already exists\n",
      "81bcaebf20b7: Layer already exists\n",
      "b89ba47ef264: Layer already exists\n",
      "5e365e6e2026: Layer already exists\n",
      "30f10d0e1e2a: Layer already exists\n",
      "de6ad3f5baf9: Layer already exists\n",
      "8995be0bc275: Layer already exists\n",
      "7649740a6938: Layer already exists\n",
      "138718a88769: Layer already exists\n",
      "4c8ddbfabe2c: Layer already exists\n",
      "d2516bd9d454: Layer already exists\n",
      "e11d715889d8: Layer already exists\n",
      "ab91cb17a698: Layer already exists\n",
      "375dafba5be7: Layer already exists\n",
      "eb2d5581a4b3: Layer already exists\n",
      "6e5ea4d3b078: Layer already exists\n",
      "629205717bfa: Layer already exists\n",
      "a83e3f8647a8: Layer already exists\n",
      "91962ccfdb56: Layer already exists\n",
      "e42093c82aca: Layer already exists\n",
      "88f627f04385: Layer already exists\n",
      "53d4ef0348b1: Layer already exists\n",
      "7dec9be1e6de: Layer already exists\n",
      "1c442bf32dda: Layer already exists\n",
      "7a4317d0452c: Layer already exists\n",
      "569b5fc6f9ba: Layer already exists\n",
      "16acfff66e41: Layer already exists\n",
      "c2440becfb6e: Layer already exists\n",
      "93dc2ad27ff8: Layer already exists\n",
      "3b6112f80af1: Layer already exists\n",
      "1be54c625d9b: Layer already exists\n",
      "aed2d71a436d: Layer already exists\n",
      "5d4d8e450a3a: Layer already exists\n",
      "7af37e3e56a9: Layer already exists\n",
      "e5167e76bf1b: Layer already exists\n",
      "a490a70ab1cd: Layer already exists\n",
      "b3c248c52364: Layer already exists\n",
      "d543b8cad89e: Layer already exists\n",
      "9ea5f675bf66: Pushed\n",
      "2821820dfbad: Pushed\n",
      "latest: digest: sha256:02d1d1b67f5157f9d315312f53b5a3c1114b9cf559ec53be5bbd8a3fa00b90d7 size: 10005\n"
     ]
    }
   ],
   "source": [
    "%%script env repo_name=$repo_name bash\n",
    "\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "# This script shows how to build the Docker image and push it to ECR to be ready for use\n",
    "# by SageMaker.\n",
    "\n",
    "# The argument to this script is the image name. This will be used as the image on the local\n",
    "# machine and combined with the account and region to form the repository name for ECR.\n",
    "# The name of our algorithm\n",
    "algorithm_name=${repo_name}\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${algorithm_name} -f ./Dockerfile_controlnet .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d843895",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3. 模型微调\n",
    "\n",
    "   * image_uri: ecr仓库中的 docker 镜像地址\n",
    "   * instance_type: 用于训练任务的实例大小 , 建议使用 ml.g4dn.xlarge, ml.g5.xlarge\n",
    "   * class_prompt: 提示词类别\n",
    "   * instance_prompt: 用于你的图片的关键词\n",
    "   * model_name: 预训练的模型名称\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e2932d-e923-4ece-a510-c7d83829c5fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./sd_controlnet/train.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./sd_controlnet/train.sh\n",
    "bash ./train_controlnet_sdxl-h100.sh\n",
    "# Run this after 1st raise error\n",
    "pip uninstall torch torchvision\n",
    "pip install --pre torch torchvision --index-url https://download.pytorch.org/whl/nightly/cu118\n",
    "bash ./train_controlnet_sdxl-h100.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "720c66e8-8958-47f2-bfa7-c5252fde430e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./sd_controlnet/train_controlnet_sdxl.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./sd_controlnet/train_controlnet_sdxl.sh\n",
    "\n",
    "export WANDB_API_KEY=\"298b59ce8a416fd45b5fa9ffc17fe72327854e0c\"\n",
    "export WANDB_WATCH=\"all\"\n",
    "export WANDB_ENTITY=\"121102723\"\n",
    "export WANDB_PROJECT=\"controlnet\" \n",
    "\n",
    "mkdir -p /tmp/dog\n",
    "ls -lt ./\n",
    "chmod 777 ./s5cmd\n",
    "\n",
    "\n",
    "cd diffusers && pip install -e .\n",
    "cd examples/controlnet/ && pip install -r requirements_sdxl.txt\n",
    "\n",
    "curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash\n",
    "apt-get install git-lfs\n",
    "\n",
    "# Clone Train Dataset(for production)\n",
    "#git clone https://huggingface.co/datasets/zobnec/controlnet_fs_dataset_df /tmp/dataset/\n",
    "\n",
    "\n",
    "export MODEL_NAME=\"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "export INSTANCE_DIR=\"/tmp/dataset/\"\n",
    "export OUTPUT_DIR=\"/tmp/ouput\"\n",
    "export controlnet_s3uri=\"s3://sagemaker-us-west-2-687912291502/stable-diffusion/controlnet/\"\n",
    "\n",
    "wget https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/controlnet_training/conditioning_image_1.png\n",
    "wget https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/controlnet_training/conditioning_image_2.png\n",
    "\n",
    "accelerate launch train_controlnet_sdxl.py \\\n",
    " --pretrained_model_name_or_path=$MODEL_NAME \\\n",
    " --output_dir=$OUTPUT_DIR \\\n",
    " --dataset_name=\"fusing/fill50k\" \\\n",
    " --conditioning_image_column=conditioning_image \\\n",
    " --image_column=image \\\n",
    " --caption_column=text \\\n",
    " --resolution=512 \\\n",
    " --learning_rate=1e-5 \\\n",
    " --validation_image \"./conditioning_image_1.png\" \"./conditioning_image_2.png\"  \\\n",
    " --validation_prompt \"red circle with blue background\" \"cyan circle with brown floral background\" \\\n",
    " --train_batch_size=1 \\\n",
    " --max_train_steps=15000 \\\n",
    " --tracker_project_name=\"controlnet\" \\\n",
    " --checkpointing_steps=15000 \\\n",
    " --validation_steps=15000 \\\n",
    " --report_to=\"wandb\"  \\\n",
    " --enable_xformers_memory_efficient_attention \n",
    "\n",
    "\n",
    "/opt/ml/code/s5cmd sync /tmp/ouput/checkpoint-1000/controlnet/ $controlnet_s3uri/output/$(date +%Y-%m-%d-%H-%M-%S)/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4962e2a6-ff79-4129-8d63-6c86f28f0668",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./sd_controlnet/train_controlnet_sdxl_h100.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./sd_controlnet/train_controlnet_sdxl_h100.sh\n",
    "\n",
    "export WANDB_API_KEY=\"298b59ce8a416fd45b5fa9ffc17fe72327854e0c\"\n",
    "export WANDB_WATCH=\"all\"\n",
    "export WANDB_ENTITY=\"121102723\"\n",
    "export WANDB_PROJECT=\"controlnet\" \n",
    "\n",
    "mkdir -p /tmp/dog\n",
    "ls -lt ./\n",
    "chmod 777 ./s5cmd\n",
    "\n",
    "\n",
    "cd diffusers && pip install -e .\n",
    "cd examples/controlnet/ && pip install -r requirements_sdxl.txt\n",
    "\n",
    "curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash\n",
    "apt-get install git-lfs\n",
    "\n",
    "# Clone Train Dataset(for production)\n",
    "#git clone https://huggingface.co/datasets/zobnec/controlnet_fs_dataset_df /tmp/dataset/\n",
    "\n",
    "\n",
    "export MODEL_NAME=\"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "export INSTANCE_DIR=\"/tmp/dataset/\"\n",
    "export OUTPUT_DIR=\"/tmp/ouput\"\n",
    "export controlnet_s3uri=\"s3://sagemaker-us-west-2-687912291502/stable-diffusion/controlnet/\"\n",
    "\n",
    "\n",
    "accelerate launch train_controlnet_sdxl.py \\\n",
    " --pretrained_model_name_or_path=$MODEL_NAME \\\n",
    " --output_dir=$OUTPUT_DIR \\\n",
    " --dataset_name=multimodalart/facesyntheticsspigacaptioned \\\n",
    " --conditioning_image_column=spiga_seg \\\n",
    " --image_column=image \\\n",
    " --caption_column=image_caption \\\n",
    " --resolution=512 \\\n",
    " --learning_rate=1e-5 \\\n",
    " --train_batch_size=2 \\\n",
    " --max_train_steps=15000 \\\n",
    " --tracker_project_name=\"controlnet\" \\\n",
    " --checkpointing_steps=5000 \\\n",
    " --report_to=\"wandb\"  \\\n",
    " --enable_xformers_memory_efficient_attention \n",
    "\n",
    "\n",
    "/opt/ml/code/s5cmd sync /tmp/ouput/checkpoint-1000/controlnet/ $controlnet_s3uri/output/$(date +%Y-%m-%d-%H-%M-%S)/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c569c81",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "   * 创建训练任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6535d22c-ab12-48c4-9989-5fabe4f31f69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "\n",
    "environment = {\n",
    "    'PYTORCH_CUDA_ALLOC_CONF':'max_split_size_mb:32',\n",
    "    'MODEL_NAME':'stabilityai/stable-diffusion-2-1-base'\n",
    "}\n",
    "\n",
    "## The image uri which is build and pushed above\n",
    "image_uri = \"{}.dkr.ecr.{}.amazonaws.com/{}:latest\".format(account_id, region_name, repo_name)\n",
    "base_job_name = 'sd-xl-controlnet-finetuning-high'\n",
    "#instance_type = 'ml.p4d.24xlarge'\n",
    "instance_type = 'ml.g5.48xlarge'\n",
    "#inputs = {\n",
    "#    'images': f\"s3://{bucket}/controlnet-xl/images/\"\n",
    "#}\n",
    "\n",
    "estimator = PyTorch(role=role,\n",
    "                      entry_point='train_controlnet_sdxl.sh',\n",
    "                      #entry_point='train_controlnet_sdxl_h100.sh',\n",
    "                      source_dir='./sd_controlnet/',\n",
    "                      base_job_name=base_job_name,\n",
    "                      instance_count=1,\n",
    "                      instance_type=instance_type,\n",
    "                      image_uri=image_uri,\n",
    "                      environment=environment,\n",
    "                      volume_size = 1000,\n",
    "                      keep_alive_period_in_seconds=3600, #warmpool，为下一次训练保持机器&镜像（滚动续期，最大1hour）；需要开quota。\n",
    "                      disable_profiler=True,\n",
    "                      debugger_hook_config=False,\n",
    "                      max_run=24*60*60*2)\n",
    "\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd181b4e-f435-4dca-842a-444d083fdf3c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model artifact saved at:\n",
      " s3://sagemaker-us-west-2-687912291502/stable-diffusion/controlnet/\n"
     ]
    }
   ],
   "source": [
    "print(\"Model artifact saved at:\\n\", controlnet_s3uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ae7e76-9604-4e42-9c3b-d774d32a33b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
